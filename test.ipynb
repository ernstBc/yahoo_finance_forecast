{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address1': 'One Microsoft Way',\n",
       " 'city': 'Redmond',\n",
       " 'state': 'WA',\n",
       " 'zip': '98052-6399',\n",
       " 'country': 'United States',\n",
       " 'phone': '425 882 8080',\n",
       " 'website': 'https://www.microsoft.com',\n",
       " 'industry': 'Software - Infrastructure',\n",
       " 'industryKey': 'software-infrastructure',\n",
       " 'industryDisp': 'Software - Infrastructure',\n",
       " 'sector': 'Technology',\n",
       " 'sectorKey': 'technology',\n",
       " 'sectorDisp': 'Technology',\n",
       " 'longBusinessSummary': 'Microsoft Corporation develops and supports software, services, devices and solutions worldwide. The Productivity and Business Processes segment offers office, exchange, SharePoint, Microsoft Teams, office 365 Security and Compliance, Microsoft viva, and Microsoft 365 copilot; and office consumer services, such as Microsoft 365 consumer subscriptions, Office licensed on-premises, and other office services. This segment also provides LinkedIn; and dynamics business solutions, including Dynamics 365, a set of intelligent, cloud-based applications across ERP, CRM, power apps, and power automate; and on-premises ERP and CRM applications. The Intelligent Cloud segment offers server products and cloud services, such as azure and other cloud services; SQL and windows server, visual studio, system center, and related client access licenses, as well as nuance and GitHub; and enterprise services including enterprise support services, industry solutions, and nuance professional services. The More Personal Computing segment offers Windows, including windows OEM licensing and other non-volume licensing of the Windows operating system; Windows commercial comprising volume licensing of the Windows operating system, windows cloud services, and other Windows commercial offerings; patent licensing; and windows Internet of Things; and devices, such as surface, HoloLens, and PC accessories. Additionally, this segment provides gaming, which includes Xbox hardware and content, and first- and third-party content; Xbox game pass and other subscriptions, cloud gaming, advertising, third-party disc royalties, and other cloud services; and search and news advertising, which includes Bing, Microsoft News and Edge, and third-party affiliates. The company sells its products through OEMs, distributors, and resellers; and directly through digital marketplaces, online, and retail stores. The company was founded in 1975 and is headquartered in Redmond, Washington.',\n",
       " 'fullTimeEmployees': 228000,\n",
       " 'companyOfficers': [{'maxAge': 1,\n",
       "   'name': 'Mr. Satya  Nadella',\n",
       "   'age': 56,\n",
       "   'title': 'Chairman & CEO',\n",
       "   'yearBorn': 1967,\n",
       "   'fiscalYear': 2024,\n",
       "   'totalPay': 7869791,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Mr. Bradford L. Smith LCA',\n",
       "   'age': 64,\n",
       "   'title': 'President & Vice Chairman',\n",
       "   'yearBorn': 1959,\n",
       "   'fiscalYear': 2024,\n",
       "   'totalPay': 4755618,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Ms. Amy E. Hood',\n",
       "   'age': 51,\n",
       "   'title': 'Executive VP & CFO',\n",
       "   'yearBorn': 1972,\n",
       "   'fiscalYear': 2024,\n",
       "   'totalPay': 4704250,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Mr. Judson B. Althoff',\n",
       "   'age': 50,\n",
       "   'title': 'Executive VP & Chief Commercial Officer',\n",
       "   'yearBorn': 1973,\n",
       "   'fiscalYear': 2024,\n",
       "   'totalPay': 4534974,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Mr. Christopher David Young',\n",
       "   'age': 51,\n",
       "   'title': 'Executive Vice President of Business Development, Strategy & Ventures',\n",
       "   'yearBorn': 1972,\n",
       "   'fiscalYear': 2024,\n",
       "   'totalPay': 2993772,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Ms. Carolina  Dybeck Happe',\n",
       "   'age': 51,\n",
       "   'title': 'Executive VP & COO',\n",
       "   'yearBorn': 1972,\n",
       "   'fiscalYear': 2024,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Ms. Alice L. Jolla',\n",
       "   'age': 57,\n",
       "   'title': 'Corporate VP & Chief Accounting Officer',\n",
       "   'yearBorn': 1966,\n",
       "   'fiscalYear': 2024,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Mr. James Kevin Scott',\n",
       "   'age': 51,\n",
       "   'title': 'Executive VP of AI & CTO',\n",
       "   'yearBorn': 1972,\n",
       "   'fiscalYear': 2024,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Brett  Iversen',\n",
       "   'title': 'Vice President of Investor Relations',\n",
       "   'fiscalYear': 2024,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Mr. Hossein  Nowbar',\n",
       "   'title': 'Chief Legal Officer',\n",
       "   'fiscalYear': 2024,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0}],\n",
       " 'auditRisk': 3,\n",
       " 'boardRisk': 5,\n",
       " 'compensationRisk': 2,\n",
       " 'shareHolderRightsRisk': 2,\n",
       " 'overallRisk': 1,\n",
       " 'governanceEpochDate': 1730073600,\n",
       " 'compensationAsOfEpochDate': 1735603200,\n",
       " 'irWebsite': 'http://www.microsoft.com/investor/default.aspx',\n",
       " 'maxAge': 86400,\n",
       " 'priceHint': 2,\n",
       " 'previousClose': 431.95,\n",
       " 'open': 437.435,\n",
       " 'dayLow': 432.58,\n",
       " 'dayHigh': 438.5,\n",
       " 'regularMarketPreviousClose': 431.95,\n",
       " 'regularMarketOpen': 437.435,\n",
       " 'regularMarketDayLow': 432.58,\n",
       " 'regularMarketDayHigh': 438.5,\n",
       " 'dividendRate': 3.32,\n",
       " 'dividendYield': 0.0077,\n",
       " 'exDividendDate': 1732147200,\n",
       " 'payoutRatio': 0.2483,\n",
       " 'fiveYearAvgDividendYield': 0.89,\n",
       " 'beta': 0.896,\n",
       " 'trailingPE': 36.925236,\n",
       " 'forwardPE': 28.622519,\n",
       " 'volume': 17344727,\n",
       " 'regularMarketVolume': 17344727,\n",
       " 'averageVolume': 19198354,\n",
       " 'averageVolume10days': 16976180,\n",
       " 'averageDailyVolume10Day': 16976180,\n",
       " 'bid': 435.2,\n",
       " 'ask': 435.58,\n",
       " 'bidSize': 100,\n",
       " 'askSize': 100,\n",
       " 'marketCap': 3236572430336,\n",
       " 'fiftyTwoWeekLow': 339.65,\n",
       " 'fiftyTwoWeekHigh': 468.35,\n",
       " 'priceToSalesTrailing12Months': 13.203924,\n",
       " 'fiftyDayAverage': 420.9922,\n",
       " 'twoHundredDayAverage': 420.4501,\n",
       " 'trailingAnnualDividendRate': 3.0,\n",
       " 'trailingAnnualDividendYield': 0.006945248,\n",
       " 'currency': 'USD',\n",
       " 'enterpriseValue': 3233021952000,\n",
       " 'profitMargins': 0.35956,\n",
       " 'floatShares': 7422632127,\n",
       " 'sharesOutstanding': 7434440192,\n",
       " 'sharesShort': 60313798,\n",
       " 'sharesShortPriorMonth': 67500308,\n",
       " 'sharesShortPreviousMonthDate': 1726185600,\n",
       " 'dateShortInterest': 1728950400,\n",
       " 'sharesPercentSharesOut': 0.0081,\n",
       " 'heldPercentInsiders': 0.00055,\n",
       " 'heldPercentInstitutions': 0.73706,\n",
       " 'shortRatio': 3.26,\n",
       " 'shortPercentOfFloat': 0.0081,\n",
       " 'impliedSharesOutstanding': 7433039872,\n",
       " 'bookValue': 36.115,\n",
       " 'priceToBook': 12.054506,\n",
       " 'lastFiscalYearEnd': 1719705600,\n",
       " 'nextFiscalYearEnd': 1751241600,\n",
       " 'mostRecentQuarter': 1719705600,\n",
       " 'earningsQuarterlyGrowth': 0.097,\n",
       " 'netIncomeToCommon': 88135999488,\n",
       " 'trailingEps': 11.79,\n",
       " 'forwardEps': 15.21,\n",
       " 'pegRatio': 2.21,\n",
       " 'lastSplitFactor': '2:1',\n",
       " 'lastSplitDate': 1045526400,\n",
       " 'enterpriseToRevenue': 13.189,\n",
       " 'enterpriseToEbitda': 24.978,\n",
       " '52WeekChange': 0.24815786,\n",
       " 'SandP52WeekChange': 0.3763833,\n",
       " 'lastDividendValue': 0.75,\n",
       " 'lastDividendDate': 1723680000,\n",
       " 'exchange': 'NMS',\n",
       " 'quoteType': 'EQUITY',\n",
       " 'symbol': 'MSFT',\n",
       " 'underlyingSymbol': 'MSFT',\n",
       " 'shortName': 'Microsoft Corporation',\n",
       " 'longName': 'Microsoft Corporation',\n",
       " 'firstTradeDateEpochUtc': 511108200,\n",
       " 'timeZoneFullName': 'America/New_York',\n",
       " 'timeZoneShortName': 'EDT',\n",
       " 'uuid': 'b004b3ec-de24-385e-b2c1-923f10d3fb62',\n",
       " 'messageBoardId': 'finmb_21835',\n",
       " 'gmtOffSetMilliseconds': -14400000,\n",
       " 'currentPrice': 435.3485,\n",
       " 'targetHighPrice': 600.0,\n",
       " 'targetLowPrice': 440.0,\n",
       " 'targetMeanPrice': 495.89,\n",
       " 'targetMedianPrice': 500.0,\n",
       " 'recommendationMean': 1.7,\n",
       " 'recommendationKey': 'buy',\n",
       " 'numberOfAnalystOpinions': 46,\n",
       " 'totalCash': 75531001856,\n",
       " 'totalCashPerShare': 10.162,\n",
       " 'ebitda': 129433001984,\n",
       " 'totalDebt': 97851998208,\n",
       " 'quickRatio': 1.141,\n",
       " 'currentRatio': 1.275,\n",
       " 'totalRevenue': 245122007040,\n",
       " 'debtToEquity': 36.447,\n",
       " 'revenuePerShare': 32.986,\n",
       " 'returnOnAssets': 0.14802,\n",
       " 'returnOnEquity': 0.37133,\n",
       " 'freeCashflow': 56705249280,\n",
       " 'operatingCashflow': 118547996672,\n",
       " 'earningsGrowth': 0.097,\n",
       " 'revenueGrowth': 0.152,\n",
       " 'grossMargins': 0.69764,\n",
       " 'ebitdaMargins': 0.52804,\n",
       " 'operatingMargins': 0.43143,\n",
       " 'financialCurrency': 'USD',\n",
       " 'trailingPegRatio': 2.3462}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft=yf.Ticker('MSFT')\n",
    "msft.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-04-30 00:00:00-04:00</th>\n",
       "      <td>400.046050</td>\n",
       "      <td>400.713654</td>\n",
       "      <td>387.770381</td>\n",
       "      <td>387.929779</td>\n",
       "      <td>28781400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01 00:00:00-04:00</th>\n",
       "      <td>391.197985</td>\n",
       "      <td>400.275238</td>\n",
       "      <td>388.906269</td>\n",
       "      <td>393.519623</td>\n",
       "      <td>23562500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-02 00:00:00-04:00</th>\n",
       "      <td>396.229865</td>\n",
       "      <td>398.491690</td>\n",
       "      <td>393.230680</td>\n",
       "      <td>396.409210</td>\n",
       "      <td>17709400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-03 00:00:00-04:00</th>\n",
       "      <td>400.833227</td>\n",
       "      <td>405.685707</td>\n",
       "      <td>400.414724</td>\n",
       "      <td>405.197479</td>\n",
       "      <td>17446700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-06 00:00:00-04:00</th>\n",
       "      <td>407.289957</td>\n",
       "      <td>412.441346</td>\n",
       "      <td>404.908537</td>\n",
       "      <td>412.052765</td>\n",
       "      <td>16996600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-24 00:00:00-04:00</th>\n",
       "      <td>425.329987</td>\n",
       "      <td>425.980011</td>\n",
       "      <td>422.399994</td>\n",
       "      <td>424.730011</td>\n",
       "      <td>13581600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-25 00:00:00-04:00</th>\n",
       "      <td>426.760010</td>\n",
       "      <td>432.519989</td>\n",
       "      <td>426.570007</td>\n",
       "      <td>428.149994</td>\n",
       "      <td>16899100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-28 00:00:00-04:00</th>\n",
       "      <td>431.660004</td>\n",
       "      <td>431.940002</td>\n",
       "      <td>426.299988</td>\n",
       "      <td>426.589996</td>\n",
       "      <td>14882400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-29 00:00:00-04:00</th>\n",
       "      <td>428.000000</td>\n",
       "      <td>433.170013</td>\n",
       "      <td>425.799988</td>\n",
       "      <td>431.950012</td>\n",
       "      <td>17644100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-30 00:00:00-04:00</th>\n",
       "      <td>437.434998</td>\n",
       "      <td>438.500000</td>\n",
       "      <td>432.579987</td>\n",
       "      <td>435.348511</td>\n",
       "      <td>17344547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2024-04-30 00:00:00-04:00  400.046050  400.713654  387.770381  387.929779   \n",
       "2024-05-01 00:00:00-04:00  391.197985  400.275238  388.906269  393.519623   \n",
       "2024-05-02 00:00:00-04:00  396.229865  398.491690  393.230680  396.409210   \n",
       "2024-05-03 00:00:00-04:00  400.833227  405.685707  400.414724  405.197479   \n",
       "2024-05-06 00:00:00-04:00  407.289957  412.441346  404.908537  412.052765   \n",
       "...                               ...         ...         ...         ...   \n",
       "2024-10-24 00:00:00-04:00  425.329987  425.980011  422.399994  424.730011   \n",
       "2024-10-25 00:00:00-04:00  426.760010  432.519989  426.570007  428.149994   \n",
       "2024-10-28 00:00:00-04:00  431.660004  431.940002  426.299988  426.589996   \n",
       "2024-10-29 00:00:00-04:00  428.000000  433.170013  425.799988  431.950012   \n",
       "2024-10-30 00:00:00-04:00  437.434998  438.500000  432.579987  435.348511   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  \n",
       "Date                                                          \n",
       "2024-04-30 00:00:00-04:00  28781400        0.0           0.0  \n",
       "2024-05-01 00:00:00-04:00  23562500        0.0           0.0  \n",
       "2024-05-02 00:00:00-04:00  17709400        0.0           0.0  \n",
       "2024-05-03 00:00:00-04:00  17446700        0.0           0.0  \n",
       "2024-05-06 00:00:00-04:00  16996600        0.0           0.0  \n",
       "...                             ...        ...           ...  \n",
       "2024-10-24 00:00:00-04:00  13581600        0.0           0.0  \n",
       "2024-10-25 00:00:00-04:00  16899100        0.0           0.0  \n",
       "2024-10-28 00:00:00-04:00  14882400        0.0           0.0  \n",
       "2024-10-29 00:00:00-04:00  17644100        0.0           0.0  \n",
       "2024-10-30 00:00:00-04:00  17344547        0.0           0.0  \n",
       "\n",
       "[128 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = msft.history(period=\"6mo\")\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Date'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist.Close.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = yf.Tickers('msft aapl goog')\n",
    "\n",
    "msft=tickers.tickers['MSFT'].history(period='1mo')\n",
    "apple=tickers.tickers['AAPL'].history(period=\"1mo\")\n",
    "goo=tickers.tickers['GOOG'].history(period=\"1mo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_msft</th>\n",
       "      <th>High_msft</th>\n",
       "      <th>Low_msft</th>\n",
       "      <th>Close_msft</th>\n",
       "      <th>Volume_msft</th>\n",
       "      <th>Dividends_msft</th>\n",
       "      <th>Stock Splits_msft</th>\n",
       "      <th>Open_apple</th>\n",
       "      <th>High_apple</th>\n",
       "      <th>Low_apple</th>\n",
       "      <th>...</th>\n",
       "      <th>Volume_apple</th>\n",
       "      <th>Dividends_apple</th>\n",
       "      <th>Stock Splits_apple</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-09-30 00:00:00-04:00</th>\n",
       "      <td>428.209991</td>\n",
       "      <td>430.420013</td>\n",
       "      <td>425.369995</td>\n",
       "      <td>430.299988</td>\n",
       "      <td>16807300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.039993</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>229.649994</td>\n",
       "      <td>...</td>\n",
       "      <td>54541900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.779999</td>\n",
       "      <td>167.360001</td>\n",
       "      <td>164.639999</td>\n",
       "      <td>167.190002</td>\n",
       "      <td>14070100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00-04:00</th>\n",
       "      <td>428.450012</td>\n",
       "      <td>428.480011</td>\n",
       "      <td>418.809998</td>\n",
       "      <td>420.690002</td>\n",
       "      <td>19092900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.520004</td>\n",
       "      <td>229.649994</td>\n",
       "      <td>223.740005</td>\n",
       "      <td>...</td>\n",
       "      <td>63285000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.860001</td>\n",
       "      <td>170.440002</td>\n",
       "      <td>165.899994</td>\n",
       "      <td>168.419998</td>\n",
       "      <td>18629500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-02 00:00:00-04:00</th>\n",
       "      <td>422.579987</td>\n",
       "      <td>422.820007</td>\n",
       "      <td>416.709991</td>\n",
       "      <td>417.130005</td>\n",
       "      <td>16582300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.889999</td>\n",
       "      <td>227.369995</td>\n",
       "      <td>223.020004</td>\n",
       "      <td>...</td>\n",
       "      <td>32880600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.759995</td>\n",
       "      <td>168.880005</td>\n",
       "      <td>166.250000</td>\n",
       "      <td>167.309998</td>\n",
       "      <td>12745000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-03 00:00:00-04:00</th>\n",
       "      <td>417.630005</td>\n",
       "      <td>419.549988</td>\n",
       "      <td>414.290009</td>\n",
       "      <td>416.540009</td>\n",
       "      <td>13686400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.139999</td>\n",
       "      <td>226.809998</td>\n",
       "      <td>223.320007</td>\n",
       "      <td>...</td>\n",
       "      <td>34044200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.820007</td>\n",
       "      <td>167.910004</td>\n",
       "      <td>165.369995</td>\n",
       "      <td>167.210007</td>\n",
       "      <td>11004300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-04 00:00:00-04:00</th>\n",
       "      <td>418.239990</td>\n",
       "      <td>419.750000</td>\n",
       "      <td>414.970001</td>\n",
       "      <td>416.059998</td>\n",
       "      <td>19169700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.899994</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>224.130005</td>\n",
       "      <td>...</td>\n",
       "      <td>37245100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.339996</td>\n",
       "      <td>169.550003</td>\n",
       "      <td>166.960007</td>\n",
       "      <td>168.559998</td>\n",
       "      <td>11422100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-07 00:00:00-04:00</th>\n",
       "      <td>416.000000</td>\n",
       "      <td>417.109985</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.540009</td>\n",
       "      <td>20919800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.500000</td>\n",
       "      <td>225.690002</td>\n",
       "      <td>221.330002</td>\n",
       "      <td>...</td>\n",
       "      <td>39505400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.139999</td>\n",
       "      <td>169.899994</td>\n",
       "      <td>164.130005</td>\n",
       "      <td>164.389999</td>\n",
       "      <td>14034700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08 00:00:00-04:00</th>\n",
       "      <td>410.899994</td>\n",
       "      <td>415.660004</td>\n",
       "      <td>408.170013</td>\n",
       "      <td>414.709991</td>\n",
       "      <td>19229300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.300003</td>\n",
       "      <td>225.979996</td>\n",
       "      <td>223.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>31855700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.429993</td>\n",
       "      <td>166.100006</td>\n",
       "      <td>164.309998</td>\n",
       "      <td>165.699997</td>\n",
       "      <td>11723900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-09 00:00:00-04:00</th>\n",
       "      <td>415.859985</td>\n",
       "      <td>420.380005</td>\n",
       "      <td>414.299988</td>\n",
       "      <td>417.459991</td>\n",
       "      <td>14974300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.229996</td>\n",
       "      <td>229.750000</td>\n",
       "      <td>224.830002</td>\n",
       "      <td>...</td>\n",
       "      <td>33591100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.854996</td>\n",
       "      <td>166.259995</td>\n",
       "      <td>161.119995</td>\n",
       "      <td>163.059998</td>\n",
       "      <td>19666400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-10 00:00:00-04:00</th>\n",
       "      <td>415.230011</td>\n",
       "      <td>417.350006</td>\n",
       "      <td>413.149994</td>\n",
       "      <td>415.839996</td>\n",
       "      <td>13848400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.779999</td>\n",
       "      <td>229.500000</td>\n",
       "      <td>227.169998</td>\n",
       "      <td>...</td>\n",
       "      <td>28183500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.110001</td>\n",
       "      <td>164.311005</td>\n",
       "      <td>161.639999</td>\n",
       "      <td>163.179993</td>\n",
       "      <td>12900500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-11 00:00:00-04:00</th>\n",
       "      <td>416.140015</td>\n",
       "      <td>417.130005</td>\n",
       "      <td>413.250000</td>\n",
       "      <td>416.320007</td>\n",
       "      <td>14144900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.300003</td>\n",
       "      <td>229.410004</td>\n",
       "      <td>227.339996</td>\n",
       "      <td>...</td>\n",
       "      <td>31759200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.330002</td>\n",
       "      <td>165.270004</td>\n",
       "      <td>162.500000</td>\n",
       "      <td>164.520004</td>\n",
       "      <td>10946000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-14 00:00:00-04:00</th>\n",
       "      <td>417.769989</td>\n",
       "      <td>424.040009</td>\n",
       "      <td>417.519989</td>\n",
       "      <td>419.140015</td>\n",
       "      <td>16653100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.699997</td>\n",
       "      <td>231.729996</td>\n",
       "      <td>228.600006</td>\n",
       "      <td>...</td>\n",
       "      <td>39882100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.910004</td>\n",
       "      <td>167.619995</td>\n",
       "      <td>164.779999</td>\n",
       "      <td>166.350006</td>\n",
       "      <td>9981800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-15 00:00:00-04:00</th>\n",
       "      <td>422.179993</td>\n",
       "      <td>422.480011</td>\n",
       "      <td>415.260010</td>\n",
       "      <td>418.739990</td>\n",
       "      <td>18900200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.610001</td>\n",
       "      <td>237.490005</td>\n",
       "      <td>232.369995</td>\n",
       "      <td>...</td>\n",
       "      <td>64751400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.139999</td>\n",
       "      <td>169.089996</td>\n",
       "      <td>166.050003</td>\n",
       "      <td>166.899994</td>\n",
       "      <td>14829300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-16 00:00:00-04:00</th>\n",
       "      <td>415.170013</td>\n",
       "      <td>416.359985</td>\n",
       "      <td>410.480011</td>\n",
       "      <td>416.119995</td>\n",
       "      <td>15508900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.600006</td>\n",
       "      <td>232.119995</td>\n",
       "      <td>229.839996</td>\n",
       "      <td>...</td>\n",
       "      <td>34082200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.029999</td>\n",
       "      <td>167.279999</td>\n",
       "      <td>165.216003</td>\n",
       "      <td>166.740005</td>\n",
       "      <td>9968500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-17 00:00:00-04:00</th>\n",
       "      <td>422.359985</td>\n",
       "      <td>422.500000</td>\n",
       "      <td>415.589996</td>\n",
       "      <td>416.720001</td>\n",
       "      <td>14820000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.429993</td>\n",
       "      <td>233.850006</td>\n",
       "      <td>230.520004</td>\n",
       "      <td>...</td>\n",
       "      <td>32993800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.380005</td>\n",
       "      <td>167.929993</td>\n",
       "      <td>164.369995</td>\n",
       "      <td>164.509995</td>\n",
       "      <td>15113400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-18 00:00:00-04:00</th>\n",
       "      <td>417.140015</td>\n",
       "      <td>419.649994</td>\n",
       "      <td>416.260010</td>\n",
       "      <td>418.160004</td>\n",
       "      <td>17145300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236.179993</td>\n",
       "      <td>236.179993</td>\n",
       "      <td>234.009995</td>\n",
       "      <td>...</td>\n",
       "      <td>46431500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.869995</td>\n",
       "      <td>166.369995</td>\n",
       "      <td>164.750000</td>\n",
       "      <td>165.050003</td>\n",
       "      <td>13091300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-21 00:00:00-04:00</th>\n",
       "      <td>416.119995</td>\n",
       "      <td>418.959991</td>\n",
       "      <td>413.750000</td>\n",
       "      <td>418.779999</td>\n",
       "      <td>14206100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234.449997</td>\n",
       "      <td>236.850006</td>\n",
       "      <td>234.449997</td>\n",
       "      <td>...</td>\n",
       "      <td>36254500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.580002</td>\n",
       "      <td>166.220001</td>\n",
       "      <td>164.304993</td>\n",
       "      <td>165.800003</td>\n",
       "      <td>11384000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-22 00:00:00-04:00</th>\n",
       "      <td>418.489990</td>\n",
       "      <td>430.579987</td>\n",
       "      <td>418.040009</td>\n",
       "      <td>427.510010</td>\n",
       "      <td>25482200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.889999</td>\n",
       "      <td>236.220001</td>\n",
       "      <td>232.600006</td>\n",
       "      <td>...</td>\n",
       "      <td>38846600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.699997</td>\n",
       "      <td>167.470001</td>\n",
       "      <td>164.669998</td>\n",
       "      <td>166.820007</td>\n",
       "      <td>11958600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-23 00:00:00-04:00</th>\n",
       "      <td>430.859985</td>\n",
       "      <td>431.079987</td>\n",
       "      <td>422.529999</td>\n",
       "      <td>424.600006</td>\n",
       "      <td>19654400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234.080002</td>\n",
       "      <td>235.139999</td>\n",
       "      <td>227.759995</td>\n",
       "      <td>...</td>\n",
       "      <td>52287000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.429993</td>\n",
       "      <td>167.600006</td>\n",
       "      <td>163.632996</td>\n",
       "      <td>164.479996</td>\n",
       "      <td>12754300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-24 00:00:00-04:00</th>\n",
       "      <td>425.329987</td>\n",
       "      <td>425.980011</td>\n",
       "      <td>422.399994</td>\n",
       "      <td>424.730011</td>\n",
       "      <td>13581600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.979996</td>\n",
       "      <td>230.820007</td>\n",
       "      <td>228.410004</td>\n",
       "      <td>...</td>\n",
       "      <td>31109500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.589996</td>\n",
       "      <td>165.050003</td>\n",
       "      <td>162.770004</td>\n",
       "      <td>164.529999</td>\n",
       "      <td>12764400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-25 00:00:00-04:00</th>\n",
       "      <td>426.760010</td>\n",
       "      <td>432.519989</td>\n",
       "      <td>426.570007</td>\n",
       "      <td>428.149994</td>\n",
       "      <td>16899100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.740005</td>\n",
       "      <td>233.220001</td>\n",
       "      <td>229.570007</td>\n",
       "      <td>...</td>\n",
       "      <td>38802300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.365005</td>\n",
       "      <td>167.399994</td>\n",
       "      <td>165.229996</td>\n",
       "      <td>166.990005</td>\n",
       "      <td>14566400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-28 00:00:00-04:00</th>\n",
       "      <td>431.660004</td>\n",
       "      <td>431.940002</td>\n",
       "      <td>426.299988</td>\n",
       "      <td>426.589996</td>\n",
       "      <td>14882400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.320007</td>\n",
       "      <td>234.729996</td>\n",
       "      <td>232.550003</td>\n",
       "      <td>...</td>\n",
       "      <td>36087100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.589996</td>\n",
       "      <td>170.606003</td>\n",
       "      <td>165.789993</td>\n",
       "      <td>168.339996</td>\n",
       "      <td>20858300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-29 00:00:00-04:00</th>\n",
       "      <td>428.000000</td>\n",
       "      <td>433.170013</td>\n",
       "      <td>425.799988</td>\n",
       "      <td>431.950012</td>\n",
       "      <td>17644100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.100006</td>\n",
       "      <td>234.330002</td>\n",
       "      <td>232.320007</td>\n",
       "      <td>...</td>\n",
       "      <td>35417200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.384995</td>\n",
       "      <td>171.860001</td>\n",
       "      <td>168.660004</td>\n",
       "      <td>171.139999</td>\n",
       "      <td>28916100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-30 00:00:00-04:00</th>\n",
       "      <td>437.434998</td>\n",
       "      <td>438.500000</td>\n",
       "      <td>432.579987</td>\n",
       "      <td>435.350006</td>\n",
       "      <td>17346205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232.619995</td>\n",
       "      <td>233.470001</td>\n",
       "      <td>229.870407</td>\n",
       "      <td>...</td>\n",
       "      <td>27945162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.544998</td>\n",
       "      <td>183.779999</td>\n",
       "      <td>177.220001</td>\n",
       "      <td>177.330002</td>\n",
       "      <td>42789018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Open_msft   High_msft    Low_msft  Close_msft  \\\n",
       "Date                                                                        \n",
       "2024-09-30 00:00:00-04:00  428.209991  430.420013  425.369995  430.299988   \n",
       "2024-10-01 00:00:00-04:00  428.450012  428.480011  418.809998  420.690002   \n",
       "2024-10-02 00:00:00-04:00  422.579987  422.820007  416.709991  417.130005   \n",
       "2024-10-03 00:00:00-04:00  417.630005  419.549988  414.290009  416.540009   \n",
       "2024-10-04 00:00:00-04:00  418.239990  419.750000  414.970001  416.059998   \n",
       "2024-10-07 00:00:00-04:00  416.000000  417.109985  409.000000  409.540009   \n",
       "2024-10-08 00:00:00-04:00  410.899994  415.660004  408.170013  414.709991   \n",
       "2024-10-09 00:00:00-04:00  415.859985  420.380005  414.299988  417.459991   \n",
       "2024-10-10 00:00:00-04:00  415.230011  417.350006  413.149994  415.839996   \n",
       "2024-10-11 00:00:00-04:00  416.140015  417.130005  413.250000  416.320007   \n",
       "2024-10-14 00:00:00-04:00  417.769989  424.040009  417.519989  419.140015   \n",
       "2024-10-15 00:00:00-04:00  422.179993  422.480011  415.260010  418.739990   \n",
       "2024-10-16 00:00:00-04:00  415.170013  416.359985  410.480011  416.119995   \n",
       "2024-10-17 00:00:00-04:00  422.359985  422.500000  415.589996  416.720001   \n",
       "2024-10-18 00:00:00-04:00  417.140015  419.649994  416.260010  418.160004   \n",
       "2024-10-21 00:00:00-04:00  416.119995  418.959991  413.750000  418.779999   \n",
       "2024-10-22 00:00:00-04:00  418.489990  430.579987  418.040009  427.510010   \n",
       "2024-10-23 00:00:00-04:00  430.859985  431.079987  422.529999  424.600006   \n",
       "2024-10-24 00:00:00-04:00  425.329987  425.980011  422.399994  424.730011   \n",
       "2024-10-25 00:00:00-04:00  426.760010  432.519989  426.570007  428.149994   \n",
       "2024-10-28 00:00:00-04:00  431.660004  431.940002  426.299988  426.589996   \n",
       "2024-10-29 00:00:00-04:00  428.000000  433.170013  425.799988  431.950012   \n",
       "2024-10-30 00:00:00-04:00  437.434998  438.500000  432.579987  435.350006   \n",
       "\n",
       "                           Volume_msft  Dividends_msft  Stock Splits_msft  \\\n",
       "Date                                                                        \n",
       "2024-09-30 00:00:00-04:00     16807300             0.0                0.0   \n",
       "2024-10-01 00:00:00-04:00     19092900             0.0                0.0   \n",
       "2024-10-02 00:00:00-04:00     16582300             0.0                0.0   \n",
       "2024-10-03 00:00:00-04:00     13686400             0.0                0.0   \n",
       "2024-10-04 00:00:00-04:00     19169700             0.0                0.0   \n",
       "2024-10-07 00:00:00-04:00     20919800             0.0                0.0   \n",
       "2024-10-08 00:00:00-04:00     19229300             0.0                0.0   \n",
       "2024-10-09 00:00:00-04:00     14974300             0.0                0.0   \n",
       "2024-10-10 00:00:00-04:00     13848400             0.0                0.0   \n",
       "2024-10-11 00:00:00-04:00     14144900             0.0                0.0   \n",
       "2024-10-14 00:00:00-04:00     16653100             0.0                0.0   \n",
       "2024-10-15 00:00:00-04:00     18900200             0.0                0.0   \n",
       "2024-10-16 00:00:00-04:00     15508900             0.0                0.0   \n",
       "2024-10-17 00:00:00-04:00     14820000             0.0                0.0   \n",
       "2024-10-18 00:00:00-04:00     17145300             0.0                0.0   \n",
       "2024-10-21 00:00:00-04:00     14206100             0.0                0.0   \n",
       "2024-10-22 00:00:00-04:00     25482200             0.0                0.0   \n",
       "2024-10-23 00:00:00-04:00     19654400             0.0                0.0   \n",
       "2024-10-24 00:00:00-04:00     13581600             0.0                0.0   \n",
       "2024-10-25 00:00:00-04:00     16899100             0.0                0.0   \n",
       "2024-10-28 00:00:00-04:00     14882400             0.0                0.0   \n",
       "2024-10-29 00:00:00-04:00     17644100             0.0                0.0   \n",
       "2024-10-30 00:00:00-04:00     17346205             0.0                0.0   \n",
       "\n",
       "                           Open_apple  High_apple   Low_apple  ...  \\\n",
       "Date                                                           ...   \n",
       "2024-09-30 00:00:00-04:00  230.039993  233.000000  229.649994  ...   \n",
       "2024-10-01 00:00:00-04:00  229.520004  229.649994  223.740005  ...   \n",
       "2024-10-02 00:00:00-04:00  225.889999  227.369995  223.020004  ...   \n",
       "2024-10-03 00:00:00-04:00  225.139999  226.809998  223.320007  ...   \n",
       "2024-10-04 00:00:00-04:00  227.899994  228.000000  224.130005  ...   \n",
       "2024-10-07 00:00:00-04:00  224.500000  225.690002  221.330002  ...   \n",
       "2024-10-08 00:00:00-04:00  224.300003  225.979996  223.250000  ...   \n",
       "2024-10-09 00:00:00-04:00  225.229996  229.750000  224.830002  ...   \n",
       "2024-10-10 00:00:00-04:00  227.779999  229.500000  227.169998  ...   \n",
       "2024-10-11 00:00:00-04:00  229.300003  229.410004  227.339996  ...   \n",
       "2024-10-14 00:00:00-04:00  228.699997  231.729996  228.600006  ...   \n",
       "2024-10-15 00:00:00-04:00  233.610001  237.490005  232.369995  ...   \n",
       "2024-10-16 00:00:00-04:00  231.600006  232.119995  229.839996  ...   \n",
       "2024-10-17 00:00:00-04:00  233.429993  233.850006  230.520004  ...   \n",
       "2024-10-18 00:00:00-04:00  236.179993  236.179993  234.009995  ...   \n",
       "2024-10-21 00:00:00-04:00  234.449997  236.850006  234.449997  ...   \n",
       "2024-10-22 00:00:00-04:00  233.889999  236.220001  232.600006  ...   \n",
       "2024-10-23 00:00:00-04:00  234.080002  235.139999  227.759995  ...   \n",
       "2024-10-24 00:00:00-04:00  229.979996  230.820007  228.410004  ...   \n",
       "2024-10-25 00:00:00-04:00  229.740005  233.220001  229.570007  ...   \n",
       "2024-10-28 00:00:00-04:00  233.320007  234.729996  232.550003  ...   \n",
       "2024-10-29 00:00:00-04:00  233.100006  234.330002  232.320007  ...   \n",
       "2024-10-30 00:00:00-04:00  232.619995  233.470001  229.870407  ...   \n",
       "\n",
       "                           Volume_apple  Dividends_apple  Stock Splits_apple  \\\n",
       "Date                                                                           \n",
       "2024-09-30 00:00:00-04:00      54541900              0.0                 0.0   \n",
       "2024-10-01 00:00:00-04:00      63285000              0.0                 0.0   \n",
       "2024-10-02 00:00:00-04:00      32880600              0.0                 0.0   \n",
       "2024-10-03 00:00:00-04:00      34044200              0.0                 0.0   \n",
       "2024-10-04 00:00:00-04:00      37245100              0.0                 0.0   \n",
       "2024-10-07 00:00:00-04:00      39505400              0.0                 0.0   \n",
       "2024-10-08 00:00:00-04:00      31855700              0.0                 0.0   \n",
       "2024-10-09 00:00:00-04:00      33591100              0.0                 0.0   \n",
       "2024-10-10 00:00:00-04:00      28183500              0.0                 0.0   \n",
       "2024-10-11 00:00:00-04:00      31759200              0.0                 0.0   \n",
       "2024-10-14 00:00:00-04:00      39882100              0.0                 0.0   \n",
       "2024-10-15 00:00:00-04:00      64751400              0.0                 0.0   \n",
       "2024-10-16 00:00:00-04:00      34082200              0.0                 0.0   \n",
       "2024-10-17 00:00:00-04:00      32993800              0.0                 0.0   \n",
       "2024-10-18 00:00:00-04:00      46431500              0.0                 0.0   \n",
       "2024-10-21 00:00:00-04:00      36254500              0.0                 0.0   \n",
       "2024-10-22 00:00:00-04:00      38846600              0.0                 0.0   \n",
       "2024-10-23 00:00:00-04:00      52287000              0.0                 0.0   \n",
       "2024-10-24 00:00:00-04:00      31109500              0.0                 0.0   \n",
       "2024-10-25 00:00:00-04:00      38802300              0.0                 0.0   \n",
       "2024-10-28 00:00:00-04:00      36087100              0.0                 0.0   \n",
       "2024-10-29 00:00:00-04:00      35417200              0.0                 0.0   \n",
       "2024-10-30 00:00:00-04:00      27945162              0.0                 0.0   \n",
       "\n",
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2024-09-30 00:00:00-04:00  164.779999  167.360001  164.639999  167.190002   \n",
       "2024-10-01 00:00:00-04:00  168.860001  170.440002  165.899994  168.419998   \n",
       "2024-10-02 00:00:00-04:00  167.759995  168.880005  166.250000  167.309998   \n",
       "2024-10-03 00:00:00-04:00  165.820007  167.910004  165.369995  167.210007   \n",
       "2024-10-04 00:00:00-04:00  169.339996  169.550003  166.960007  168.559998   \n",
       "2024-10-07 00:00:00-04:00  169.139999  169.899994  164.130005  164.389999   \n",
       "2024-10-08 00:00:00-04:00  165.429993  166.100006  164.309998  165.699997   \n",
       "2024-10-09 00:00:00-04:00  164.854996  166.259995  161.119995  163.059998   \n",
       "2024-10-10 00:00:00-04:00  162.110001  164.311005  161.639999  163.179993   \n",
       "2024-10-11 00:00:00-04:00  163.330002  165.270004  162.500000  164.520004   \n",
       "2024-10-14 00:00:00-04:00  164.910004  167.619995  164.779999  166.350006   \n",
       "2024-10-15 00:00:00-04:00  167.139999  169.089996  166.050003  166.899994   \n",
       "2024-10-16 00:00:00-04:00  166.029999  167.279999  165.216003  166.740005   \n",
       "2024-10-17 00:00:00-04:00  167.380005  167.929993  164.369995  164.509995   \n",
       "2024-10-18 00:00:00-04:00  164.869995  166.369995  164.750000  165.050003   \n",
       "2024-10-21 00:00:00-04:00  164.580002  166.220001  164.304993  165.800003   \n",
       "2024-10-22 00:00:00-04:00  164.699997  167.470001  164.669998  166.820007   \n",
       "2024-10-23 00:00:00-04:00  166.429993  167.600006  163.632996  164.479996   \n",
       "2024-10-24 00:00:00-04:00  164.589996  165.050003  162.770004  164.529999   \n",
       "2024-10-25 00:00:00-04:00  165.365005  167.399994  165.229996  166.990005   \n",
       "2024-10-28 00:00:00-04:00  170.589996  170.606003  165.789993  168.339996   \n",
       "2024-10-29 00:00:00-04:00  169.384995  171.860001  168.660004  171.139999   \n",
       "2024-10-30 00:00:00-04:00  182.544998  183.779999  177.220001  177.330002   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  \n",
       "Date                                                          \n",
       "2024-09-30 00:00:00-04:00  14070100        0.0           0.0  \n",
       "2024-10-01 00:00:00-04:00  18629500        0.0           0.0  \n",
       "2024-10-02 00:00:00-04:00  12745000        0.0           0.0  \n",
       "2024-10-03 00:00:00-04:00  11004300        0.0           0.0  \n",
       "2024-10-04 00:00:00-04:00  11422100        0.0           0.0  \n",
       "2024-10-07 00:00:00-04:00  14034700        0.0           0.0  \n",
       "2024-10-08 00:00:00-04:00  11723900        0.0           0.0  \n",
       "2024-10-09 00:00:00-04:00  19666400        0.0           0.0  \n",
       "2024-10-10 00:00:00-04:00  12900500        0.0           0.0  \n",
       "2024-10-11 00:00:00-04:00  10946000        0.0           0.0  \n",
       "2024-10-14 00:00:00-04:00   9981800        0.0           0.0  \n",
       "2024-10-15 00:00:00-04:00  14829300        0.0           0.0  \n",
       "2024-10-16 00:00:00-04:00   9968500        0.0           0.0  \n",
       "2024-10-17 00:00:00-04:00  15113400        0.0           0.0  \n",
       "2024-10-18 00:00:00-04:00  13091300        0.0           0.0  \n",
       "2024-10-21 00:00:00-04:00  11384000        0.0           0.0  \n",
       "2024-10-22 00:00:00-04:00  11958600        0.0           0.0  \n",
       "2024-10-23 00:00:00-04:00  12754300        0.0           0.0  \n",
       "2024-10-24 00:00:00-04:00  12764400        0.0           0.0  \n",
       "2024-10-25 00:00:00-04:00  14566400        0.0           0.0  \n",
       "2024-10-28 00:00:00-04:00  20858300        0.0           0.0  \n",
       "2024-10-29 00:00:00-04:00  28916100        0.0           0.0  \n",
       "2024-10-30 00:00:00-04:00  42789018        0.0           0.0  \n",
       "\n",
       "[23 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined=msft.join(apple, how='left', on='Date', lsuffix='_msft', rsuffix='_apple')\n",
    "joined.join(goo, how='left', on='Date', rsuffix='_google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tickers:str, time_delta:str):\n",
    "    label_tickers=tickers.split(' ')\n",
    "\n",
    "    tickers = yf.Tickers(tickers)\n",
    "    \n",
    "    data=pd.DataFrame({})\n",
    "    for idx, tick in enumerate(label_tickers):\n",
    "        new_df=tickers.tickers[tick.upper()].history(period=time_delta)\n",
    "        new_df.columns=[f'{col.replace(' ', '_').lower()}_{tick}' for col in new_df.columns]\n",
    "\n",
    "        if idx==0:\n",
    "            data=new_df\n",
    "        elif idx==1:\n",
    "            data=data.join(new_df, how='left', on='Date')\n",
    "        else:\n",
    "            data=data.join(new_df, how='left', on='Date')\n",
    "            \n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "joinend_data=get_data('msft aapl goog', '5y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'open_msft'.find('open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_msft</th>\n",
       "      <th>open_aapl</th>\n",
       "      <th>open_goog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-30 00:00:00-04:00</th>\n",
       "      <td>137.083112</td>\n",
       "      <td>59.210130</td>\n",
       "      <td>62.495022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-31 00:00:00-04:00</th>\n",
       "      <td>138.401182</td>\n",
       "      <td>59.810082</td>\n",
       "      <td>62.909502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 00:00:00-04:00</th>\n",
       "      <td>137.789914</td>\n",
       "      <td>60.366473</td>\n",
       "      <td>63.095049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 00:00:00-05:00</th>\n",
       "      <td>138.334351</td>\n",
       "      <td>62.250952</td>\n",
       "      <td>63.666146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 00:00:00-05:00</th>\n",
       "      <td>138.468094</td>\n",
       "      <td>62.183219</td>\n",
       "      <td>64.486131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-24 00:00:00-04:00</th>\n",
       "      <td>425.329987</td>\n",
       "      <td>229.979996</td>\n",
       "      <td>164.589996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-25 00:00:00-04:00</th>\n",
       "      <td>426.760010</td>\n",
       "      <td>229.740005</td>\n",
       "      <td>165.365005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-28 00:00:00-04:00</th>\n",
       "      <td>431.660004</td>\n",
       "      <td>233.320007</td>\n",
       "      <td>170.589996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-29 00:00:00-04:00</th>\n",
       "      <td>428.000000</td>\n",
       "      <td>233.100006</td>\n",
       "      <td>169.384995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-30 00:00:00-04:00</th>\n",
       "      <td>437.434998</td>\n",
       "      <td>232.619995</td>\n",
       "      <td>182.544998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            open_msft   open_aapl   open_goog\n",
       "Date                                                         \n",
       "2019-10-30 00:00:00-04:00  137.083112   59.210130   62.495022\n",
       "2019-10-31 00:00:00-04:00  138.401182   59.810082   62.909502\n",
       "2019-11-01 00:00:00-04:00  137.789914   60.366473   63.095049\n",
       "2019-11-04 00:00:00-05:00  138.334351   62.250952   63.666146\n",
       "2019-11-05 00:00:00-05:00  138.468094   62.183219   64.486131\n",
       "...                               ...         ...         ...\n",
       "2024-10-24 00:00:00-04:00  425.329987  229.979996  164.589996\n",
       "2024-10-25 00:00:00-04:00  426.760010  229.740005  165.365005\n",
       "2024-10-28 00:00:00-04:00  431.660004  233.320007  170.589996\n",
       "2024-10-29 00:00:00-04:00  428.000000  233.100006  169.384995\n",
       "2024-10-30 00:00:00-04:00  437.434998  232.619995  182.544998\n",
       "\n",
       "[1259 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinend_data.loc[:, [col for col in joinend_data.columns if col.find('open')==0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSFT': yfinance.Ticker object <MSFT>,\n",
       " 'AAPL': yfinance.Ticker object <AAPL>,\n",
       " 'GOOG': yfinance.Ticker object <GOOG>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers.tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['2019-10-30', '2019-10-31', '2019-11-01', '2019-11-04', '2019-11-05',\n",
       "       '2019-11-06', '2019-11-07', '2019-11-08', '2019-11-11', '2019-11-12',\n",
       "       ...\n",
       "       '2024-10-17', '2024-10-18', '2024-10-21', '2024-10-22', '2024-10-23',\n",
       "       '2024-10-24', '2024-10-25', '2024-10-28', '2024-10-29', '2024-10-30'],\n",
       "      dtype='object', name='Date', length=1259)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinend_data.index.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-10-30'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils import check_database_day\n",
    "\n",
    "check_database_day()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/ernes/Documents/ML Projects/forecast_yahoo/data/data')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.config import RAW_DATA_DIR\n",
    "RAW_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open_msft', 'high_msft', 'low_msft', 'close_msft', 'volume_msft',\n",
       "       'dividends_msft', 'stock_splits_msft', 'open_aapl', 'high_aapl',\n",
       "       'low_aapl', 'close_aapl', 'volume_aapl', 'dividends_aapl',\n",
       "       'stock_splits_aapl', 'open_goog', 'high_goog', 'low_goog', 'close_goog',\n",
       "       'volume_goog', 'dividends_goog', 'stock_splits_goog'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinend_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinend_data.index=pd.to_datetime(joinend_data.index, format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_msft</th>\n",
       "      <th>high_msft</th>\n",
       "      <th>low_msft</th>\n",
       "      <th>close_msft</th>\n",
       "      <th>volume_msft</th>\n",
       "      <th>dividends_msft</th>\n",
       "      <th>stock_splits_msft</th>\n",
       "      <th>open_aapl</th>\n",
       "      <th>high_aapl</th>\n",
       "      <th>low_aapl</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_aapl</th>\n",
       "      <th>dividends_aapl</th>\n",
       "      <th>stock_splits_aapl</th>\n",
       "      <th>open_goog</th>\n",
       "      <th>high_goog</th>\n",
       "      <th>low_goog</th>\n",
       "      <th>close_goog</th>\n",
       "      <th>volume_goog</th>\n",
       "      <th>dividends_goog</th>\n",
       "      <th>stock_splits_goog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-24 00:00:00-04:00</th>\n",
       "      <td>425.329987</td>\n",
       "      <td>425.980011</td>\n",
       "      <td>422.399994</td>\n",
       "      <td>424.730011</td>\n",
       "      <td>13581600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.979996</td>\n",
       "      <td>230.820007</td>\n",
       "      <td>228.410004</td>\n",
       "      <td>...</td>\n",
       "      <td>31109500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.589996</td>\n",
       "      <td>165.050003</td>\n",
       "      <td>162.770004</td>\n",
       "      <td>164.529999</td>\n",
       "      <td>12764400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-25 00:00:00-04:00</th>\n",
       "      <td>426.760010</td>\n",
       "      <td>432.519989</td>\n",
       "      <td>426.570007</td>\n",
       "      <td>428.149994</td>\n",
       "      <td>16899100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.740005</td>\n",
       "      <td>233.220001</td>\n",
       "      <td>229.570007</td>\n",
       "      <td>...</td>\n",
       "      <td>38802300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.365005</td>\n",
       "      <td>167.399994</td>\n",
       "      <td>165.229996</td>\n",
       "      <td>166.990005</td>\n",
       "      <td>14566400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-28 00:00:00-04:00</th>\n",
       "      <td>431.660004</td>\n",
       "      <td>431.940002</td>\n",
       "      <td>426.299988</td>\n",
       "      <td>426.589996</td>\n",
       "      <td>14882400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.320007</td>\n",
       "      <td>234.729996</td>\n",
       "      <td>232.550003</td>\n",
       "      <td>...</td>\n",
       "      <td>36087100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.589996</td>\n",
       "      <td>170.606003</td>\n",
       "      <td>165.789993</td>\n",
       "      <td>168.339996</td>\n",
       "      <td>20858300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-29 00:00:00-04:00</th>\n",
       "      <td>428.000000</td>\n",
       "      <td>433.170013</td>\n",
       "      <td>425.799988</td>\n",
       "      <td>431.950012</td>\n",
       "      <td>17644100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.100006</td>\n",
       "      <td>234.330002</td>\n",
       "      <td>232.320007</td>\n",
       "      <td>...</td>\n",
       "      <td>35417200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.384995</td>\n",
       "      <td>171.860001</td>\n",
       "      <td>168.660004</td>\n",
       "      <td>171.139999</td>\n",
       "      <td>28916100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-30 00:00:00-04:00</th>\n",
       "      <td>437.434998</td>\n",
       "      <td>438.500000</td>\n",
       "      <td>432.579987</td>\n",
       "      <td>435.359985</td>\n",
       "      <td>17346996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232.619995</td>\n",
       "      <td>233.470001</td>\n",
       "      <td>229.870407</td>\n",
       "      <td>...</td>\n",
       "      <td>27945170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.544998</td>\n",
       "      <td>183.779999</td>\n",
       "      <td>177.220001</td>\n",
       "      <td>177.330002</td>\n",
       "      <td>42789018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            open_msft   high_msft    low_msft  close_msft  \\\n",
       "Date                                                                        \n",
       "2024-10-24 00:00:00-04:00  425.329987  425.980011  422.399994  424.730011   \n",
       "2024-10-25 00:00:00-04:00  426.760010  432.519989  426.570007  428.149994   \n",
       "2024-10-28 00:00:00-04:00  431.660004  431.940002  426.299988  426.589996   \n",
       "2024-10-29 00:00:00-04:00  428.000000  433.170013  425.799988  431.950012   \n",
       "2024-10-30 00:00:00-04:00  437.434998  438.500000  432.579987  435.359985   \n",
       "\n",
       "                           volume_msft  dividends_msft  stock_splits_msft  \\\n",
       "Date                                                                        \n",
       "2024-10-24 00:00:00-04:00     13581600             0.0                0.0   \n",
       "2024-10-25 00:00:00-04:00     16899100             0.0                0.0   \n",
       "2024-10-28 00:00:00-04:00     14882400             0.0                0.0   \n",
       "2024-10-29 00:00:00-04:00     17644100             0.0                0.0   \n",
       "2024-10-30 00:00:00-04:00     17346996             0.0                0.0   \n",
       "\n",
       "                            open_aapl   high_aapl    low_aapl  ...  \\\n",
       "Date                                                           ...   \n",
       "2024-10-24 00:00:00-04:00  229.979996  230.820007  228.410004  ...   \n",
       "2024-10-25 00:00:00-04:00  229.740005  233.220001  229.570007  ...   \n",
       "2024-10-28 00:00:00-04:00  233.320007  234.729996  232.550003  ...   \n",
       "2024-10-29 00:00:00-04:00  233.100006  234.330002  232.320007  ...   \n",
       "2024-10-30 00:00:00-04:00  232.619995  233.470001  229.870407  ...   \n",
       "\n",
       "                           volume_aapl  dividends_aapl  stock_splits_aapl  \\\n",
       "Date                                                                        \n",
       "2024-10-24 00:00:00-04:00     31109500             0.0                0.0   \n",
       "2024-10-25 00:00:00-04:00     38802300             0.0                0.0   \n",
       "2024-10-28 00:00:00-04:00     36087100             0.0                0.0   \n",
       "2024-10-29 00:00:00-04:00     35417200             0.0                0.0   \n",
       "2024-10-30 00:00:00-04:00     27945170             0.0                0.0   \n",
       "\n",
       "                            open_goog   high_goog    low_goog  close_goog  \\\n",
       "Date                                                                        \n",
       "2024-10-24 00:00:00-04:00  164.589996  165.050003  162.770004  164.529999   \n",
       "2024-10-25 00:00:00-04:00  165.365005  167.399994  165.229996  166.990005   \n",
       "2024-10-28 00:00:00-04:00  170.589996  170.606003  165.789993  168.339996   \n",
       "2024-10-29 00:00:00-04:00  169.384995  171.860001  168.660004  171.139999   \n",
       "2024-10-30 00:00:00-04:00  182.544998  183.779999  177.220001  177.330002   \n",
       "\n",
       "                           volume_goog  dividends_goog  stock_splits_goog  \n",
       "Date                                                                       \n",
       "2024-10-24 00:00:00-04:00     12764400             0.0                0.0  \n",
       "2024-10-25 00:00:00-04:00     14566400             0.0                0.0  \n",
       "2024-10-28 00:00:00-04:00     20858300             0.0                0.0  \n",
       "2024-10-29 00:00:00-04:00     28916100             0.0                0.0  \n",
       "2024-10-30 00:00:00-04:00     42789018             0.0                0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinend_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>SARIMAX Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>   <td>1259</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>            <td>ARIMA(1, 0, 0)</td>  <th>  Log Likelihood     </th> <td>-3739.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 30 Oct 2024</td> <th>  AIC                </th> <td>7485.824</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>13:41:29</td>     <th>  BIC                </th> <td>7501.239</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sample:</th>                  <td>0</td>        <th>  HQIC               </th> <td>7491.617</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                      <td> - 1259</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>        <td>opg</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td>  280.0916</td> <td>   92.415</td> <td>    3.031</td> <td> 0.002</td> <td>   98.961</td> <td>  461.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L1</th>  <td>    0.9993</td> <td>    0.002</td> <td>  660.754</td> <td> 0.000</td> <td>    0.996</td> <td>    1.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sigma2</th> <td>   22.1553</td> <td>    0.649</td> <td>   34.162</td> <td> 0.000</td> <td>   20.884</td> <td>   23.426</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Ljung-Box (L1) (Q):</th>     <td>9.59</td> <th>  Jarque-Bera (JB):  </th> <td>173.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Q):</th>                <td>0.00</td> <th>  Prob(JB):          </th>  <td>0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Heteroskedasticity (H):</th> <td>2.05</td> <th>  Skew:              </th>  <td>-0.19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(H) (two-sided):</th>    <td>0.00</td> <th>  Kurtosis:          </th>  <td>4.78</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Covariance matrix calculated using the outer product of gradients (complex-step)."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}          &        y         & \\textbf{  No. Observations:  } &    1259     \\\\\n",
       "\\textbf{Model:}                  &  ARIMA(1, 0, 0)  & \\textbf{  Log Likelihood     } & -3739.912   \\\\\n",
       "\\textbf{Date:}                   & Wed, 30 Oct 2024 & \\textbf{  AIC                } &  7485.824   \\\\\n",
       "\\textbf{Time:}                   &     13:41:29     & \\textbf{  BIC                } &  7501.239   \\\\\n",
       "\\textbf{Sample:}                 &        0         & \\textbf{  HQIC               } &  7491.617   \\\\\n",
       "\\textbf{}                        &      - 1259      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}        &       opg        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}  &     280.0916  &       92.415     &     3.031  &         0.002        &       98.961    &      461.222     \\\\\n",
       "\\textbf{ar.L1}  &       0.9993  &        0.002     &   660.754  &         0.000        &        0.996    &        1.002     \\\\\n",
       "\\textbf{sigma2} &      22.1553  &        0.649     &    34.162  &         0.000        &       20.884    &       23.426     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Ljung-Box (L1) (Q):}     & 9.59 & \\textbf{  Jarque-Bera (JB):  } & 173.39  \\\\\n",
       "\\textbf{Prob(Q):}                & 0.00 & \\textbf{  Prob(JB):          } &  0.00   \\\\\n",
       "\\textbf{Heteroskedasticity (H):} & 2.05 & \\textbf{  Skew:              } & -0.19   \\\\\n",
       "\\textbf{Prob(H) (two-sided):}    & 0.00 & \\textbf{  Kurtosis:          } &  4.78   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{SARIMAX Results}\n",
       "\\end{center}\n",
       "\n",
       "Warnings: \\newline\n",
       " [1] Covariance matrix calculated using the outer product of gradients (complex-step)."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                               SARIMAX Results                                \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                 1259\n",
       "Model:                 ARIMA(1, 0, 0)   Log Likelihood               -3739.912\n",
       "Date:                Wed, 30 Oct 2024   AIC                           7485.824\n",
       "Time:                        13:41:29   BIC                           7501.239\n",
       "Sample:                             0   HQIC                          7491.617\n",
       "                               - 1259                                         \n",
       "Covariance Type:                  opg                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        280.0916     92.415      3.031      0.002      98.961     461.222\n",
       "ar.L1          0.9993      0.002    660.754      0.000       0.996       1.002\n",
       "sigma2        22.1553      0.649     34.162      0.000      20.884      23.426\n",
       "===================================================================================\n",
       "Ljung-Box (L1) (Q):                   9.59   Jarque-Bera (JB):               173.39\n",
       "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
       "Heteroskedasticity (H):               2.05   Skew:                            -0.19\n",
       "Prob(H) (two-sided):                  0.00   Kurtosis:                         4.78\n",
       "===================================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=ARIMA(joinend_data.loc[:, 'open_msft'].values, order=(1, 0,0))\n",
    "res=model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7485.824399478166)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (0, 0, 0) model\n",
      "training (0, 0, 1) model\n",
      "training (0, 0, 2) model\n",
      "training (0, 0, 3) model\n",
      "training (0, 0, 4) model\n",
      "training (0, 0, 5) model\n",
      "training (0, 0, 6) model\n",
      "training (0, 0, 7) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (0, 0, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (0, 0, 9) model\n",
      "training (0, 0, 10) model\n",
      "training (1, 0, 0) model\n",
      "training (1, 0, 1) model\n",
      "training (1, 0, 2) model\n",
      "training (1, 0, 3) model\n",
      "training (1, 0, 4) model\n",
      "training (1, 0, 5) model\n",
      "training (1, 0, 6) model\n",
      "training (1, 0, 7) model\n",
      "training (1, 0, 8) model\n",
      "training (1, 0, 9) model\n",
      "training (1, 0, 10) model\n",
      "training (2, 0, 0) model\n",
      "training (2, 0, 1) model\n",
      "training (2, 0, 2) model\n",
      "training (2, 0, 3) model\n",
      "training (2, 0, 4) model\n",
      "training (2, 0, 5) model\n",
      "training (2, 0, 6) model\n",
      "training (2, 0, 7) model\n",
      "training (2, 0, 8) model\n",
      "training (2, 0, 9) model\n",
      "training (2, 0, 10) model\n",
      "training (3, 0, 0) model\n",
      "training (3, 0, 1) model\n",
      "training (3, 0, 2) model\n",
      "training (3, 0, 3) model\n",
      "training (3, 0, 4) model\n",
      "training (3, 0, 5) model\n",
      "training (3, 0, 6) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (3, 0, 7) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (3, 0, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (3, 0, 9) model\n",
      "training (3, 0, 10) model\n",
      "training (4, 0, 0) model\n",
      "training (4, 0, 1) model\n",
      "training (4, 0, 2) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (4, 0, 3) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (4, 0, 4) model\n",
      "training (4, 0, 5) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (4, 0, 6) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (4, 0, 7) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (4, 0, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (4, 0, 9) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (4, 0, 10) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (5, 0, 0) model\n",
      "training (5, 0, 1) model\n",
      "training (5, 0, 2) model\n",
      "training (5, 0, 3) model\n",
      "training (5, 0, 4) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (5, 0, 5) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (5, 0, 6) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (5, 0, 7) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (5, 0, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (5, 0, 9) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (5, 0, 10) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (6, 0, 0) model\n",
      "training (6, 0, 1) model\n",
      "training (6, 0, 2) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (6, 0, 3) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (6, 0, 4) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (6, 0, 5) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (6, 0, 6) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (6, 0, 7) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (6, 0, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (6, 0, 9) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (6, 0, 10) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7, 0, 0) model\n",
      "training (7, 0, 1) model\n",
      "training (7, 0, 2) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7, 0, 3) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7, 0, 4) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7, 0, 5) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7, 0, 6) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7, 0, 7) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7, 0, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7, 0, 9) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7, 0, 10) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (8, 0, 0) model\n",
      "training (8, 0, 1) model\n",
      "training (8, 0, 2) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (8, 0, 3) model\n",
      "training (8, 0, 4) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (8, 0, 5) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (8, 0, 6) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (8, 0, 7) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (8, 0, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (8, 0, 9) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (8, 0, 10) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (9, 0, 0) model\n",
      "training (9, 0, 1) model\n",
      "training (9, 0, 2) model\n",
      "training (9, 0, 3) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (9, 0, 4) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (9, 0, 5) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (9, 0, 6) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (9, 0, 7) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (9, 0, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (9, 0, 9) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (9, 0, 10) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (10, 0, 0) model\n",
      "training (10, 0, 1) model\n",
      "training (10, 0, 2) model\n",
      "training (10, 0, 3) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (10, 0, 4) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (10, 0, 5) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (10, 0, 6) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (10, 0, 7) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (10, 0, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (10, 0, 9) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (10, 0, 10) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (0, 1, 0) model\n",
      "training (0, 1, 1) model\n",
      "training (0, 1, 2) model\n",
      "training (0, 1, 3) model\n",
      "training (0, 1, 4) model\n",
      "training (0, 1, 5) model\n",
      "training (0, 1, 6) model\n",
      "training (0, 1, 7) model\n",
      "training (0, 1, 8) model\n",
      "training (0, 1, 9) model\n",
      "training (0, 1, 10) model\n",
      "training (1, 1, 0) model\n",
      "training (1, 1, 1) model\n",
      "training (1, 1, 2) model\n",
      "training (1, 1, 3) model\n",
      "training (1, 1, 4) model\n",
      "training (1, 1, 5) model\n",
      "training (1, 1, 6) model\n",
      "training (1, 1, 7) model\n",
      "training (1, 1, 8) model\n",
      "training (1, 1, 9) model\n",
      "training (1, 1, 10) model\n",
      "training (2, 1, 0) model\n",
      "training (2, 1, 1) model\n",
      "training (2, 1, 2) model\n",
      "training (2, 1, 3) model\n",
      "training (2, 1, 4) model\n",
      "training (2, 1, 5) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (2, 1, 6) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (2, 1, 7) model\n",
      "training (2, 1, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (2, 1, 9) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (2, 1, 10) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (3, 1, 0) model\n",
      "training (3, 1, 1) model\n",
      "training (3, 1, 2) model\n",
      "training (3, 1, 3) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (3, 1, 4) model\n",
      "training (3, 1, 5) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (3, 1, 6) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (3, 1, 7) model\n",
      "training (3, 1, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (3, 1, 9) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (3, 1, 10) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (4, 1, 0) model\n",
      "training (4, 1, 1) model\n",
      "training (4, 1, 2) model\n",
      "training (4, 1, 3) model\n",
      "training (4, 1, 4) model\n",
      "training (4, 1, 5) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (4, 1, 6) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (4, 1, 7) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (4, 1, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (4, 1, 9) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (4, 1, 10) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (5, 1, 0) model\n",
      "training (5, 1, 1) model\n",
      "training (5, 1, 2) model\n",
      "training (5, 1, 3) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (5, 1, 4) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (5, 1, 5) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (5, 1, 6) model\n",
      "training (5, 1, 7) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (5, 1, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (5, 1, 9) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (5, 1, 10) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (6, 1, 0) model\n",
      "training (6, 1, 1) model\n",
      "training (6, 1, 2) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (6, 1, 3) model\n",
      "training (6, 1, 4) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (6, 1, 5) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (6, 1, 6) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (6, 1, 7) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (6, 1, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (6, 1, 9) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (6, 1, 10) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7, 1, 0) model\n",
      "training (7, 1, 1) model\n",
      "training (7, 1, 2) model\n",
      "training (7, 1, 3) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7, 1, 4) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7, 1, 5) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7, 1, 6) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7, 1, 7) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7, 1, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7, 1, 9) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (7, 1, 10) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (8, 1, 0) model\n",
      "training (8, 1, 1) model\n",
      "training (8, 1, 2) model\n",
      "training (8, 1, 3) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (8, 1, 4) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (8, 1, 5) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (8, 1, 6) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (8, 1, 7) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (8, 1, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (8, 1, 9) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (8, 1, 10) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (9, 1, 0) model\n",
      "training (9, 1, 1) model\n",
      "training (9, 1, 2) model\n",
      "training (9, 1, 3) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (9, 1, 4) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (9, 1, 5) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (9, 1, 6) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (9, 1, 7) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (9, 1, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (9, 1, 9) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (9, 1, 10) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (10, 1, 0) model\n",
      "training (10, 1, 1) model\n",
      "training (10, 1, 2) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (10, 1, 3) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (10, 1, 4) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (10, 1, 5) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (10, 1, 6) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (10, 1, 7) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (10, 1, 8) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (10, 1, 9) model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (10, 1, 10) model\n",
      "path save c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\models2024-10-30.plk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "from src.components.trainer import TrainerARIMA\n",
    "trainer=TrainerARIMA()\n",
    "model, report, best_order=trainer.init_trainer(joinend_data.loc[:, 'open_msft'].values, max_ar=10, max_i=1, max_ma=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<statsmodels.tsa.arima.model.ARIMA at 0x1d503e5eb70>,\n",
       " (0, 1, 4),\n",
       " <class 'statsmodels.iolib.summary.Summary'>\n",
       " \"\"\"\n",
       "                                SARIMAX Results                                \n",
       " ==============================================================================\n",
       " Dep. Variable:                      y   No. Observations:                 1259\n",
       " Model:                 ARIMA(0, 1, 4)   Log Likelihood               -3723.452\n",
       " Date:                Wed, 30 Oct 2024   AIC                           7456.903\n",
       " Time:                        14:05:20   BIC                           7482.590\n",
       " Sample:                             0   HQIC                          7466.557\n",
       "                                - 1259                                         \n",
       " Covariance Type:                  opg                                         \n",
       " ==============================================================================\n",
       "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
       " ------------------------------------------------------------------------------\n",
       " ma.L1         -0.0869      0.023     -3.702      0.000      -0.133      -0.041\n",
       " ma.L2         -0.0492      0.026     -1.884      0.060      -0.100       0.002\n",
       " ma.L3         -0.0175      0.026     -0.667      0.505      -0.069       0.034\n",
       " ma.L4          0.0776      0.027      2.902      0.004       0.025       0.130\n",
       " sigma2        21.7960      0.641     34.022      0.000      20.540      23.052\n",
       " ===================================================================================\n",
       " Ljung-Box (L1) (Q):                   0.03   Jarque-Bera (JB):               173.96\n",
       " Prob(Q):                              0.87   Prob(JB):                         0.00\n",
       " Heteroskedasticity (H):               2.02   Skew:                            -0.23\n",
       " Prob(H) (two-sided):                  0.00   Kurtosis:                         4.76\n",
       " ===================================================================================\n",
       " \n",
       " Warnings:\n",
       " [1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
       " \"\"\")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, best_order, report.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>SARIMAX Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>   <td>1259</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>            <td>ARIMA(0, 1, 4)</td>  <th>  Log Likelihood     </th> <td>-3723.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 30 Oct 2024</td> <th>  AIC                </th> <td>7456.903</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:05:28</td>     <th>  BIC                </th> <td>7482.590</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sample:</th>                  <td>0</td>        <th>  HQIC               </th> <td>7466.557</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                      <td> - 1259</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>        <td>opg</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ma.L1</th>  <td>   -0.0869</td> <td>    0.023</td> <td>   -3.702</td> <td> 0.000</td> <td>   -0.133</td> <td>   -0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ma.L2</th>  <td>   -0.0492</td> <td>    0.026</td> <td>   -1.884</td> <td> 0.060</td> <td>   -0.100</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ma.L3</th>  <td>   -0.0175</td> <td>    0.026</td> <td>   -0.667</td> <td> 0.505</td> <td>   -0.069</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ma.L4</th>  <td>    0.0776</td> <td>    0.027</td> <td>    2.902</td> <td> 0.004</td> <td>    0.025</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sigma2</th> <td>   21.7960</td> <td>    0.641</td> <td>   34.022</td> <td> 0.000</td> <td>   20.540</td> <td>   23.052</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Ljung-Box (L1) (Q):</th>     <td>0.03</td> <th>  Jarque-Bera (JB):  </th> <td>173.96</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Q):</th>                <td>0.87</td> <th>  Prob(JB):          </th>  <td>0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Heteroskedasticity (H):</th> <td>2.02</td> <th>  Skew:              </th>  <td>-0.23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(H) (two-sided):</th>    <td>0.00</td> <th>  Kurtosis:          </th>  <td>4.76</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Covariance matrix calculated using the outer product of gradients (complex-step)."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}          &        y         & \\textbf{  No. Observations:  } &    1259     \\\\\n",
       "\\textbf{Model:}                  &  ARIMA(0, 1, 4)  & \\textbf{  Log Likelihood     } & -3723.452   \\\\\n",
       "\\textbf{Date:}                   & Wed, 30 Oct 2024 & \\textbf{  AIC                } &  7456.903   \\\\\n",
       "\\textbf{Time:}                   &     14:05:28     & \\textbf{  BIC                } &  7482.590   \\\\\n",
       "\\textbf{Sample:}                 &        0         & \\textbf{  HQIC               } &  7466.557   \\\\\n",
       "\\textbf{}                        &      - 1259      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}        &       opg        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{ma.L1}  &      -0.0869  &        0.023     &    -3.702  &         0.000        &       -0.133    &       -0.041     \\\\\n",
       "\\textbf{ma.L2}  &      -0.0492  &        0.026     &    -1.884  &         0.060        &       -0.100    &        0.002     \\\\\n",
       "\\textbf{ma.L3}  &      -0.0175  &        0.026     &    -0.667  &         0.505        &       -0.069    &        0.034     \\\\\n",
       "\\textbf{ma.L4}  &       0.0776  &        0.027     &     2.902  &         0.004        &        0.025    &        0.130     \\\\\n",
       "\\textbf{sigma2} &      21.7960  &        0.641     &    34.022  &         0.000        &       20.540    &       23.052     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Ljung-Box (L1) (Q):}     & 0.03 & \\textbf{  Jarque-Bera (JB):  } & 173.96  \\\\\n",
       "\\textbf{Prob(Q):}                & 0.87 & \\textbf{  Prob(JB):          } &  0.00   \\\\\n",
       "\\textbf{Heteroskedasticity (H):} & 2.02 & \\textbf{  Skew:              } & -0.23   \\\\\n",
       "\\textbf{Prob(H) (two-sided):}    & 0.00 & \\textbf{  Kurtosis:          } &  4.76   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{SARIMAX Results}\n",
       "\\end{center}\n",
       "\n",
       "Warnings: \\newline\n",
       " [1] Covariance matrix calculated using the outer product of gradients (complex-step)."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                               SARIMAX Results                                \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                 1259\n",
       "Model:                 ARIMA(0, 1, 4)   Log Likelihood               -3723.452\n",
       "Date:                Wed, 30 Oct 2024   AIC                           7456.903\n",
       "Time:                        14:05:28   BIC                           7482.590\n",
       "Sample:                             0   HQIC                          7466.557\n",
       "                               - 1259                                         \n",
       "Covariance Type:                  opg                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "ma.L1         -0.0869      0.023     -3.702      0.000      -0.133      -0.041\n",
       "ma.L2         -0.0492      0.026     -1.884      0.060      -0.100       0.002\n",
       "ma.L3         -0.0175      0.026     -0.667      0.505      -0.069       0.034\n",
       "ma.L4          0.0776      0.027      2.902      0.004       0.025       0.130\n",
       "sigma2        21.7960      0.641     34.022      0.000      20.540      23.052\n",
       "===================================================================================\n",
       "Ljung-Box (L1) (Q):                   0.03   Jarque-Bera (JB):               173.96\n",
       "Prob(Q):                              0.87   Prob(JB):                         0.00\n",
       "Heteroskedasticity (H):               2.02   Skew:                            -0.23\n",
       "Prob(H) (two-sided):                  0.00   Kurtosis:                         4.76\n",
       "===================================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 30\n",
    "batch_size = 128\n",
    "shuffle_buffer_size = 1000\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(joinend_data['open_msft'])\n",
    "train_ds=train_ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "train_ds = train_ds.flat_map(lambda window: window.batch(window_size + 1))\n",
    "train_ds = train_ds.map(lambda window: (window[:-1], window[-1]))\n",
    "train_ds = train_ds.shuffle(shuffle_buffer_size)\n",
    "train_ds = train_ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,792</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,935</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m33,792\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             â”‚         \u001b[38;5;34m1,935\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m16\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,743</span> (139.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35,743\u001b[0m (139.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,743</span> (139.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,743\u001b[0m (139.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64), input_shape=[window_size, 1]),\n",
    "  tf.keras.layers.Dense(15, activation = 'relu'),\n",
    "  tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 17.3457 - learning_rate: 1.0000e-08\n",
      "Epoch 2/200\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32mâ”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 11.9038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.6569 - learning_rate: 1.1220e-08\n",
      "Epoch 3/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 17.4006 - learning_rate: 1.2589e-08\n",
      "Epoch 4/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 18.1672 - learning_rate: 1.4125e-08\n",
      "Epoch 5/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 17.4631 - learning_rate: 1.5849e-08\n",
      "Epoch 6/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 17.7155 - learning_rate: 1.7783e-08\n",
      "Epoch 7/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 17.6695 - learning_rate: 1.9953e-08\n",
      "Epoch 8/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 17.3969 - learning_rate: 2.2387e-08\n",
      "Epoch 9/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 17.7433 - learning_rate: 2.5119e-08\n",
      "Epoch 10/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 17.4096 - learning_rate: 2.8184e-08\n",
      "Epoch 11/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 17.5482 - learning_rate: 3.1623e-08\n",
      "Epoch 12/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 17.6037 - learning_rate: 3.5481e-08\n",
      "Epoch 13/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 18.0220 - learning_rate: 3.9811e-08\n",
      "Epoch 14/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17.5634 - learning_rate: 4.4668e-08\n",
      "Epoch 15/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17.5853 - learning_rate: 5.0119e-08\n",
      "Epoch 16/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.2126 - learning_rate: 5.6234e-08\n",
      "Epoch 17/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 17.4244 - learning_rate: 6.3096e-08\n",
      "Epoch 18/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.6579 - learning_rate: 7.0795e-08\n",
      "Epoch 19/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.3482 - learning_rate: 7.9433e-08\n",
      "Epoch 20/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.4276 - learning_rate: 8.9125e-08\n",
      "Epoch 21/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 17.8906 - learning_rate: 1.0000e-07\n",
      "Epoch 22/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 17.6465 - learning_rate: 1.1220e-07\n",
      "Epoch 23/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 16.9850 - learning_rate: 1.2589e-07\n",
      "Epoch 24/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.3814 - learning_rate: 1.4125e-07\n",
      "Epoch 25/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.2303 - learning_rate: 1.5849e-07\n",
      "Epoch 26/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 17.3271 - learning_rate: 1.7783e-07\n",
      "Epoch 27/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.3592 - learning_rate: 1.9953e-07\n",
      "Epoch 28/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 18.4091 - learning_rate: 2.2387e-07\n",
      "Epoch 29/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.2977 - learning_rate: 2.5119e-07\n",
      "Epoch 30/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 18.3489 - learning_rate: 2.8184e-07\n",
      "Epoch 31/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 18.1347 - learning_rate: 3.1623e-07\n",
      "Epoch 32/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.5336 - learning_rate: 3.5481e-07\n",
      "Epoch 33/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.9370 - learning_rate: 3.9811e-07\n",
      "Epoch 34/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16.8992 - learning_rate: 4.4668e-07\n",
      "Epoch 35/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.5402 - learning_rate: 5.0119e-07\n",
      "Epoch 36/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 17.6769 - learning_rate: 5.6234e-07\n",
      "Epoch 37/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.8265 - learning_rate: 6.3096e-07\n",
      "Epoch 38/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 17.2729 - learning_rate: 7.0795e-07\n",
      "Epoch 39/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.2564 - learning_rate: 7.9433e-07\n",
      "Epoch 40/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17.6923 - learning_rate: 8.9125e-07\n",
      "Epoch 41/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.9177 - learning_rate: 1.0000e-06\n",
      "Epoch 42/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17.8221 - learning_rate: 1.1220e-06\n",
      "Epoch 43/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.5750 - learning_rate: 1.2589e-06\n",
      "Epoch 44/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 17.5993 - learning_rate: 1.4125e-06\n",
      "Epoch 45/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 17.0790 - learning_rate: 1.5849e-06\n",
      "Epoch 46/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 18.2326 - learning_rate: 1.7783e-06\n",
      "Epoch 47/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17.0710 - learning_rate: 1.9953e-06\n",
      "Epoch 48/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.5717 - learning_rate: 2.2387e-06\n",
      "Epoch 49/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.7130 - learning_rate: 2.5119e-06\n",
      "Epoch 50/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 17.8950 - learning_rate: 2.8184e-06\n",
      "Epoch 51/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.7213 - learning_rate: 3.1623e-06\n",
      "Epoch 52/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.2091 - learning_rate: 3.5481e-06\n",
      "Epoch 53/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17.4622 - learning_rate: 3.9811e-06\n",
      "Epoch 54/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16.9347 - learning_rate: 4.4668e-06\n",
      "Epoch 55/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16.9786 - learning_rate: 5.0119e-06\n",
      "Epoch 56/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.1053 - learning_rate: 5.6234e-06\n",
      "Epoch 57/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.7148 - learning_rate: 6.3096e-06\n",
      "Epoch 58/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.1214 - learning_rate: 7.0795e-06\n",
      "Epoch 59/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 18.0866 - learning_rate: 7.9433e-06\n",
      "Epoch 60/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 17.3948 - learning_rate: 8.9125e-06\n",
      "Epoch 61/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.6303 - learning_rate: 1.0000e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.2661 - learning_rate: 1.1220e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.1011 - learning_rate: 1.2589e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 16.9790 - learning_rate: 1.4125e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16.8489 - learning_rate: 1.5849e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17.4693 - learning_rate: 1.7783e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 16.6996 - learning_rate: 1.9953e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.1670 - learning_rate: 2.2387e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.4294 - learning_rate: 2.5119e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.6925 - learning_rate: 2.8184e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.2546 - learning_rate: 3.1623e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.4708 - learning_rate: 3.5481e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.1682 - learning_rate: 3.9811e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16.9925 - learning_rate: 4.4668e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 16.8993 - learning_rate: 5.0119e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 16.8097 - learning_rate: 5.6234e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16.5572 - learning_rate: 6.3096e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 16.9177 - learning_rate: 7.0795e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 17.3336 - learning_rate: 7.9433e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 16.9183 - learning_rate: 8.9125e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16.7329 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 15.7915 - learning_rate: 1.1220e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16.3637 - learning_rate: 1.2589e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 16.3633 - learning_rate: 1.4125e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 16.6972 - learning_rate: 1.5849e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 15.9281 - learning_rate: 1.7783e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 15.6159 - learning_rate: 1.9953e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 15.1614 - learning_rate: 2.2387e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 15.5872 - learning_rate: 2.5119e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 14.4442 - learning_rate: 2.8184e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 14.5210 - learning_rate: 3.1623e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 14.6445 - learning_rate: 3.5481e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 14.2782 - learning_rate: 3.9811e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 13.9985 - learning_rate: 4.4668e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 13.9822 - learning_rate: 5.0119e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.6173 - learning_rate: 5.6234e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 14.5613 - learning_rate: 6.3096e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 15.0393 - learning_rate: 7.0795e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 15.1139 - learning_rate: 7.9433e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 14.9201 - learning_rate: 8.9125e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.7945 - learning_rate: 0.0010\n",
      "Epoch 102/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 15.5594 - learning_rate: 0.0011\n",
      "Epoch 103/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 15.5716 - learning_rate: 0.0013\n",
      "Epoch 104/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.5597 - learning_rate: 0.0014\n",
      "Epoch 105/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 20.7611 - learning_rate: 0.0016\n",
      "Epoch 106/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 18.4967 - learning_rate: 0.0018\n",
      "Epoch 107/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 19.6922 - learning_rate: 0.0020\n",
      "Epoch 108/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 19.6711 - learning_rate: 0.0022\n",
      "Epoch 109/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 24.0931 - learning_rate: 0.0025\n",
      "Epoch 110/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 24.9447 - learning_rate: 0.0028\n",
      "Epoch 111/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 37.3162 - learning_rate: 0.0032\n",
      "Epoch 112/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 31.6076 - learning_rate: 0.0035\n",
      "Epoch 113/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 28.8841 - learning_rate: 0.0040\n",
      "Epoch 114/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 43.4413 - learning_rate: 0.0045\n",
      "Epoch 115/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 31.3798 - learning_rate: 0.0050\n",
      "Epoch 116/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 38.4200 - learning_rate: 0.0056\n",
      "Epoch 117/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 38.8189 - learning_rate: 0.0063\n",
      "Epoch 118/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 40.2501 - learning_rate: 0.0071\n",
      "Epoch 119/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 39.4683 - learning_rate: 0.0079\n",
      "Epoch 120/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 41.5663 - learning_rate: 0.0089\n",
      "Epoch 121/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 54.2216 - learning_rate: 0.0100\n",
      "Epoch 122/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 52.5577 - learning_rate: 0.0112\n",
      "Epoch 123/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 42.9234 - learning_rate: 0.0126\n",
      "Epoch 124/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 45.2769 - learning_rate: 0.0141\n",
      "Epoch 125/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 48.5198 - learning_rate: 0.0158\n",
      "Epoch 126/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 46.6671 - learning_rate: 0.0178\n",
      "Epoch 127/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 55.5800 - learning_rate: 0.0200\n",
      "Epoch 128/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 55.9873 - learning_rate: 0.0224\n",
      "Epoch 129/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 58.9332 - learning_rate: 0.0251\n",
      "Epoch 130/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 65.7196 - learning_rate: 0.0282\n",
      "Epoch 131/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 60.0304 - learning_rate: 0.0316\n",
      "Epoch 132/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 62.2783 - learning_rate: 0.0355\n",
      "Epoch 133/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 63.1093 - learning_rate: 0.0398\n",
      "Epoch 134/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 59.9402 - learning_rate: 0.0447\n",
      "Epoch 135/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 64.2426 - learning_rate: 0.0501\n",
      "Epoch 136/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 62.6097 - learning_rate: 0.0562\n",
      "Epoch 137/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 68.5974 - learning_rate: 0.0631\n",
      "Epoch 138/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 64.8615 - learning_rate: 0.0708\n",
      "Epoch 139/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 66.0601 - learning_rate: 0.0794\n",
      "Epoch 140/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 66.7681 - learning_rate: 0.0891\n",
      "Epoch 141/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 63.5974 - learning_rate: 0.1000\n",
      "Epoch 142/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 64.0207 - learning_rate: 0.1122\n",
      "Epoch 143/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 64.8577 - learning_rate: 0.1259\n",
      "Epoch 144/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 66.7741 - learning_rate: 0.1413\n",
      "Epoch 145/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 68.4925 - learning_rate: 0.1585\n",
      "Epoch 146/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 67.1016 - learning_rate: 0.1778\n",
      "Epoch 147/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 66.1902 - learning_rate: 0.1995\n",
      "Epoch 148/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 83.7968 - learning_rate: 0.2239\n",
      "Epoch 149/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 68.1717 - learning_rate: 0.2512\n",
      "Epoch 150/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 84.0238 - learning_rate: 0.2818\n",
      "Epoch 151/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 79.5084 - learning_rate: 0.3162\n",
      "Epoch 152/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 87.3914 - learning_rate: 0.3548\n",
      "Epoch 153/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 84.7890 - learning_rate: 0.3981\n",
      "Epoch 154/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 93.0701 - learning_rate: 0.4467\n",
      "Epoch 155/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 83.4462 - learning_rate: 0.5012\n",
      "Epoch 156/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 119.7054 - learning_rate: 0.5623\n",
      "Epoch 157/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 88.8232 - learning_rate: 0.6310\n",
      "Epoch 158/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 99.3372 - learning_rate: 0.7079\n",
      "Epoch 159/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 102.8021 - learning_rate: 0.7943\n",
      "Epoch 160/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 91.9707 - learning_rate: 0.8913\n",
      "Epoch 161/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 86.6617 - learning_rate: 1.0000\n",
      "Epoch 162/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 117.5830 - learning_rate: 1.1220\n",
      "Epoch 163/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 105.0921 - learning_rate: 1.2589\n",
      "Epoch 164/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 110.1967 - learning_rate: 1.4125\n",
      "Epoch 165/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 129.4174 - learning_rate: 1.5849\n",
      "Epoch 166/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 142.6426 - learning_rate: 1.7783\n",
      "Epoch 167/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 126.5099 - learning_rate: 1.9953\n",
      "Epoch 168/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 143.1530 - learning_rate: 2.2387\n",
      "Epoch 169/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 219.9869 - learning_rate: 2.5119\n",
      "Epoch 170/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 185.0484 - learning_rate: 2.8184\n",
      "Epoch 171/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 185.4622 - learning_rate: 3.1623\n",
      "Epoch 172/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 150.9653 - learning_rate: 3.5481\n",
      "Epoch 173/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 115.0118 - learning_rate: 3.9811\n",
      "Epoch 174/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 87.0030 - learning_rate: 4.4668\n",
      "Epoch 175/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 67.2924 - learning_rate: 5.0119\n",
      "Epoch 176/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 61.4540 - learning_rate: 5.6234\n",
      "Epoch 177/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 62.4194 - learning_rate: 6.3096\n",
      "Epoch 178/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 61.6070 - learning_rate: 7.0795\n",
      "Epoch 179/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 61.9130 - learning_rate: 7.9433\n",
      "Epoch 180/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 62.3644 - learning_rate: 8.9125\n",
      "Epoch 181/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 62.6157 - learning_rate: 10.0000\n",
      "Epoch 182/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 61.6286 - learning_rate: 11.2202\n",
      "Epoch 183/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 61.1859 - learning_rate: 12.5893\n",
      "Epoch 184/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 61.8894 - learning_rate: 14.1254\n",
      "Epoch 185/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 62.7244 - learning_rate: 15.8489\n",
      "Epoch 186/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 64.1956 - learning_rate: 17.7828\n",
      "Epoch 187/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 61.7775 - learning_rate: 19.9526\n",
      "Epoch 188/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 62.6270 - learning_rate: 22.3872\n",
      "Epoch 189/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 61.5635 - learning_rate: 25.1189\n",
      "Epoch 190/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 65.8663 - learning_rate: 28.1838\n",
      "Epoch 191/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 66.5984 - learning_rate: 31.6228\n",
      "Epoch 192/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 66.4974 - learning_rate: 35.4813\n",
      "Epoch 193/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 62.8994 - learning_rate: 39.8107\n",
      "Epoch 194/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 69.7834 - learning_rate: 44.6684\n",
      "Epoch 195/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 64.4735 - learning_rate: 50.1187\n",
      "Epoch 196/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 66.3928 - learning_rate: 56.2341\n",
      "Epoch 197/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 68.4704 - learning_rate: 63.0957\n",
      "Epoch 198/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 65.8300 - learning_rate: 70.7946\n",
      "Epoch 199/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 68.6736 - learning_rate: 79.4328\n",
      "Epoch 200/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 68.1552 - learning_rate: 89.1251\n"
     ]
    }
   ],
   "source": [
    "# Set the learning rate scheduler\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-3)\n",
    "\n",
    "# Set the training parameters\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_ds, epochs=200, callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select learning rate\n",
    "lrs=1e-8 * 10**(np.arange(200) / 20)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.semilogx(lrs[:120], history.history['loss'][:120])\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components.data_ingestion import DataIngestion\n",
    "from src.components.transformer import DataTransformer\n",
    "from src.components.trainer import TrainerARIMA\n",
    "from src.components.trainer_rnn import TrainerNeuralNetwork\n",
    "\n",
    "from src.config import TICKERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingesition=DataIngestion()\n",
    "raw_path,train_path,test_path=data_ingesition.init_data_ingestion(TICKERS, '5y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_data=DataTransformer()\n",
    "train_df, test_df=transformer_data.init_transformer(rnn_model=False,\n",
    "                                                    ticker='open_MSFT',\n",
    "                                                    train_path=train_path,\n",
    "                                                    test_path=test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training (0, 0, 0) model\n",
      "training (0, 0, 1) model\n",
      "training (0, 0, 2) model\n",
      "training (1, 0, 0) model\n",
      "training (1, 0, 1) model\n",
      "training (1, 0, 2) model\n",
      "training (2, 0, 0) model\n",
      "training (2, 0, 1) model\n",
      "training (2, 0, 2) model\n",
      "training (0, 1, 0) model\n",
      "training (0, 1, 1) model\n",
      "training (0, 1, 2) model\n",
      "training (1, 1, 0) model\n",
      "training (1, 1, 1) model\n",
      "training (1, 1, 2) model\n",
      "training (2, 1, 0) model\n",
      "training (2, 1, 1) model\n",
      "training (2, 1, 2) model\n",
      "path save c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\models2024-10-30.plk\n"
     ]
    }
   ],
   "source": [
    "trainer_arima=TrainerARIMA()\n",
    "arima_model_path=trainer_arima.init_trainer(train_dataset=train_df, max_ar=2, max_i=1, max_ma=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
