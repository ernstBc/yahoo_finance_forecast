{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'address1': 'One Microsoft Way',\n",
       " 'city': 'Redmond',\n",
       " 'state': 'WA',\n",
       " 'zip': '98052-6399',\n",
       " 'country': 'United States',\n",
       " 'phone': '425 882 8080',\n",
       " 'website': 'https://www.microsoft.com',\n",
       " 'industry': 'Software - Infrastructure',\n",
       " 'industryKey': 'software-infrastructure',\n",
       " 'industryDisp': 'Software - Infrastructure',\n",
       " 'sector': 'Technology',\n",
       " 'sectorKey': 'technology',\n",
       " 'sectorDisp': 'Technology',\n",
       " 'longBusinessSummary': 'Microsoft Corporation develops and supports software, services, devices and solutions worldwide. The Productivity and Business Processes segment offers office, exchange, SharePoint, Microsoft Teams, office 365 Security and Compliance, Microsoft viva, and Microsoft 365 copilot; and office consumer services, such as Microsoft 365 consumer subscriptions, Office licensed on-premises, and other office services. This segment also provides LinkedIn; and dynamics business solutions, including Dynamics 365, a set of intelligent, cloud-based applications across ERP, CRM, power apps, and power automate; and on-premises ERP and CRM applications. The Intelligent Cloud segment offers server products and cloud services, such as azure and other cloud services; SQL and windows server, visual studio, system center, and related client access licenses, as well as nuance and GitHub; and enterprise services including enterprise support services, industry solutions, and nuance professional services. The More Personal Computing segment offers Windows, including windows OEM licensing and other non-volume licensing of the Windows operating system; Windows commercial comprising volume licensing of the Windows operating system, windows cloud services, and other Windows commercial offerings; patent licensing; and windows Internet of Things; and devices, such as surface, HoloLens, and PC accessories. Additionally, this segment provides gaming, which includes Xbox hardware and content, and first- and third-party content; Xbox game pass and other subscriptions, cloud gaming, advertising, third-party disc royalties, and other cloud services; and search and news advertising, which includes Bing, Microsoft News and Edge, and third-party affiliates. The company sells its products through OEMs, distributors, and resellers; and directly through digital marketplaces, online, and retail stores. The company was founded in 1975 and is headquartered in Redmond, Washington.',\n",
       " 'fullTimeEmployees': 228000,\n",
       " 'companyOfficers': [{'maxAge': 1,\n",
       "   'name': 'Mr. Satya  Nadella',\n",
       "   'age': 56,\n",
       "   'title': 'Chairman & CEO',\n",
       "   'yearBorn': 1967,\n",
       "   'fiscalYear': 2024,\n",
       "   'totalPay': 7869791,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Mr. Bradford L. Smith LCA',\n",
       "   'age': 64,\n",
       "   'title': 'President & Vice Chairman',\n",
       "   'yearBorn': 1959,\n",
       "   'fiscalYear': 2024,\n",
       "   'totalPay': 4755618,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Ms. Amy E. Hood',\n",
       "   'age': 51,\n",
       "   'title': 'Executive VP & CFO',\n",
       "   'yearBorn': 1972,\n",
       "   'fiscalYear': 2024,\n",
       "   'totalPay': 4704250,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Mr. Judson B. Althoff',\n",
       "   'age': 50,\n",
       "   'title': 'Executive VP & Chief Commercial Officer',\n",
       "   'yearBorn': 1973,\n",
       "   'fiscalYear': 2024,\n",
       "   'totalPay': 4534974,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Mr. Christopher David Young',\n",
       "   'age': 51,\n",
       "   'title': 'Executive Vice President of Business Development, Strategy & Ventures',\n",
       "   'yearBorn': 1972,\n",
       "   'fiscalYear': 2024,\n",
       "   'totalPay': 2993772,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Ms. Carolina  Dybeck Happe',\n",
       "   'age': 51,\n",
       "   'title': 'Executive VP & COO',\n",
       "   'yearBorn': 1972,\n",
       "   'fiscalYear': 2024,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Ms. Alice L. Jolla',\n",
       "   'age': 57,\n",
       "   'title': 'Corporate VP & Chief Accounting Officer',\n",
       "   'yearBorn': 1966,\n",
       "   'fiscalYear': 2024,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Mr. James Kevin Scott',\n",
       "   'age': 51,\n",
       "   'title': 'Executive VP of AI & CTO',\n",
       "   'yearBorn': 1972,\n",
       "   'fiscalYear': 2024,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Brett  Iversen',\n",
       "   'title': 'Vice President of Investor Relations',\n",
       "   'fiscalYear': 2024,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0},\n",
       "  {'maxAge': 1,\n",
       "   'name': 'Mr. Hossein  Nowbar',\n",
       "   'title': 'Chief Legal Officer',\n",
       "   'fiscalYear': 2024,\n",
       "   'exercisedValue': 0,\n",
       "   'unexercisedValue': 0}],\n",
       " 'auditRisk': 3,\n",
       " 'boardRisk': 5,\n",
       " 'compensationRisk': 2,\n",
       " 'shareHolderRightsRisk': 2,\n",
       " 'overallRisk': 1,\n",
       " 'governanceEpochDate': 1730073600,\n",
       " 'compensationAsOfEpochDate': 1735603200,\n",
       " 'irWebsite': 'http://www.microsoft.com/investor/default.aspx',\n",
       " 'maxAge': 86400,\n",
       " 'priceHint': 2,\n",
       " 'previousClose': 432.53,\n",
       " 'open': 415.96,\n",
       " 'dayLow': 406.3,\n",
       " 'dayHigh': 416.065,\n",
       " 'regularMarketPreviousClose': 432.53,\n",
       " 'regularMarketOpen': 415.96,\n",
       " 'regularMarketDayLow': 406.3,\n",
       " 'regularMarketDayHigh': 416.065,\n",
       " 'dividendRate': 3.32,\n",
       " 'dividendYield': 0.0077,\n",
       " 'exDividendDate': 1732147200,\n",
       " 'payoutRatio': 0.2477,\n",
       " 'fiveYearAvgDividendYield': 0.89,\n",
       " 'trailingPE': 33.61561,\n",
       " 'forwardPE': 26.7643,\n",
       " 'volume': 40475966,\n",
       " 'regularMarketVolume': 40475966,\n",
       " 'averageVolume': 18978912,\n",
       " 'averageVolume10days': 18310000,\n",
       " 'averageDailyVolume10Day': 18310000,\n",
       " 'bid': 405.0,\n",
       " 'ask': 408.97,\n",
       " 'bidSize': 200,\n",
       " 'askSize': 600,\n",
       " 'marketCap': 3026628116480,\n",
       " 'fiftyTwoWeekLow': 344.77,\n",
       " 'fiftyTwoWeekHigh': 468.35,\n",
       " 'priceToSalesTrailing12Months': 11.906952,\n",
       " 'fiftyDayAverage': 421.1468,\n",
       " 'twoHundredDayAverage': 420.6614,\n",
       " 'trailingAnnualDividendRate': 3.0,\n",
       " 'trailingAnnualDividendYield': 0.006935935,\n",
       " 'currency': 'USD',\n",
       " 'enterpriseValue': 3198859083776,\n",
       " 'profitMargins': 0.35608003,\n",
       " 'floatShares': 7424471943,\n",
       " 'sharesOutstanding': 7434440192,\n",
       " 'sharesShort': 60313798,\n",
       " 'sharesShortPriorMonth': 67500308,\n",
       " 'sharesShortPreviousMonthDate': 1726185600,\n",
       " 'dateShortInterest': 1728950400,\n",
       " 'sharesPercentSharesOut': 0.0081,\n",
       " 'heldPercentInsiders': 0.00055,\n",
       " 'heldPercentInstitutions': 0.73727,\n",
       " 'shortRatio': 3.26,\n",
       " 'shortPercentOfFloat': 0.0081,\n",
       " 'impliedSharesOutstanding': 7434880000,\n",
       " 'bookValue': 38.693,\n",
       " 'priceToBook': 10.520895,\n",
       " 'lastFiscalYearEnd': 1719705600,\n",
       " 'nextFiscalYearEnd': 1751241600,\n",
       " 'mostRecentQuarter': 1727654400,\n",
       " 'earningsQuarterlyGrowth': 0.107,\n",
       " 'netIncomeToCommon': 90511998976,\n",
       " 'trailingEps': 12.11,\n",
       " 'forwardEps': 15.21,\n",
       " 'pegRatio': 2.21,\n",
       " 'lastSplitFactor': '2:1',\n",
       " 'lastSplitDate': 1045526400,\n",
       " 'enterpriseToRevenue': 12.585,\n",
       " 'enterpriseToEbitda': 23.426,\n",
       " '52WeekChange': 0.24176049,\n",
       " 'SandP52WeekChange': 0.3464489,\n",
       " 'lastDividendValue': 0.75,\n",
       " 'lastDividendDate': 1723680000,\n",
       " 'exchange': 'NMS',\n",
       " 'quoteType': 'EQUITY',\n",
       " 'symbol': 'MSFT',\n",
       " 'underlyingSymbol': 'MSFT',\n",
       " 'shortName': 'Microsoft Corporation',\n",
       " 'longName': 'Microsoft Corporation',\n",
       " 'firstTradeDateEpochUtc': 511108200,\n",
       " 'timeZoneFullName': 'America/New_York',\n",
       " 'timeZoneShortName': 'EDT',\n",
       " 'uuid': 'b004b3ec-de24-385e-b2c1-923f10d3fb62',\n",
       " 'messageBoardId': 'finmb_21835',\n",
       " 'gmtOffSetMilliseconds': -14400000,\n",
       " 'currentPrice': 407.085,\n",
       " 'targetHighPrice': 600.0,\n",
       " 'targetLowPrice': 440.0,\n",
       " 'targetMeanPrice': 495.89,\n",
       " 'targetMedianPrice': 500.0,\n",
       " 'recommendationMean': 1.7,\n",
       " 'recommendationKey': 'buy',\n",
       " 'numberOfAnalystOpinions': 46,\n",
       " 'totalCash': 78427996160,\n",
       " 'totalCashPerShare': 10.549,\n",
       " 'ebitda': 136551997440,\n",
       " 'totalDebt': 61477998592,\n",
       " 'quickRatio': 1.064,\n",
       " 'currentRatio': 1.301,\n",
       " 'totalRevenue': 254189993984,\n",
       " 'debtToEquity': 21.367,\n",
       " 'revenuePerShare': 34.202,\n",
       " 'returnOnAssets': 0.14592,\n",
       " 'returnOnEquity': 0.35604,\n",
       " 'freeCashflow': 67502874624,\n",
       " 'operatingCashflow': 122144997376,\n",
       " 'earningsGrowth': 0.104,\n",
       " 'revenueGrowth': 0.16,\n",
       " 'grossMargins': 0.69348997,\n",
       " 'ebitdaMargins': 0.53720003,\n",
       " 'operatingMargins': 0.46583998,\n",
       " 'financialCurrency': 'USD',\n",
       " 'trailingPegRatio': 2.3492}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft=yf.Ticker('MSFT')\n",
    "msft.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-04-30 00:00:00-04:00</th>\n",
       "      <td>400.046081</td>\n",
       "      <td>400.713685</td>\n",
       "      <td>387.770412</td>\n",
       "      <td>387.929810</td>\n",
       "      <td>28781400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01 00:00:00-04:00</th>\n",
       "      <td>391.197985</td>\n",
       "      <td>400.275238</td>\n",
       "      <td>388.906269</td>\n",
       "      <td>393.519623</td>\n",
       "      <td>23562500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-02 00:00:00-04:00</th>\n",
       "      <td>396.229834</td>\n",
       "      <td>398.491659</td>\n",
       "      <td>393.230650</td>\n",
       "      <td>396.409180</td>\n",
       "      <td>17709400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-03 00:00:00-04:00</th>\n",
       "      <td>400.833227</td>\n",
       "      <td>405.685707</td>\n",
       "      <td>400.414724</td>\n",
       "      <td>405.197479</td>\n",
       "      <td>17446700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-06 00:00:00-04:00</th>\n",
       "      <td>407.289957</td>\n",
       "      <td>412.441346</td>\n",
       "      <td>404.908537</td>\n",
       "      <td>412.052765</td>\n",
       "      <td>16996600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-25 00:00:00-04:00</th>\n",
       "      <td>426.760010</td>\n",
       "      <td>432.519989</td>\n",
       "      <td>426.570007</td>\n",
       "      <td>428.149994</td>\n",
       "      <td>16899100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-28 00:00:00-04:00</th>\n",
       "      <td>431.660004</td>\n",
       "      <td>431.940002</td>\n",
       "      <td>426.299988</td>\n",
       "      <td>426.589996</td>\n",
       "      <td>14882400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-29 00:00:00-04:00</th>\n",
       "      <td>428.000000</td>\n",
       "      <td>433.170013</td>\n",
       "      <td>425.799988</td>\n",
       "      <td>431.950012</td>\n",
       "      <td>17644100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-30 00:00:00-04:00</th>\n",
       "      <td>437.440002</td>\n",
       "      <td>438.500000</td>\n",
       "      <td>432.100006</td>\n",
       "      <td>432.529999</td>\n",
       "      <td>29749100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-31 00:00:00-04:00</th>\n",
       "      <td>415.959991</td>\n",
       "      <td>416.065002</td>\n",
       "      <td>406.299988</td>\n",
       "      <td>407.040009</td>\n",
       "      <td>40494003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2024-04-30 00:00:00-04:00  400.046081  400.713685  387.770412  387.929810   \n",
       "2024-05-01 00:00:00-04:00  391.197985  400.275238  388.906269  393.519623   \n",
       "2024-05-02 00:00:00-04:00  396.229834  398.491659  393.230650  396.409180   \n",
       "2024-05-03 00:00:00-04:00  400.833227  405.685707  400.414724  405.197479   \n",
       "2024-05-06 00:00:00-04:00  407.289957  412.441346  404.908537  412.052765   \n",
       "...                               ...         ...         ...         ...   \n",
       "2024-10-25 00:00:00-04:00  426.760010  432.519989  426.570007  428.149994   \n",
       "2024-10-28 00:00:00-04:00  431.660004  431.940002  426.299988  426.589996   \n",
       "2024-10-29 00:00:00-04:00  428.000000  433.170013  425.799988  431.950012   \n",
       "2024-10-30 00:00:00-04:00  437.440002  438.500000  432.100006  432.529999   \n",
       "2024-10-31 00:00:00-04:00  415.959991  416.065002  406.299988  407.040009   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  \n",
       "Date                                                          \n",
       "2024-04-30 00:00:00-04:00  28781400        0.0           0.0  \n",
       "2024-05-01 00:00:00-04:00  23562500        0.0           0.0  \n",
       "2024-05-02 00:00:00-04:00  17709400        0.0           0.0  \n",
       "2024-05-03 00:00:00-04:00  17446700        0.0           0.0  \n",
       "2024-05-06 00:00:00-04:00  16996600        0.0           0.0  \n",
       "...                             ...        ...           ...  \n",
       "2024-10-25 00:00:00-04:00  16899100        0.0           0.0  \n",
       "2024-10-28 00:00:00-04:00  14882400        0.0           0.0  \n",
       "2024-10-29 00:00:00-04:00  17644100        0.0           0.0  \n",
       "2024-10-30 00:00:00-04:00  29749100        0.0           0.0  \n",
       "2024-10-31 00:00:00-04:00  40494003        0.0           0.0  \n",
       "\n",
       "[129 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = msft.history(period=\"6mo\")\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Date'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGjCAYAAAAGku4DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB+A0lEQVR4nO3dd3yUVfY/8M8zJTNpk94JhA4hCRBQCItIkxYsK7Y1grqILbqArqu4/tYufNW1oLgiirqKomJnEUFpChFiMBBCD4GE9D6pU+/vj5nnyQxpM8mUZybn/XrlJZl6c01mzpx77rkcY4yBEEIIIUREJO4eACGEEELIpShAIYQQQojoUIBCCCGEENGhAIUQQgghokMBCiGEEEJEhwIUQgghhIgOBSiEEEIIER0KUAghhBAiOhSgEEIIIUR0KEAhhBBCiOjI+nLnNWvWYNWqVVi+fDlee+01nD9/HoMHD+70tp9//jluvPFGAEBRURHuu+8+7N69GwEBAbj99tuxevVqyGS2DcdoNKK0tBSBgYHgOK4vPwIhhBBCXIQxhsbGRsTGxkIi6T5H0usAJTs7G+vXr0dKSopwWXx8PMrKyqxu98477+Cll17C/PnzAQAGgwHp6emIjo7GgQMHUFZWhiVLlkAul+OFF16w6blLS0sRHx/f26ETQgghxI2Ki4sxYMCAbm/D9eawwKamJqSmpuKtt97Cc889h3HjxuG1117r9Lbjx49Hamoq3nvvPQDADz/8gIULF6K0tBRRUVEAgLfffhuPPvooqqqq4OPj0+PzNzQ0IDg4GMXFxVCpVPYOnxBCCCFuoFarER8fj/r6egQFBXV7215lUDIzM5Geno7Zs2fjueee6/J2OTk5yM3Nxbp164TLsrKykJycLAQnADB37lzcd999yM/Px/jx4zs8jkajgUajEb5vbGwEAKhUKgpQCCGEEA9jS3mG3QHK5s2bcfjwYWRnZ/d42/feew+jR4/GlClThMvKy8utghMAwvfl5eWdPs7q1avx9NNP2ztUQgghhHgou3bxFBcXY/ny5di0aROUSmW3t21tbcUnn3yCpUuX9mmAALBq1So0NDQIX8XFxX1+TEIIIYSIl10ZlJycHFRWViI1NVW4zGAwYN++fXjzzTeh0WgglUoBAFu2bEFLSwuWLFli9RjR0dE4dOiQ1WUVFRXCdZ1RKBRQKBT2DJUQQgghHsyuDMqsWbOQl5eH3Nxc4WvixInIyMhAbm6uEJwApuWda665BhEREVaPkZaWhry8PFRWVgqX7dy5EyqVComJiX38cQghhBDiDezKoAQGBiIpKcnqMn9/f4SFhVldfvbsWezbtw/btm3r8Bhz5sxBYmIiFi9ejBdffBHl5eV44oknkJmZSVkSQgghhABwUifZjRs3YsCAAZgzZ06H66RSKbZu3QqpVIq0tDTcdtttWLJkCZ555hlnDIUQQgghHqhXfVDcTa1WIygoCA0NDbTNmBBCCPEQ9rx/01k8hBBCCBEdClAIIYQQIjoUoBBCCCFEdChAIYQQQojoUIBCiMjsPlWJjHd/w+5TlT3fmBBCvBQFKISIzLu/nMP+szW48/1sPLrlKBrbdO4eEiGEuBwFKISICGMM+aVq4fvPfi/GvNd+wf6z1W4cFSGEuB4FKISISEl9K+pbdJBJOHy09HLEh/qipL4VGe8exP/75hiaNXp3D5EQQlyCAhRCRITPngyPCsQVwyOwffk03DZ5IADgo98uYP7rv+DguRp3DpEQQlyCAhRCRIQPUMbEmjos+itkeO66ZHy8dBLign1RVNuCWzb8hs+yi4T7nK9uxjVv/opteWVuGTMhhDgDBSiEiMjx0gYAQFKsdQvoqcPDsX3FFbh2XCwYAz48cEG4bufxChy92IAvcy66dKyEEOJMFKAQIiJCBiUuqMN1gUo57p42BABQ2agRLq9sbAMANFJ9CiHEi1CAQohI1DRpUNbQBo4DRsd0fohWZKDSdNtmDfQGI4D2YKWxjQIUQoj3oACFEJHgsycJYf4IUMg6vU2Yvw+kEg6MATXNWgBApdoUoDRpqF8KIcR7UIBCiEjwAUpibNdHkEskHMIDfAC0BybCEg9lUAghXoQCFEJEIt9cIDummwAFaF/m4QMTfomnqU0PxpgTR0gIIa5DAQohInFc2GLcsUDWUmSgAoApMGnTGYTMid7IoNEbnTtIQghxEQpQCBGBZo0ehTXNAGzIoKjMAYpagyqL3TwAoKZzewghXoICFEJE4ESZGowB0SolwgMU3d42IoDPoLQJyzy8JqpDIYR4CQpQCBGBSzvIdidCxdegaIRCWR4VyhJCvAUFKISIwLES2wpkAesalMpLlniaqFkbIcRLUIBCiAi0bzHuvkAWaA9QqtQdl3gaqQaFEOIlKEAhxM20eiPOVDYCsDGDYl7iqWrSoIKWeAghXooCFELc7HRFI3QGhiBfOQaE+PZ4e75IVmdgOFPZZHUdBSiEEG9BAQohbsb3P0mMUYHjuB5v7yOTIMRPDgA4WWa6b0yQKatCNSiEEG9BAQohbsZ3kE2K63l5h8d3k+Ubsw2J8AdAAQohxHtQgEKIm+Xb2EHWEt+sjTckPAAAFckSQrxHnwKUNWvWgOM4rFixwuryrKwszJw5E/7+/lCpVJg2bRpaW1uF62tra5GRkQGVSoXg4GAsXboUTU1NIKS/MRgZjpfZ3gOFFxHYHqBIOGBQmB8AqkEhhHiPXgco2dnZWL9+PVJSUqwuz8rKwrx58zBnzhwcOnQI2dnZeOCBByCRtD9VRkYG8vPzsXPnTmzduhX79u3D3Xff3fufghAPdb6mGS1aA5RyCYZEBNh8P8sAJTxAgSBfU00KBSiEEG8h682dmpqakJGRgQ0bNuC5556zum7lypX429/+hscee0y4bOTIkcK/T5w4ge3btyM7OxsTJ04EALzxxhtYsGABXn75ZcTGxvZmSIR4JH55Z1S0ClJJzwWyPL4GBTAt9wQqTX/KVINCCPEWvcqgZGZmIj09HbNnz7a6vLKyEgcPHkRkZCSmTJmCqKgoXHnllfj111+F22RlZSE4OFgITgBg9uzZkEgkOHjwYKfPp9FooFarrb4I8QY552sB2Le8A7Q3azP9W4lAJZ9BoRoUQoh3sDtA2bx5Mw4fPozVq1d3uO7cuXMAgKeeegrLli3D9u3bkZqailmzZuHMmTMAgPLyckRGRlrdTyaTITQ0FOXl5Z0+5+rVqxEUFCR8xcfH2ztsQkSnSaPHV4dLAACzE6Psuq9lgBIRoECAwpxBoSUeQoiXsCtAKS4uxvLly7Fp0yYolcoO1xuNpi2P99xzD+68806MHz8er776KkaOHImNGzf2epCrVq1CQ0OD8FVcXNzrxyJELLb8XoxGjR5DIvxx5fAIu+7Ld5M1/bt9iYdqUAgh3sKuGpScnBxUVlYiNTVVuMxgMGDfvn148803cerUKQBAYmKi1f1Gjx6NoqIiAEB0dDQqKyutrtfr9aitrUV0dHSnz6tQKKBQdH8EPSGexGhkeP/AeQDAnX8aDIkd9SfApUs8CgTwNShaPYxGZvfjEUKI2NiVQZk1axby8vKQm5srfE2cOBEZGRnIzc3FkCFDEBsbKwQqvNOnT2PQoEEAgLS0NNTX1yMnJ0e4fteuXTAajZg0aZIDfiRCxG/XyUpcqGmBSinDotQ4u+/vr5DB30cKAIgIVEJlrkFhDGjWUhaFEOL57MqgBAYGIikpyeoyf39/hIWFCZc/8sgjePLJJzF27FiMGzcOH374IU6ePIktW7YAMGVT5s2bh2XLluHtt9+GTqfDAw88gFtuuYV28JB+Y+P+QgDAXyYNhJ9PrzbTYUhEAPJKGjA0wh8KmQQyCQe9kaFJoxeKZgkhxFP17pWxGytWrEBbWxtWrlyJ2tpajB07Fjt37sTQoUOF22zatAkPPPAAZs2aBYlEgkWLFmHt2rWOHgoholTVqMGBghoAwJK0hF4/zrpbU3G+phnDowIBAIFKGepadKZCWdub0hJCiCj1OUDZs2dPh8see+wxqz4olwoNDcUnn3zS16cmxCNlnTMFJ6NjVIgL7vn04q4MDPPDQHMHWQAIMAcoaiqUJYR4ATqLhxAXyzJnT6YMDXPo4wYqTMs61KyNEOINKEAhxMWyCqoBAGlDHBugBAhbjalZGyHE81GAQogLlda34nxNCyQccPmQUIc+diA1ayOEeBEKUAhxIX55JzkuSNga7CjUrI0Q4k0oQCHEhfgC2bSh4Q5/bGGJh2pQCCFegAIUQlyEMSZkUNIcXCALgA4MJIR4FQpQCHGR4tpWlNS3QibhcFlCiMMfnw4MJIR4EwpQCHGRrHOm3Tvj4oN73T22OyqqQSGEeBEKUAhxkdziegDAxATH7t7hCQcGUg0KIcQLUIBCiIvklTQAAFIGOKcPPd+ojYpkCSHegAIUQlxAozfgVHkjANMWY2egRm2EEG9CAQohLnC6vAk6A0OwnxwDQnp//k53+D4oVCRLCPEGFKAQ4gL88k5yXBA4jnPKcwhLPBSgEEK8AAUohLhAXkk9ACDJScs7QHsGpVVngN5gdNrzEEKIK1CAQogLWGZQnMVf0b51mXbyEEI8HQUohDiZKwpkAcBHJoG/jxQAcKxE7bTnIYQQV6AAhRAn4wtkg3ydVyDL+3NqHABg9Q8nYDAypz4XIYQ4EwUohDiZZf8TZxXI8lbOHoFApQz5pWp8efii1XVtOgMOF9Xh/f2FeOSLI/g2t8SpYyGEkL5wfL9tQogVVxTI8sICFHhw5jC8sO0kXvrxFMCAIxfrcfRiA06UqaG3yKpsyyvD1SmxkEicGzQRQkhvUIBCiJO5okDW0u1TErDpYBEu1LTgH18etbouzN8HY+ODse90FZq1BlQ0tiEmyLnLToQQ0hsUoBDiRK4qkLWkkEnxwp+T8eiXRxEX7Itx8cFIGRCMsfFBiAv2BcdxmPHyHhRWN6OwupkCFEKIKFGAQkgf6Q1GfHn4IlIGBGN0jMrqOlcWyFr607Bw/ProzC6vHxzuLwQoU4aGu2xchBBiKwpQCOkDo5HhH1uO4qs/SjB2QBC+fWCq1fWu6CDbGwlh/gCA89XNbh4JIYR0jnbxENJLjDE8+V0+vvrDtBumsJM3e75ANtlJJxj31uAIU4DS2ZgJIUQMKEAhpJfe2lOAj367AD4xom7To/mSDq6uLpC11ZBwU4ByjgIUQohIUYBCSC+UN7Rh7c9nAADPXJuEAHOb+XJ1m3AbdxTI2irBHKAU17bQuT2EEFHqU4CyZs0acByHFStWCJdNnz4dHMdZfd17771W9ysqKkJ6ejr8/PwQGRmJRx55BHo9nR1CPMdrP52GRm/EZQkhuG3SQEQHKQGYAheeuwpkbRGjUkIhk0BnYCipb3X3cAghpINeF8lmZ2dj/fr1SElJ6XDdsmXL8Mwzzwjf+/n5Cf82GAxIT09HdHQ0Dhw4gLKyMixZsgRyuRwvvPBCb4dDiMucrWzE578XAwAemz8KHMchJkiJs5VNKLV4sxdrgSwASCQcEsL8caqiEYXVzRhkLpolhBCx6FUGpampCRkZGdiwYQNCQkI6XO/n54fo6GjhS6Vq33q5Y8cOHD9+HB9//DHGjRuH+fPn49lnn8W6deug1Wp7/5MQ4iIvbj8FIwPmJEZhwqBQAEBMJxkUsRbI8gaHU6EsIUS8ehWgZGZmIj09HbNnz+70+k2bNiE8PBxJSUlYtWoVWlpahOuysrKQnJyMqKgo4bK5c+dCrVYjPz+/08fTaDRQq9VWX4S4w4WaZuw4XgEJB/xj3kjh8mhzs7MytWWAIs4CWV4CBSiEEBGze4ln8+bNOHz4MLKzszu9/tZbb8WgQYMQGxuLo0eP4tFHH8WpU6fw1VdfAQDKy8utghMAwvfl5eWdPubq1avx9NNP2ztUQhzuj6J6AMC4+GAMiwwULo+9JIMi5gJZ3hAKUAghImZXgFJcXIzly5dj586dUCqVnd7m7rvvFv6dnJyMmJgYzJo1CwUFBRg6dGivBrlq1So89NBDwvdqtRrx8fG9eixC+qKrrAhfJMvXoIi5QJZHGRRCiJjZtcSTk5ODyspKpKamQiaTQSaTYe/evVi7di1kMhkMBkOH+0yaNAkAcPbsWQBAdHQ0KioqrG7Dfx8dHd3p8yoUCqhUKqsvQtyBD1AuPZmYP8+G32Ys5gJZHl+DUlLfCo2+498uIYS4k10ByqxZs5CXl4fc3Fzha+LEicjIyEBubi6kUmmH++Tm5gIAYmJiAABpaWnIy8tDZWWlcJudO3dCpVIhMTGxDz8KIX3zt0//wDVv/ooKizoSS0Yjw/FSU/3TpYWvfAalvkWHVq1BKJC9NJARk/AAHwQoZGAMKKpp6fkOhBDiQnYt8QQGBiIpKcnqMn9/f4SFhSEpKQkFBQX45JNPsGDBAoSFheHo0aNYuXIlpk2bJmxHnjNnDhITE7F48WK8+OKLKC8vxxNPPIHMzEwoFArH/WSE2EHdpsN3R0oBAIvfO4jP70lDsJ+P1W0Ka5rRpNFDKZdgWESA1XUqpQz+PlI0aw0oV7cJGZQUke7gAQCO4zA43B95JQ04V92M4VGBPd+JEEJcxKGdZH18fPDTTz9hzpw5GDVqFB5++GEsWrQI33//vXAbqVSKrVu3QiqVIi0tDbfddhuWLFli1TeFEFcrqGwS/n26ogl3vJ/doW39MXPQMTpGBZnU+k+H4zghi3Khpln0BbK8gaGmHkUlddSsjRAiLn0+zXjPnj3Cv+Pj47F3794e7zNo0CBs27atr09NiMOcNQcoQyP8UdOsRW5xPe79OAfv3j4RCplp6fJYD9uGY4J8UVDVjD2nqkRfIMsTOuB2saxFCCHuQmfxEALgbJUpQPnTsHB8cOfl8POR4pcz1Vj5WS4MRgag6wJZHv9mv/O4qehbzAWyPL7BXFkDBSiEEHGhAIV4vayCGqzedgJtuq53qhQIGZQAjIsPxjuLJ8JHKsG2vHL88+s8GI0M+SXmAtkuAhS+Fwp/to2YC2R57WcI0RIPIURc+rzEQ4iYMcbwyJYjuFjXigGhflg8eVCnt+OXeIZFmopfpw4Px+u3jEPmJ4exObsYzVoDGjV6KGQSDI8M6PQx+G6yPLHXnwAWLfppiYcQIjKUQSFe7cjFBlw0F4DuyO+8U3GbzoCiWtM222EWwcf85Bisvj4ZAPC9eYdPZwWyPP7NnifmHTw8PqiqaNDAaF7KIoQQMaAAhXi1rebAAjAt9dS3dDyQ8nxNM4wMCFTIEBlovdX95ssGYtX8UcL3SXFdNwmMCW4PUDyhQBYAIgMV4DhAazCitpO5IYQQd6EAhXgto5FhW14ZAMBHKoHeyPDTicoOtxN28EQGdFrUes+VQ7F81nAEKmRIT47t8vliVO0BiScUyAKAXCpBeIApKCunQllCiIhQgEK81h/F9ShtaEOAQoalVwwGAGw/1nGZp6DSdBbNsC5qSwBg5VUjcPSpOUgbGtblbVS+MvjKTVuSPaFAlkc7eQghYkQBCvFaW4+alneuSozCteNMmY99Z6o6NGDjtxh3F6AA6DEjwnEcYs3LPJ5QIMuLVtFOHkKI+FCAQryS5fJOenIMRkYFIiHMD1q9EbtPWS/zCDt4IroPUGzx8JyRuHHCAMwaHdnnx3IV2slDCBEjClCIV8opqkOFWoNApQxXjAgHx3GYm2Q6LfvVnafx84kKMMZgMDKcszGDYosFyTF46caxUMo7HpwpVvxOHlriIYSICfVBIV6J370zJzFaaFV/y2UD8cnBIhRUNWPph79jTKwKN02Mh0ZvhI9UgnjzuTT9TXQQFckSQsSHMijE6xiMDNvMxbALU2KEyweH+2PXw9Nxz7Qh8PORIr9UjSe/yxeuk0rEv+vGGaLNu48oQCGEiAkFKMTrZJ+vRVWjBkG+cvxpWLjVdRGBCqxaMBq/PjoTmTOGIkBhSiKOie26v4m3s9zFwxg1ayOEiAMt8RCvw+/emTsmCj6yzmPwUH8fPDJ3FJZdMQQ/n6jEtBERrhyiqPDn8bTqDFC36hHkJ3fziAghhDIoxMvoDUah10l6StdN1XjBfj5YNGEAIi7pINufKOVShJiDkt7s5GnTGbD1aClatPqeb0wIITaiAIV4lUOFtahu0iLET44p3TRVI9bad/LY3wvlpR9P4YFP/sDHv11w9LAIIf0YBSjEq3x/1NT7ZF5SNORdHOpHOopW9W4nj8HI8G2uaUmtpI4avRFCHIdewYnXMC3v8M3Zel7eIe162wvlYGENqps0AEw1LIQQ4igUoBCvkXWuBnUtOoT5+2DykFB3D8ejCN1k7QxQ/mfOWAFAi5YCFEKI41CAQrzG1iPtyzsyWt6xS3Qv2t1bFiQDpmJZQghxFHoVJ15BZzBiez6/eyemh1uTS/EZlOK6Fpvvc7CwFjXNWuF7WuIhhDgSBSjEK+w/W42GVh3CAxSYNJh279hrZHQgAKCwurnDac9d4fvNRJq3aNMSDyHEkShAIV6Br4VYkBzdb1vW90VkoBIxQUowBuSXqnu8vc5ieefPqXEAgFYKUAghDkQBCvF4rVoDfuSXd5Jpeae3kuOCAABHL9b3eNusAlNBcqi/D2aOjARASzyEEMeiAIV4vFd2noK6TY+4YF9MTKDdO72VMsAUoOSVNPR42/9Z9JsJUJpOzKAMCiHEkShAIR7tcFEd3vu1EADw3HVJtLzTB8kDggEAeRe7D1C0+vaC5IUpMfDzoQCFEOJ4FKAQj9WmM+AfW47CyIDrU+MwY1Sku4fk0fglnnPVzVC36bq83f4CviDZB5MGh8FXLgVASzyEEMfqU4CyZs0acByHFStWdLiOMYb58+eD4zh88803VtcVFRUhPT0dfn5+iIyMxCOPPAK9ng4aI7Zr1uixfPMfOFvZhIhABf61MNHdQ/J4of4+GBBi6ih7rJtlHn55Z35SDKQSTghQ9EYGrd7o/IESQvoFWW/vmJ2djfXr1yMlJaXT61977TVwXMd0u8FgQHp6OqKjo3HgwAGUlZVhyZIlkMvleOGFF3o7HNKPFFY3456PfsfpiibIpRxeXJSCYD8fdw/LK6QMCMLFulbkXWzAlKHhHa7X6o3tBcnmfjO+PlLh+ladAT4ySswSQvquV68kTU1NyMjIwIYNGxASEtLh+tzcXPz73//Gxo0bO1y3Y8cOHD9+HB9//DHGjRuH+fPn49lnn8W6deug1Wo73J4QS0Yjw+0bD+F0RRMiAxXYfHcaLe04UHJcMADgaBcZlF/PVqGxTY/IQAUuMxcky6WcUPtDdSiEEEfpVYCSmZmJ9PR0zJ49u8N1LS0tuPXWW7Fu3TpER0d3uD4rKwvJycmIiooSLps7dy7UajXy8/M7fT6NRgO1Wm31Rfqn+lYdimpN3U6/f3AqJgzqGCCT3hN28nRRKMsfJ7AgOUYISjiOgx/VoRBCHMzuAGXz5s04fPgwVq9e3en1K1euxJQpU3Dttdd2en15eblVcAJA+L68vLyzu2D16tUICgoSvuLj4+0dNvEStebW6iqlDFEqpZtH432SYk0BSlFtC+pbrDOabToDdh6vANDxOAGleZmHMiiEEEexK0ApLi7G8uXLsWnTJiiVHd8cvvvuO+zatQuvvfaao8YHAFi1ahUaGhqEr+LiYoc+PvEcdeY3zVB/qjlxhiA/ORLC/AB07Ifyy5lqNGr0iFYpMWGgdebKjw9QdFTsTghxDLsClJycHFRWViI1NRUymQwymQx79+7F2rVrIZPJsHPnThQUFCA4OFi4HgAWLVqE6dOnAwCio6NRUVFh9bj8950tCQGAQqGASqWy+iL9E59BCaEAxWn4fihHL1nm+Z/57J0FyTGQXNJvRthqrKVdPIQQx7BrF8+sWbOQl5dnddmdd96JUaNG4dFHH0V4eDjuueceq+uTk5Px6quv4uqrrwYApKWl4fnnn0dlZSUiI03FjTt37oRKpUJiIm0VJd2rMwcoobRrx2lS4oLw/ZFSqzqU7pZ3gPadPC1ayqAQ2zDGUFDVhIGh/rTzi3TKrgAlMDAQSUlJVpf5+/sjLCxMuLyzLMjAgQMxePBgAMCcOXOQmJiIxYsX48UXX0R5eTmeeOIJZGZmQqFQ9PbnIP1EbQtlUJwtuZOW93tOVaFZa0BskBLj44M73IeatRF7/XyiEnf993fc+acEPHn1GHcPh4iQy8NWqVSKrVu3QiqVIi0tDbfddhuWLFmCZ555xtVDIR6Iz6CE+MndPBLvNSZWBY4DSupbUd2kAQD8L8+0eyc9pePyDmBRg0JFssRGJ8tNuzGzCmrcPBIiVr1u1Mbbs2dPt9czxjpcNmjQIGzbtq2vT036odpmUwt2yqA4T6BSjiHh/iioakZeSQMmDw7Dzyf45Z3YTu+jpAwKsVON+cPGmcomtOkMwu8QITxa+CMeRdjFQzUoTpVicXDg7lOVaNEaMCDEF2PNyz+X4pd4WiiDQmzEF7wbjAynKxrdPBoiRhSgEI9Cu3hcgz848OjFeuHsnfSUmE6PrwDal3jaKINCbMT/LQNAfik13yQd9XmJhxBXqqc+KC7Bd5T9o6gezeadOQuTO1/eAdobtVEGhdiquqk9QDlOAQrpBAUoxKMIGRRa4nGqxFgVJFx7ncDAUD8kxXXdf8hPbnopoRoUYqvaZo3w7/zSrk/PJv0XLfEQj6EzGKFuM32apwyKc/n5yDA8MlD4vrvlHQDw9TG9lNAuHmILxpjVEs+JskYYjB03VJD+jQIU4jHqW0w7eDgOCPKlbcbOlmJRELuwk+Zslnx9zBkUClCIDRo1eugMpoDERyZBq86AwupmN4+KiA0FKMRj8Dt4gn3lwkm6xHn4AGVwuD8SY7o/XoIatRF71JrrT/x8pBgTa/rdOl5GdSjEGgUoxGPQDh7Xuj51AG65LB7PX5fU7fIOQI3aiH342qZQfx8hQKE6FHIpKpIlHoPO4XEtf4UMaxal2HRbyqAQe9SYOxSH+fsgMcaUqaOdPORSlEEhHoPO4REvpZwOCyS247OhYQEKiwyKutPO46T/ogCFeAw6h0e82hu1Gd08EiJGFeo2zHttHzb+WgjAeolnZHQgZBIOtc1avL33HAUpREABCvEYdA6PePn6UAaFdO3nE5U4Wd6ITw4VAbDIoPj7QCmXInPGMADA/20/iWe3noCRthwTUIBCPAidwyNeVINCusOftXOhphkGY3sPFL6f0cqrRuCfC0YDADbuL8Tyz3Kh0dPvUn9HAQrxGLSLR7x8LZZ46NMvudSpclOAojMwlNS1Wi3x8JZNG4LXbh4HmYTD90dKsfSD39GkoYxcf0YBCvEY9ZRBES2+BgUA2uiTL7nEmcr204oLqpvad/EEWP8tXzc+DhvvuAx+PlL8erYat7yThapGDUj/RAEK8Ri0i0e8lLL2AIUODCSWqps0VgcDFlY1WyzxKDrcftqICGy+ezLC/H1wrESNRf85gPPUZbZfogCFeIw6c5EsncMjPhIJB6WczuMhHfH1J7xz1U3CEk9YF3/LKQOC8eV9UzAw1A9FtS244e0DKKppcfpYibhQgEI8gkZvENajaYlHnKhQlnTmtLn+hD+d4liJGlq9aTv6pUs8lhLC/bHlvjSMig5EdZMWX+QUO32sRFwoQCEegT8oUCrhEKikBshi5EcHBpJOnK5sAgBMGhwGADhWYmppr5RLhN+ZrkQGKnHDhAEAgHNVtMzT31CAQjxCrUWTNgkdFChKwhIPZVCIBT6DMj85GgCgN+/yCuuk/qQzg8P9AQDnqA7F6RhjMIhoFx4FKMQjtHeRpeUdsfKlAwPJJRhjOGWuQbksIdSqC7SttWRDIgIAAIXVTbSF3YnKGlpx3br9mPHyHrSJ5EMGBSjEIwg7eChAES0/uXmJRyQvbsT9ytVtaGzTQyrhMCTCX8iGALYHKANCfCGTcGjTGVGubgMAlNS34suci0ItC+mb0xWNuP6tAzhysQFFtS0oqW9195AAUIBCPISQQfGnc3jESim0u6cAhZicrjDVnwwO94dCJhWyIUDXO3guJZdKMDDUD0B7Hcq/vjmGh784gse/zqOze/qouLYFN/znAMoa2oTLxBL4UYBCPALfrCkswLZ1a+J6frSLh1yCrz8ZGRUIAFYZlO528FxqSITpfvwyz6HCWgDAlpyLeH//eQeNtn/6Mb8c6jY9RkUHCkGjzkABCiE2u1Br6oEQH+Ln5pGQrrTXoFB7cgK06Qw4aA4kRpgDlCFWSzy2f9iwLJQ9W9WERosW+M9vO4Ffz1Q7Ysj9Er+cc+XICGGHJGVQCLFDkTlAGRRGAYpYtQco4nhxI67HGMOR4nr88+s8XPb8T/jpRAUAIDFWBQAYHGGRQbGj4SK/NHSuqhmHL9QBACYNDsWi1AEwGBme33bCUT9Cv1NSZwpQBgT7wkdmCgnEEqBQQwniEfgukvxaNBEfvlFbi44yKP1NTZMG3+SW4ovfi3GyvL1z7IAQX9w6aSCmj4wAACSE+YPjAMbs6wjNZ1AKq5vxR1E9ACB1UAjumJKALw9fxKlyNVq0+h77qpCOLpoDlLgQX8il5gDFG5Z41qxZA47jsGLFCuGye+65B0OHDoWvry8iIiJw7bXX4uTJk1b3KyoqQnp6Ovz8/BAZGYlHHnkEej29qJHONWn0QmvsgZRBES3+wMA2KpLtNxhjeHTLUUxe/TOe3XocJ8sboZBJcN24WHxy1yTse2QG7p8+THjjU8qlQrAxINTX5ufha1Au1rXgYGENACB1YAiiVEpEBCpgZMCJssbuHoJ0gV/iiQv2854MSnZ2NtavX4+UlBSryydMmICMjAwMHDgQtbW1eOqppzBnzhwUFhZCKpXCYDAgPT0d0dHROHDgAMrKyrBkyRLI5XK88MILff6BiPe5UGOq3A/xk0OlpF08YqWU0y6e/uZURSM++93Ugj5lQBBunBiPa8bGIsi367/TN/4yHmcrmzAqWmXz80QEKBCgkKFJo8d5czZ1/MBgAEBSrAq7T1XhWEkDJgwK6fT+pfWtePeXQvzl8ngMN9fDENOHv4ZWU5duywyKziCOnVG9yqA0NTUhIyMDGzZsQEiI9S/E3XffjWnTpiEhIQGpqal47rnnUFxcjPPnzwMAduzYgePHj+Pjjz/GuHHjMH/+fDz77LNYt24dtFptJ89G+rtic/3JwDD/Hm5J3InPoNAunv7jRJkaADBxUAi+e2AqFk8e1G1wAgBjYoNw7bg4u56H4zirHUADQ/0Qbt7RlxwXBADIM7fQv1RDqw5LNh7Cxv2F2PDLObue19vx9SdBvnIEKGRQ8BkUgzj+hnsVoGRmZiI9PR2zZ8/u9nbNzc14//33MXjwYMTHxwMAsrKykJycjKioKOF2c+fOhVqtRn5+fqePo9FooFarrb6I7dRtOry15ywq1G0931iELpg/MQ2i+hNR42tQxNKFkjjfSfOyCl8E60xDLApsU83ZEwBIMgcoxzoJUHQGI+7flIOz5vOAaproQ7ClknrTa2tcsGm5zYfPoOjFkUGxe4ln8+bNOHz4MLKzs7u8zVtvvYV//OMfaG5uxsiRI7Fz5074+JgKosrLy62CEwDC9+Xl5Z0+3urVq/H000/bO1RitnrbCXx6qBjFtS1Yfb1pSc5oZMgvVaO6SQN1mw7qNj3UrTrTv1v1aLS4LFApw6s3jxM+sbgav8WYCmTFzZcatfU7J8wFsfYs1/SWZQYl1WIphw9QzlQ2oU1nEJYaGWN44utj2H+2RrhtvXk5g5iUWBTIAhCWeDQiKZK1K0ApLi7G8uXLsXPnTiiVyi5vl5GRgauuugplZWV4+eWXcdNNN2H//v3d3qc7q1atwkMPPSR8r1arhYwM6V5tsxZfHS4BABy92P4J4+19BXhx+ymbH+fF7Sfx4g1jHT4+W7Qv8VCAIma+1Kit3+GXeEbFOL+uw7IL7fj49gAlJkiJMH8f1DRrcbK8EePigwEAb+89h89+L4aEA5ZOHYwNvxQK9RbE5KJQIGvOoMj4DIoHBig5OTmorKxEamqqcJnBYMC+ffvw5ptvQqPRQCqVIigoCEFBQRg+fDgmT56MkJAQfP311/jLX/6C6OhoHDp0yOpxKypMe+Wjo6M7fV6FQgGFgjqI9sYnBy9AY/5lO1PRBJ3BCLlUgr2nqgAACWF+iA32hUoph8pXhkClXPi3SilHq86AJ745hi9yLmJJWoLwacWVaInHM9Bhgf1LdZMGVY0acFx7p1hnGmYOUHzlUquAiOM4JMUFYe/pKuSVNGBcfDC25ZXh/7abdo/+a2EiLhscig2/FKK+hQIUS0IPlEsyKGLZZmxXgDJr1izk5eVZXXbnnXdi1KhRePTRRyGVSjvchzEGxhg0GlOr8rS0NDz//POorKxEZGQkAGDnzp1QqVRITEzs7c9BOqHVG/HfrAvt3xuMKKhqwvDIQGG99u3FE3pMzx4qrMV3R0rx7Nbj2Hz3ZHAc59RxW9IZjMI2uEFUJCtqVCTbv/D1J4NC/eCvcH7/kdExgXh8wSgMDPUT3kh5SXEq7D1dhfySBvxRVIeVn+UCAO6YkoA7/jRYeA1Rt+rAGHPpa5iYlXhTBiUwMBBJSUlWl/n7+yMsLAxJSUk4d+4cPvvsM8yZMwcRERG4ePEi1qxZA19fXyxYsAAAMGfOHCQmJmLx4sV48cUXUV5ejieeeAKZmZmUJXGwrUdLUdmoQWSgArHBvsgtrseJMjVkEg7NWgN85VLhU0l3Hp0/Cj/ml+NgYS1+zK/AvKTOM13OUFrfCoORwUcmQWQg/X6IGW0z7l9OlpuWd0bHOL/+BDBlSu6eNrTT6/idPPsLqvHTiQpo9EbMHBWJ/7fQ9KGX31mkNRjRpjMK2b7+7tIaFB+pKXATSwbFoa3ulUolfvnlFyxYsADDhg3DzTffjMDAQBw4cEDIlkilUmzduhVSqRRpaWm47bbbsGTJEjzzzDOOHAoB8OGB8wCA26ckYOwA0x/w8VI1jhSbsidJcSrIpD3/CsQF+2Lp1MEAgE0HL/Rwa8cqsiiQlUjoU4+Y8V08qVFb/3Ccrz9xQYFsT/il5+LaVlQ3aTE6RoW1fxkPqfk1w99HKvy7vrV/7ORhjOGjrPPYfaqy0+s1egMqzYewXppB8fhGbbw9e/YI/46NjcW2bdt6vM+gQYNsuh3pvWaNHkfMRbE3ThiAXSdNv6QnyhqFX76UAcE2P97EBFNRmquLzKj+xHPwSzwtOgOl0fsBfonHFQWyPYkL9kWwnxz1LTpEqRTYeMdEBFgsO3Ech2BfOWqatWho1SEmyPYutp7q6MUG/L9vTa077pk2BI/MHWn1gbS03tR2QimXCMcOiK0GhQ4L9FKnK0wvHhGBCkSqlEKfguNlaiFwSRlge8Grr9z0x96sce2RBEW0g8dj8CehGoyM6lC8nM5gFHqLJLpoiac7HMfhlssGIi7YF+/dflmnAQi/zNPgZYWyXf08Ry36wqzfdw53vJ+Nuub27JGwvBPsK3yYEFsGhQIUL3VK6E9g+nQzIioQEs607fjoxXoA9mVQ/BXu2aFBhwR6Dl+5FDJzGl3dSmdrebNzVc3QGowIUMiE5QF3e2z+KOx/bGaXOw1V5gDFm3qhfP57McY+swOfZxd3uO54qSlAuTwhFL5yKX49W41r1v2K46WmpTmhSVtI+2tre6t7ClCIE/EnivLb/5RyqdBHwMgAlVKGBDuyEnz6vtnFAQrfpG0QZVBEj+M4IYuibvOeNwHSEV8gOzI60GNqw4L9zBkULwpQ+JOdf8zv2OQ03xyI3D4lAV9nTsHAUD8U17bi+v/sx3dHSjtsMQbQ3uqeMijEmSxfQHiWqdiUAcF21QjwBZCuzKCUNbTibKUp0Boc3vNuI+J+/KdUtRe9CZCO+JODR0W7v/7EVkFe+LtZ32JasjlcVAfG2tvT6w1G4UPqmFgVRkWr8N0Df8K0ERFo0xnxt0//wCeHigDAKgPmFYcFEnFjjFks8bQHJaOtAhT7Gq7xGRStweiy9N/6veegMzBcPjjUqs01ES/+tGnKoHi3MxWeF6AE80s8XlSDUmcOUOpadCisbhYuL6hqhlZvWoLjl8eD/Xzw/h2X4f7ppq3a1eZziSwzKHwNioYyKMRZqho1qGvRQcIBw6PaMw+jLart7ak/AdozKIBr+lxUNWrwqTnCf3DmMKc/H3EMla95iYdqULzaGXOB7LBIzwlQhCJZr8qgtP8sh83LPQCQb64/GR1jvQQnlXD4x7xReCsjVfjQOcKiC7DYalCc3/6PuByf2ksI8xeaZwHWJ47am0HxkUkgk3DQGxlatPoej1Tvq3d/OQeN3ohx8cGYOizcqc9FHMfeDEpVowblDW1ItvP3kbhPq9aA4jpTbZjlByCxU3lhgMJnUADTMs8NEwYAaK8/GRPb+d/VguQYJMcFobi2xSqzLrZdPBSgeCF+eWfkJenXyEAlnkgfDcaA2F5U3vv5SKFu0zs9g1LbrMVHv5kawj04cxj10/AgfIDS2NZzBuWHvDL8Y8tRNGr02LFymtUnOSJeBVVNYAwI8ZMjzNw/wxME+5nG6i27eBhjqGu2yKBcqBP+ze/U6W4LeHyoH+Iv2R3pQxkU4mwnuzkC/a4rhvT6cf0VMlOAonFugPL+/kK0aA1IjFFh5qhIpz4Xcaz2JZ6u3wTadAa8sO2E1TlRfxTVUYDiIfj+J8MjAz3qw4O3LfG0aA1WDdVOVTSisU2HAIVMWOKxzJrbwkfmxa3uiTicqui4g8cR+PMrWrTOqy9oaNXhg/3nAVD2xBP1tMRzvroZi/5zQAhO4kNNmbzTFU2uGSDpszPmnXXDPGh5B/C+XTz88o6PVIK4YF8wBhwpbsDFulao2/SQSzm7g34f84G/YlnioQDFy+gNRpwxv9g7usLe31wo68wlnv8eOI9GjR4jogIwd4zrDiUkjtG+zbhjEPv9kVIsfONX5JeqEeInx/t3XIYHZpgKoPnOx0T8+NeXEZGeFaDwfVDqW7zjLB6+QDbYT44Jg0xHkRwuqhPOSBoWGSjUlNhK7s2HBRL3O1/TAo3eCF+51OHdV32FZm3OyaA0afR4b38hACBzxjCPaQBF2glLPBYZlDadAY9/nYcHP/0DTRo9LksIwbblV2DGqEjhEx5fN+UtHv86D9eu24+L5mJSbyIs8XjYkpzlEo/RKI4+H33BZ1BC/HyQOjAYgKlh26aDpt2PY+xc3gGoSJY4GR89j4gKcPgbvL+wxOOcDMqm3y6gvkWHweH+WJgS65TnIM4VqLBOo+sMRtz8zm84UlwPjgPunz4UK2ePEA4t49/kKhs1qGvWIsSDii670qTR49NDRWAMuHXDQWy+e3KvitLFSKM34HyNqd/GcA/LoPABipEBTVq9sBzpqeosMiip5gwKv3sHAFIHhtj9mGLbZkwZFC/zv6OlAIDLEkId/th8L5QWJxwY2Ko1YMMv5wCY3sSklD3xSMISj3kXz5Hiehwproe/jxQf3nk5Hpk7yupE1QCFTGgU5S3LPMdL1eCbehbVtuAvG35DpbrNvYNykMLqZuGojIhAhbuHYxelXCq0cveGAwPrLTIoY2KDcPXYWKQMCMJfLh+Il28cixsnDrD7McXW6p4yKF6kpkmDn09UAgBu6MUvZ0/4xj4tDjqpljEmFMFuzi5CdZMWA0J8cd34OIc8PnG9S3fxVDZqAJi6GE8bEdHpfUZEBeJiXStOVzRi0pAw1wzUifLMp8iOHxiM6iYNLtS04J195/DEwkQ3j6zv+PqT4VGetYOHF+QrR2WjBg2tOsS7ezB9xG8xDvGXQyrh8MZfxvf5ManVPXGar/8ogd7IkDIgqNMtxn0lBCh93GbcpNFjxeY/cNnzP2P3qUpo9Aas32vKntw3fajwR0I8j2UfFMYYqswBSqSq60/bfB2Kt+zkOWYOUKaPiMQy87b+kvpWdw7JYc4IW4w9a3mH501bjfkaFL6/iyNQDQpxCsYYtuRcBADcOMHx2RMA8FP0fRfP2com3PtxjlBod89HObhmbCzK1W2IVimFTojEM/FLPFqDERq9UQhQIgK6DlBGRpve7E55yRIPn0FJHqBCszmYr232jp0j/OGdwzw0QPGmE435JZ5QBwYo/IdDrcFoleF2F/qo6iXyShpwsrwRPjIJrhnrnCUSP3nf+qCo23S48e0DOFvZhCiVAlOHhUOrNwqB1T1XDoFCJu3hUYiY+ftIwZcPqVt1qGw01V50V6/QnkFptDqR1RO1aPUoqDIF30lxQQjhu5d6Qc0DYL3E44m8K4PSXiTrKJbbksWwzEMBipf4/PdiAMC8MdEIcuAvrKW+ZlBOlTeirkWHMH8fbH3wCrx3x0TMGGmqSwgP8MEtlw102FiJe3AcZ1Eoq2vPoHQToAyNCICEM72J87f3VHyBbJRKgchApfDmUecFvTcMRiacmOupGZQgX+8JGC2LZB3FR2oZoLh/mYeWeLxAm86A73JNu3d6U7ltK78+dpKtMR/vHR/qJ7xh/ee2CXh//3lcPjhE6LNCPJtKKUd9iw4NrXpUNZlrUAKVXd5eKZciIcwf56qbcaqiEZGqrm8rdsLyTpzpkLZQ87bpuhatKFLmfVHfooXe3D8kysN28PC8KYNSywco/s7JoGj1Rvi7+X8zZVBErqimBW/8fKbboODH/HKo2/SIC/bFlKHOO/nXr499UPh1eMsDxpRyKe6bPhQTBjl+WzRxD8tmbZXqnjMogPcUyvIBSpI5QOE/3eoMDM1OPmTT2fglBZVSZrVV3JN4U4BS38wv8TgugyKVcMISrRgyKJ75W9aPvP7zGfx752m8vaegy9vwNRyLUuOc2j+E74PS2xfa2mbTm1WoFzTjIl3jd/LUt2hRYw5KewxQovmOsupubyd2xy7JoPj6SKGUm15m6zy8UFboXOrBf7/tRbKe/f9CZzCi0dyPypFLPEB7FkUjgp08FKCIXEm9qVX2juMVXVzfil/PVgMAbpjg3J39fCfZ1t4u8ZhfoEMDPPcFjvSMD1Au1LTAYGTgOOusWWf4moZzVc1OH5+ztGj1wu40PkAB2t9APL0OhQ+wHPmJ3dW8JYPC19BwXPvP5CiWO3ncjQIUkas2122cLG/EhZqOL95f5lwEY8DkIaEYGObYs3cuJZzF08s+KJ0t8RDvE6g0ZdoKzMFGmL9Pj0sCg8P8AZjOkvJUJ8rUMDIgMlBhVUcTLAQo3vGmGOqkInxX8J4AxfRaqlLKHZ4157vJ0hIP6VFNU/uuhp2XZFGMRoYvcky7d26a6Py+iP7mXTytvewkywcooe6uvCJOxe/iKTBnE8K76YHCGxRuCq6rmzRobPPMN4+Psi4AAMbGB1tdHmouYvSaJR5PzqAIJxp75u8Yjw92Q5wQLPI7ecTQrI0CFBHTGYxWn7p25FsHKL8V1qC4thUBChnmJ8U4fTy+cj6D0rddPJRB8W78Es+5alOAYsuZLSqlXPi9uCCyLIrRyPDCthP40lzr1Zm9p6vwTW4pJBzwwIxhVtcFe8kST60TOpe6mrdkUJzRRZYn95YMypo1a8BxHFasWAEAqK2txYMPPoiRI0fC19cXAwcOxN/+9jc0NDRY3a+oqAjp6enw8/NDZGQkHnnkEej1jj+AztPxGQd+Z+LvF2pRbZFR2fK76QXz6rExLtmiy2dQNHojDL04rrw9g+K5L3CkZ/wunjad6QWuuy3GlgaZlyjFFqDkXqzHO/vO4Z/f5EGj75g9bNbo8fhXeQCAO6YM7pBBCRF6oXj2myK/a8QZn9pdhQ9QGtv0vXoNE4v2HijOy6B4dJFsdnY21q9fj5SUFOGy0tJSlJaW4uWXX8axY8fwwQcfYPv27Vi6dKlwG4PBgPT0dGi1Whw4cAAffvghPvjgA/zrX//q20/ihfimVeEBCiTFqWBkwC7zYYDqNh22HSsDANzoguUdoH2bMWB/LxTGGAUo/cSlx9jbeuptQjhfhyKuQtkic8DUpjPiSHFDh+tf2XkaJfWtiAv2xcNzRnS4nm9F7jVLPB7892tZUFrT7LlNAduXeJyQQRHRgYG9ClCampqQkZGBDRs2ICQkRLg8KSkJX375Ja6++moMHToUM2fOxPPPP4/vv/9eyJDs2LEDx48fx8cff4xx48Zh/vz5ePbZZ7Fu3TpotZ79B+xofLYkPECBOYnRACAEJf87WoY2nRFDI/wx/pJPbM6ikEmEPfKtdm41btLoharwMNrF49VUvr0MUPhC2WqRBSi17RmdrIIaq+uOFNfj/f2FAIDn/5wkZBktecsST70T3xRdRS6VCJm6Mx7cc8eZSzxiOjCwVwFKZmYm0tPTMXv27B5v29DQAJVKBZnM9IeblZWF5ORkREVFCbeZO3cu1Go18vPzO30MjUYDtVpt9dUf8Dt4wgN8MD/JFKDsOVWFz7OLhdb2N02Md1l3So7jet0Lhc+eKOUS4TGId1Iprf//Rnp6BsUyQDlXLfxbZzDisa/yYGTAteNiMX1kZKf3t+wm68lqnbis4EqjzSe9nyjz3PcRZy63+Ug9uAZl8+bNOHz4MFavXt3jbaurq/Hss8/i7rvvFi4rLy+3Ck4ACN+Xl5d3+jirV69GUFCQ8BUf75olDXfjMygRAQoMjwrEitnDAQCPf52HP4rqIZVw+HOqcw4G7Epv293XCFuMaQePt+t9BsX0yVZsW40tA5TDRfVoM+9i2/DLOZwoUyPET45/LUzs8v7CeTzNHl6D4gVFsgAwOsYUoBz34ABFyKA4YbnNYzMoxcXFWL58OTZt2gSlsvvCN7VajfT0dCQmJuKpp57qyxixatUqNDQ0CF/FxcV9ejxPUc3XoJhf4JfPGo70lBjhPIwZIyNsLkB0lN62u69tovqT/qK3Acog8xJPVaMGTb3cKeYMxeYAheNML9qHi+pQWN2M1386AwB4Ij0RYd1spW4/0dhzMyiMsfY+KB7+NzwqxtS1+ERZo5tH0nt1TsxmyaWmjLzHNWrLyclBZWUlUlNTIZPJIJPJsHfvXqxduxYymQwGg+lNq7GxEfPmzUNgYCC+/vpryOXtkxgdHY2KCuvtsvz30dHRnT6vQqGASqWy+uoP2mtQTC8IHMfh5RvGYuwAU5fKxWkJLh8Tvzxjd4BCBbL9xqVLPLYGKEG+cuH3o7OmhO6g0RtQrm4DAEwdZjrnKqugBo9/lQeN3ogrhofj+h6ymPzPVOvBAUqjRi98MAr28CWeRHMG5Wxlo8uXMYxGhg37zmHTwQvQ9+G5nVkk67EZlFmzZiEvLw+5ubnC18SJE5GRkYHc3FxIpVKo1WrMmTMHPj4++O677zpkWtLS0pCXl4fKykrhsp07d0KlUiExses0aX/UXoPS/gLv6yPFZ/ekYcfKabhyRITLx+SvMGdQ7PyEW0NdZPsNfx+ZsDVeKZcgsJPC0a4IyzzV4ljmKalrBWOmzGF6sqnX0MZfC5F1rgZKuQTPX5fcYw0Y/4bepjPaXVwuFvwOJF+5FEq5Z586PiDEF4EKGXQGhoIq1xbKbtxfiOe3ncA/vz6Gq9/cj8NFdb16nPblNmdkUMQToNhVrRgYGIikpCSry/z9/REWFoakpCQhOGlpacHHH39sVdAaEREBqVSKOXPmIDExEYsXL8aLL76I8vJyPPHEE8jMzIRCQfUJlix38VhSyqXC6a+u5tvrDAodFNhfSCQcAhUyqNv0iAhU2FXEnRDmj8NF9aIplOXrTwaG+iFtaBiA9gLxh64aYdPxEgEKGeRSDjoDQ12LFr4+vs4bsJM4s3Opq3Ech1Exgcg+X4cTZWqMinZNRv50RSNe/PEUAFPgfqJMjRv+cwBb7puC1IEh3d6XMYajFxvwY345tueXCx9enfF66iOiRm0O3U5x+PBhHDx4EAAwbJh1N8XCwkIkJCRAKpVi69atuO+++5CWlgZ/f3/cfvvteOaZZxw5FK/QVYDiTv59LJKlgwL7B5Wv3BSg2Pm7K+zkEclWY77+JD7UDwND/RAbpERpQxuS4lT4658G2/QYHMch2M8HVY0a1LVoERvsiQGK5/dAsTQ6RmUOUBrx5/HOfz6t3ogVm3Oh1RsxY2QEXr5xLB789A8cKKjB1iNlnQYoeoMRh87XYkd+BX7ML0dZQ5twnVzK4dpxcYhWOb4GUUyt7vscoOzZs0f49/Tp08FYz81dBg0ahG3btvX1qb2awdje2Cw8UDwvCsKBgb2sQaElnv7B1Kyt1e4ibj5AEUs3WcsMCsdxWHrFEGz67QJeumFsjwcgWgrxk6OqUeOxZ8DUe8E5PJb4nTyu2mr8+s+ncdy84+v/FqUgLECBv1w+EAcKanCwsKbD7c9XNyPj3YMoqW8VLvPzkWLGyEjMGROFGaMiOzREdBSvzaAQx6lt1sLITDsHQkX0ouDf5yJZ8WSDiPPw7e5tLZDl8TUohSJc4gGApVMHY+lU2zInlvg39loP7SZba94i7ekFsrxR0a7byZNzoRb/2VMAAHjhz8nCSdeThoQCMG13bmjRCQcZAsDaXWdQUt+KYD85Zo+Owrwx0Zg6PNwl9T98DYpGBAEKHRYoUvzyTohfz0fVu5KwzdjeIlnaZtyv8J/u7A1QxLbVuKjW9AmWD1B6y9O3GntbBmVkdCA4zvQ6yx8p0lvHShqE3jiXatbo8dDnR2BkwPXj4zA/uf1Q18hAJYZE+IMx4ND5WuHysoZWfJdbCgD4718vx8s3jsXsxCiXFScLGRS9h7a6J8536RZjsRC2GXfxB9kVWuLpX6YOD4evXCoUltoqyFeOASGmGo2vDnd9erArMMasalD6IkToJuu4JR6Dkdm0pO4I3laD4ucjw2BzMNyXZZ4f88ux8I1f8fjXeZ1e/9z/TuBCTQtig5R46toxHa6fPMT093HwXPsyzwcHzkNvZJg0OBQpA4J7PbbeEnbxGNy/44wCFJESY4Es0LsMSqvWgFZzQENFsv3DkrQE5D01B5clhNp933uuHAoAWPvzWbuLsR2pvkUnZHH4oKm3+N0vjlriyblQixFP/IB3fyl0yOP1xJt28fD4OpQfjpX3OtD76biph9d3uaUdMjG7Tlbg00NFAICXbxrbac3IpMGmv4/fzHUojW06fPKb6T53TxvSqzH1lYIyKKQn1Y0de6CIgZ/C/k6y/KmhcilnV08M4tl6uzR588R4DAz1Q3WTBu/vP+/YQdmBrz+JUin6nF63XOL5o6gOf/0gG6fKe1//sON4BQxGhg2/nIPR6Pw3Er4Pircs8QDA/GRTY9BPDxXh8a+P9apx2u8XTH1M9EaGL3LaO5zXNmvxjy2mrMrSqYMxZWh4p/fnMyjHS9VoaNXhs+xiNGr0GBLhjxldnO3kbMIuHqpBIV0RfQbFjgDFsousqw42JJ7LRybByqtM506t31uABjftfLm0QLYv+KWR6iYtHtlyFLtOVuKhz3Nh6GVwUVBpajBW2ahBtkX9grPwGRRvKZIFgIUpsXj+z0mQcKYg5d6Pc+z6XatsbEOhxXb4zYeKYTQvuz3+VR6qmzQYHhmAR+aO7PIxolRKDA73h5EBL/14UuiTsuyKIZBI3PNa6bGt7onrVPEBioi2GAOWre5tT73X0A4eYqdrxsZhZFQg1G16fHzwglvGUOSg+hOgfWkk61wNzpqDi/xSNTZnF/Xq8c5UtndA/V9eWZ/H1xNvK5LlZUwahLcyUuEjk+CnE5VYsPYX5FywrbtrznnT7YaE+yNQKUNRbQv2nqnCyztOYXt+OWQSDq/ePK7H7Ntk826ej38rglZvxFWJUbhhwoC+/WB94CMzjVcMfVAoQBGpztrci0GvMihNVCBL7GN5UvfZSte2I+fx5wHFhzgug8JnTJLiTPUPL/14Slg+sVWbziAU7wLAtrzyXmdibMUXyXrjLrx5STHYcm8aBoX5oaS+FTetz8LvNmSl+J03U4eH4/rxpt/Vez7Kwbrdpi3Fj8wdiaS4oB4fh1/mAYAbJgzAfzJShUJVdxAyKBSgkK7wJxnb24nT2XpzWCAdFEh6Qzhkz029Q45ebAAAjI7p+7ESlpmHyEAFPl02GaOiA1HfosO/d56y67HOVTXDyIBApQzBfnJUN2k6bfblKK1aA9p0pjcrb1risZQyIBhbH5yKaSMiYDAyfJZd3ON9fjdnUCYmhOIvkwYCML2p+/tI8fot44Ri755clRiF2aOj8PBVI/DSDSlubyshpkZtFKCIlPhrUHqzxEMBCrGdO3uHNLTqcKrCVMQ6YZD9O5EuZbn75cFZwxGolOOpa0zbTjcdLMKxkgabH+us+YC7EVGBmJtoKvTcetR5yzx89kQm4RDgxUXugUo57jXvnNl9qrLb4uMmjR75pab/Z5clhGBUtAr3TBuC2aOjsPVvV+Dacd2fcG3Jz0eGd2+fiAdnDRdFjZ6YWt1TgCJCRiMT3tTFVoPSm06y/PY7WuIh9gj1N72pO7J3iK1yi+vBGDAozM/uZnOdCfKVY0FyNKaNiMDNE+MBmFL7V4+NBWPAU9/l27zVlV/yGh4ZgIVjTY2/th8r79UuFFvUCSfnen+R+2WDQxGokKG6SYvci/Vd3u6PojoYmWn7eUyQaQv6qgWj8e7tEzHYfFyDp6IMCulWbYtWWFMOE1lhqa9FDYqt2xv/MB8pPjLaPScwE88UbM6g2Fuj4Qg55vqCCT2cMmsrjuPwVsYE/PevlwtvAADw+IJR8POR4vcLdfgmt8SmxzpbacrsDIsMQNqQMIT6+6C2WYusc85Z5uHPD+IDRm8ml0owbWQEAGDXicoub5ddaPr9uLwXfX7ETmh1TxkU0pmj5sh9cLi/1YuZGPgr2ivS2/Q9Z1Eq1G04V90MCQdMGmJfV1HSv/FLPI0avcs/zeWYg+oJCY4JULoSE+SLB2aaTn5/YdtJNLb1nC3iMyhDIwMgk0owL8m8zHPEOcs8lhmU/mD2aFP/kZ9OVHR5m2yL+hNvQxkU0i2++GrCIOe+OPaGUtYeoBwqrMVDn+Vi98muP2lkFZg+1SXFBSHI1/s/gRHHCfKVg19RqHNhHYreYMQfRfUAgIkOqD/pydKpgzE43B9VjRq8setsj2Pje28MjwwAACw0n++yPb/cKW8q7U3a+sff7/QRkZBwwMnyRlys6/xU7dPm+qSUAT3v0vE0cmrURrrDdyecKMIARSLhhELZOz/Ixld/lOCvH2Zj3e6zna6hHyioBgCkUfaE2Ekq4YSgtt6FdSgnyxvRojUgUCkTggBnUsik+NfViQCAjb8WCks4nblQ2wKdgcFXLkWsufZh0pAwhAco0NCqw69nqx0+vvY29/0jgxLi7yN8OOzsw1eLVi/UCDqiR47YUKt70iWdwYgjxfUAgIlOTi/3Fh+gMAaMjAoEY6Z+Dss353Y41ZNfF59s56FxhADtb4qurEPhG3WlDgxxWTfPGSMjMXt0JPRGhqe+Ow6dwYjNh4rw8o+nrLIi/PLOsMgAYWxSCYcF5rbt/3PCbh5vOyjQFrNGRwEAfuqkDuVinemEa5VS5pVZYcqgkC7ll6qh0RsR7CfHkHDnf3rrjcvNle4v3pCC7SuuwHPXJUEm4fDdkVLctD4L5Q1tAIDi2hYU17ZCJuF6dWgcIfyygiuXePgAxdVLrP9vYSJ8ZBL8erYaU/9vFx77Kg9v7j6LH46VC7exDFAspZuXeX7ML4fGhtowe9R74UGBPZk1ylSHklVQg+ZLDkbll30GOKCBnxgJNShUJNv/FFQ14afjFV2uFf9usXvAXWcx9GTdrak4/K+rcNPEeHAch9smD8JHSychxE+OoxcbcM2bvyK3uF7InqQMCPLq/gnEeYQMiguXeHLctMQ6KMwf95j7cFSo20/GPWrOqAJdByiXJYQiMlCBxjY9fj3j2GUevlFefymSBUzzOzDUD1qDscOyGZ9BiQ/t2wnXYsV3ktVQBqV/YYzh9o2HcNd/f8fsV/bimz9KOrSoFj69iXR5BzBtmby0FXPa0DB8mzkVI6MCUdmowU3rs/DuL+cAoMuTPAnpCb+s4KoMSm2zFiX1reA4YGx8sEue01LmjGG4Y0oC/j5nBJ4y16UctWjidsZii7EliYTDAnMWxdFN27z1HJ7ucByHWebdPD9fspuHD1C8PYOi1Rtt7s3jLBSguNCpikbhl/tCTQtWfJaL+a/vw/Zj5WDMdAomXyDrqP4LrjQwzA9f3j8Fs0dHQas34nSF6dNeGtWfkF4SlnhcVINSoTYtT4b5+8DfDVk/pVyKp64ZgwdmDkeaObA/XqqG0cjQotXjZJkpQEmMUXW479Xmpm07j1d0qAXri7p+1AfF0qxRpjqUXSerrHo+8ecgDQjxzgyKj8WHT72Tz3jqCQUoLsSnXtOGhOGRuSOhUspwuqIJ936cg+vW7cfnvxejqlEDuZRzy6c3RwhQyPDO4gnInDFU+F6M26WJZwh28RIP3/VYDEdMDI3wh1IuQZNGj8KaZhwqrIXeyDAgxLfT3SPj40MQE6REk0aPvaerHDaO/tYHhXe50FVWY5XF6i8ZFMD97e4pQHGhfeYAZdboSGTOGIZfHp2JB2YMg5+PFEcuNuDRL/MAAGNig3o8olvMJBIOj8wdhc/vScPmuyd79M9C3Is/v8lVGRQxnYElk0qETEnexQahp9CULjKSEgknFMs6ajePzmBEY5upSLQ/LfEApjfqaSNMXWUtl3n4IllvrUGxzKC4u1kbBSgO8mXORcx7bZ/VMeiW2nQGHDKfOHrFcNMvfZCvHH+fOxL7/jEDS6cOFiLXPw3zjiWRyweH2nTcOCFdcfUunvYARRxvxikDggEAeSUNOCAEKF3XdKWnmAKUn05UoNWO87K6wu/g4Th45ZbanswcxXeVNW03btLohWxeXLB3BihSCSc0SKQMipd4Y9cZnCxvxP/yOv/kcvhCHdp0RkQGKjAiyrrALTxAgf+3MBF7H5mOV28eiwdnDnfFkAkRvWDhRGPXLPFUN5kP6RRBBgWAEODvP1uNY+bTc7ur6RoXH4y4YF+0aA3Yc6rrDs+24gtkg3zlkIp0V6EzzRgVCY4DTpSpUVrfihLz8k6wnxyBSu8M2DiOaz/RmDIonu98dTPO15gyJwXmbYCX+sW8VW3qsPAuTwSNCfLFn8cPoCURQsz4JZ5aV2VQ+BoUB5xg7AjJ5gDlZHkjGDPVpUSplF3enuM4LExx3G6e/tZF9lKh/j5INW9Y+PlkpdcXyPKEAIUyKJ7P8pPKOfM5GZfiC2SnDqctt4TYKti8xNPQquuwJd8ZqsxLPBEiyaAMjfCHr8UHFlu27C9MiQUA/HyyokOTMXu190DxzmyBLSy3GwtN2oK9s0CW135gIO3i8Xh7LCrmz1Y2ddg7XtesFdKzU4dRgEKIrYJ9TZ/cGQPUrc5f5qkSWQZFJpUgMbZ9S3FXBbKWkuJUGBjqhzadEbu6OcjTFv2xB8qlZpvb3h8oqMFpc4bcWwtkeXJvyKCsWbMGHMdhxYoVwmXvvPMOpk+fDpVKBY7jUF9f3+F+tbW1yMjIgEqlQnBwMJYuXYqmps6XRsSuTWcQqusB0ye92kt2HOw9XSWcWxPZTXqWEGLNRyZBoLkfiSuWedprUMTzhswv83AcMNmGQzetl3lK+/Tc/BJPf86gDI8MwIAQX2j1Rnyfa5pPb91izBOatXlqDUp2djbWr1+PlJQUq8tbWlowb948PP74413eNyMjA/n5+di5cye2bt2Kffv24e677+7tUNzqYGEtNHojolVKoaq7oMp6mefrP0oAAHOTol0+PkI8XbA/f6KxcwMUg5GhtllcSzwAMH5gMABgTKzK5gP7+N08u09VoakPyzz8nIf24wwKx3FCFqXRPJfeXoPCt7v3yAxKU1MTMjIysGHDBoSEWDfhWrFiBR577DFMnjy50/ueOHEC27dvx7vvvotJkyZh6tSpeOONN7B582aUlvYt2ncHvv5k+sgIof10QVV7NqhS3YZfzpiWgK4fH+f6ARLi4UKFE42du8RT16KFkZkyFaEiOrk3PTkG/5g3Ev+3KKXnG5slxqgwJNwfWr0RPx2v6PkOXeCzwf3pJOPO8NuNed6fQTHVPXlkH5TMzEykp6dj9uzZdt83KysLwcHBmDhxonDZ7NmzIZFIcPDgwU7vo9FooFarrb7EYu8pU/AxfWQEhkaYApRzFgHKt7mlMDLTyagJ4f5uGSMhnozfauzsJR6+/iTEzwcyqXjK82RSCe6fPgxjYm3vKcRxnJBF6ctuHlriMZk0JBT+Pu3Fyt6eQfHx1AzK5s2bcfjwYaxevbpXT1heXo7ISOtoVCaTITQ0FOXl5Z3eZ/Xq1QgKChK+4uPje/XcjlZU04Jz1c2QSThMGRaOIRGmAMRyiefLwxcBANenUvaEkN7gm7U5e4lHbE3a+orfzbPvdBUaellgTEWyJgqZVOgqG+qmc5pcySNrUIqLi7F8+XJs2rQJSqXrij1XrVqFhoYG4au4uNhlz92dPadNyzupg0KgUsqFDAq/xHO8VI2T5Y3wkUqwMDnWbeMkxJPxywu1Tl7i4QOUCJHs4OmrEVEBGBYZAK3BiFd3nu7VNu06ClAEfB3K4H6QCed38bh7iceuMDAnJweVlZVITU0VLjMYDNi3bx/efPNNaDQaSKXdNxmLjo5GZaX11je9Xo/a2lpER3deRKpQKKBQiO9FY4/F8g4ADI00/eIW17ZAozfgK3P2ZNboSAT18xQpIb0VInSTdXIGpVFcXWT7iuM4LLtiMB79Mg8fHDiP8zXNeP2W8Xa1rOc7+Ib0s5OMO3Pd+DjUNmv7xensfAZF40lLPLNmzUJeXh5yc3OFr4kTJyIjIwO5ubk9BicAkJaWhvr6euTk5AiX7dq1C0ajEZMmTbL/J3CTNp0BBwpMzdemjzAtWUUEKBColMHIgD+K6vFZtinTsyh1gNvGSYinc9V5PGI6KNBRbr5sIF6/ZRwUMgn2nKrCdev240xFo033NRoZZVAsSCUclk0b0i/OF/PIDEpgYCCSkpKsLvP390dYWJhweXl5OcrLy3H27FkAQF5eHgIDAzFw4ECEhoZi9OjRmDdvHpYtW4a3334bOp0ODzzwAG655RbExnrOMsihwlq06YyIUikwOiYQgOkTy5CIABwprsfjX+WhUaPHmFhVhwpwQojtQvxds4unygsDFAC4dlwchkYE4J6PclBY3Yw/v3UAr9w0FnPGdN/2oLFND35VqL8XyfY3Qg2KJ2VQbPH2229j/PjxWLZsGQBg2rRpGD9+PL777jvhNps2bcKoUaMwa9YsLFiwAFOnTsU777zj6KE4Fb+8c+WICKuzdYaaC2X5lver5o+GpB8eskWIo/Cf3p2dQRG6yHpJkaylpLggfPfAnzBpcCiaNHrc/VEOjpU0dHsffr79faRQyOh8sP7ExxMzKJ3Zs2eP1fdPPfUUnnrqqW7vExoaik8++aSvT+1We0/z/U+ssyN8oSwAXDE8nM7eIaSPgoUlHmcXyZprULykSPZSYQEKfHzXJGRsOIhD52vx+/nabpcr+AAlmJZ3+h06LNCDFde2oKCqGVIJhz9dcrYOH6BwHPDY/FHuGB4hXoVvmlbfou1wzpUjVYvsoEBnkEslwpI0v6TVFaH+hApk+532bcbuPSzQuzdzOwl/OGDqwOAOFfFTh4cjbUgYpgwNs6uxEiGkc3yAojcy1DRrnVIjYjQyoWuqt2wz7gp/HliluocAxVzzQwWy/Y9YDgukAKUX9p7qfHkHAAIUMnx6d+dt/gkh9lPIpIgL9kVJfSvOVzc7JUCpa9EKfULE1ObeGfgMUWWjjRkUClD6HT6D4u4aFFrisZNGb8AB8+nFV5o7CxJCnCsh3HT2SWF1cw+37B1+uSPETy58evRWESrbAhShBwrt4Ol3PLbVfX+XXViHFq0BEYEKjIlVuXs4hPQLfPdOZwUo3takrTuR5iWsqsa2bm9XS0Wy/ZZYthnTEo+d+NOLL91eTAhxnoQwU4ByvsZJAYqX9kDpTGSgqQalplkLvcHY5cGI7efwUAalv7nnyqG458qhkLm5RQZlUOzEF8jy7e0JIc7HH8R5rso5AUpZgymb4K1bjC2F+ftAKuHAWPvW6s4IRbJeXpNDOpJLJZBLJW7/EE4ZFDtcrGvB2comSDjgimEUoBDiKnwG5UJNC4xG5pDmh3qDET+frMQnB4uw74zpg0e0yvsDFImEQ3iADyrUGlQ2tiE6qPODX6lIlrgbBSh22CtsLw6hw/8IcaH4UD9IJRxadQZUNLYhJsi3149VWt+KzdnF+Cy7CBUWW22vGB6OxZMTHDBa8YsMVJoClC62GhuNTFj2ogCFuAsFKHawbG9PCHEduVSC+BBfnK9pQWF1c68ClNziery56wx2nawUzpgJ8/fBjRPj8ZfL4zHInKXpD/hC2a528vx0ogLVTVoEKGQYHNF/5oWICwUoNtIbjDhw1nx6cSf9TwghzjU43F8IUKYMtf8IicxNh1FS3woASBsShlsnDcScMVH98pyZCCFA6biThzGGN3ebDntdnDYIAQp6myDuQb95Nqpt0aJZa4CEAxJpezEhLpcQ7g+cqsL5Xmw1rlS3oaS+FRwH7FgxDcOjAp0wQs/RXQZl35lqHL3YAKVcgrumDnb10AgR0C4eG/FNi4J85ZDS6cSEuNyQPvRCyS9VAzCdldXfgxMAiDC3u6+6JEBhjOGNn88AADImDUJYP9h2TcSLAhQb1TVTRTsh7jQ43HQQZ28ClGMlDQCA5G5O7+1Pusqg/HauFr9fqIOPTIK7pw1xx9AIEVCAYiP+qPdg2r1DiFvw7e6Lalugt/OMkGOlpgCFuj+bCN1k1dY1KG/uNmVPbp4YjyhV59uPCXEVClBsVE9tnwlxq9ggX/jIJNAZGErru2/TfqljJaYlniTKoABoP9G4qkkDxkxbmnIu1GH/2RrIJBzuuZKyJ8T9KECxEWVQCHEviYRDQpgpi3Kuusnm+9U1a4XdO1TgbsKfaKwzMOG1bZ155871qXEYEOLntrERwqMAxUb11FWRELfjDw20ZycPv7yTEOYHlZI+YACmw+D4M3YqG9twrKQBu05WQsIB908f5ubREWJC24xtVEcHZxHidgm92MnDL++MoeUdKxGBCtS16FCp1uCTg0UAgGvGxgpzTIi7UQbFRu1LPJRBIcRdhK3GNS0234fPoCTFUoBiiT/VeP/ZamzPLwfHAZkzKHtCxIMCFBvREg8h7scfGlhoRw1KPm0x7hS/k+f9/ecBAPOToqlHDBEVClBsxGdQaImHEPfhz4UpqWuFRm/o8fbqNh3Om7MttMXYWoT55Gatecs2ZU+I2FCAYiPaZkyI+0UEKODvI4WRAcW1PS/zHDd3kI0L9kWIP/3tWuKXeABg1qhIjKElMCIyFKDYgDEmtLoP8acMCiHuwnGckEUprO45QDld0QgAGB1DSxeX4pd4AOCBmZQ9IeJDAYoNGjV66M3ns1MNCiHuZU8dyrkq026foREBTh2TJ0odFAJfuRRXj43F+IEh7h4OIR3QNmMb1DebsidKuQRKef87mp0QMbHn0MCCKlMQMySCts5eKi7YF0eenEOHnxLRogDFBnW0g4cQ0Whf4uk5QKEMSvd8ZJREJ+LVp9/ONWvWgOM4rFixQrisra0NmZmZCAsLQ0BAABYtWoSKigqr+xUVFSE9PR1+fn6IjIzEI488Ar1e35ehOFUdFcgSIhrtSzzdByitWoPQ4n4IBSiEeJxeByjZ2dlYv349UlJSrC5fuXIlvv/+e3zxxRfYu3cvSktLcf311wvXGwwGpKenQ6vV4sCBA/jwww/xwQcf4F//+lfvfwonq6ctxoSIBt/uvkKtQbOm6w82fAAT7CdHKO3gIcTj9CpAaWpqQkZGBjZs2ICQkPbiqoaGBrz33nt45ZVXMHPmTEyYMAHvv/8+Dhw4gN9++w0AsGPHDhw/fhwff/wxxo0bh/nz5+PZZ5/FunXroNVqO30+jUYDtVpt9eVKtMRDiHgE+/kIHxbO13SdReEPFBxCrdsJ8Ui9ClAyMzORnp6O2bNnW12ek5MDnU5ndfmoUaMwcOBAZGVlAQCysrKQnJyMqKgo4TZz586FWq1Gfn5+p8+3evVqBAUFCV/x8fG9GXav0UnGhIhL+6GBXW815utPaHmHEM9kd4CyefNmHD58GKtXr+5wXXl5OXx8fBAcHGx1eVRUFMrLy4XbWAYn/PX8dZ1ZtWoVGhoahK/i4mJ7h90n1OaeEHFpPzSw663GtIOHEM9m1y6e4uJiLF++HDt37oRSqez5Dg6iUCigUCh6vqGTUAaFEHFp32psQwYlnDIohHgiuzIoOTk5qKysRGpqKmQyGWQyGfbu3Yu1a9dCJpMhKioKWq0W9fX1VverqKhAdHQ0ACA6OrrDrh7+e/42YkMZFELEpasMSs6FOlQ2toExhnPmDMqwSMqgEOKJ7ApQZs2ahby8POTm5gpfEydOREZGhvBvuVyOn3/+WbjPqVOnUFRUhLS0NABAWloa8vLyUFlZKdxm586dUKlUSExMdNCP5VhCkSy1uSdEFIQalJr2DMrJcjUW/ecAbnw7CxfrWtGsNUAq4TAwlAIUQjyRXUs8gYGBSEpKsrrM398fYWFhwuVLly7FQw89hNDQUKhUKjz44INIS0vD5MmTAQBz5sxBYmIiFi9ejBdffBHl5eV44oknkJmZ6dZlnO7UC0s8lEEhRAz4Xii1zVo0tOgQ5CfH0YsNAIALNS148jtTwX18iC81IyPEQzn8L/fVV1/FwoULsWjRIkybNg3R0dH46quvhOulUim2bt0KqVSKtLQ03HbbbViyZAmeeeYZRw/FYdr7oFCAQogY+CtkiFKZPtAUmrcan7do3LbrpClDSzt4CPFcfW51v2fPHqvvlUol1q1bh3Xr1nV5n0GDBmHbtm19fWqX0OqNaDI3g6JGbYSIR0KYPyrUGhRWN2FcfHCnPVGoBwohnotynz2obzXVn0g4QKWkAIUQsRgSYb2Th9+1c8eUBIvbUAaFEE9FAUoP+OWdIF85JHTqJyGiMdjiVGOjkeGCuWD29ikJSE+OgY9UgrShYe4cIiGkD+g04x7UNdMWY0LEiC+UPV/djIrGNrTqTLt2BoT4Yu1fxkOrN8LXR+rmURJCeosClB5QkzZCxKl9iacZheblnfgQX8ilpsQwBSeEeDZa4ukBNWkjRJziQ/0g4YAmjR7Z5+sAtC/7EEI8HwUoPaijHiiEiJJCJkVciC8AYPcp07biBApQCPEaFKD04HRFIwBggPmFkBAiHnwdypGL9QAog0KIN6EApQeHi0yp4wmDQtw8EkLIpfg+J4yZvqcAhRDvQQFKN6oaNbhQ0wKOA8YNDHb3cAghl7h0SYfPqBBCPB8FKN3gsycjIgOpSRshImSZMfGRSRAbTEuxhHgLClC6wQcoqbS8Q4goWQYog0L9IKVmioR4DQpQunH4gjlAoeUdQkQpLtgXcqkpKKEdPIR4FwpQuqDVG4Xj26lAlhBxkkklGBjqB4AOBiTE21CA0oXjZWpo9EaE+MlpZwAhIjYqRmX+b6CbR0IIcSRqdd+FHGF5JwQcR+vahIjVE+mjMX1EBNKTY909FEKIA1GA0gUqkCXEM8QE+eLGifHuHgYhxMFoiacLf1hkUAghhBDiWhSgdKJNZ0BpQxsAYFQ0rWsTQgghrkYBSifKzMGJn48UwX7UoI0QQghxNQpQOlFa3woAiA32pQJZQgghxA0oQOlEiTlAiQlSunkkhBBCSP9EAUonyupNSzxxdK4HIYQQ4hYUoHTCcomHEEIIIa5HAUonShsoQCGEEELciQKUTvA1KLFUg0IIIYS4BQUol2CMCTUolEEhhBBC3MOuAOU///kPUlJSoFKpoFKpkJaWhh9++EG4vqCgAH/+858REREBlUqFm266CRUVFVaPUVtbi4yMDKhUKgQHB2Pp0qVoampyzE/jAPUtOrTqDACAaMqgEEIIIW5hV4AyYMAArFmzBjk5Ofj9998xc+ZMXHvttcjPz0dzczPmzJkDjuOwa9cu7N+/H1qtFldffTWMRqPwGBkZGcjPz8fOnTuxdetW7Nu3D3fffbfDf7De4pd3wgMUUMqlbh4NIYQQ0j9xjDHWlwcIDQ3FSy+9hPj4eMyfPx91dXVQqUzHnzc0NCAkJAQ7duzA7NmzceLECSQmJiI7OxsTJ04EAGzfvh0LFizAxYsXERtr22mkarUaQUFBaGhoEJ7LUXbkl+Puj3IwdkAQvn1gqkMfmxBCCOnP7Hn/7nUNisFgwObNm9Hc3Iy0tDRoNBpwHAeFQiHcRqlUQiKR4NdffwUAZGVlITg4WAhOAGD27NmQSCQ4ePBgl8+l0WigVqutvpylVGjSRvUnhBBCiLvYHaDk5eUhICAACoUC9957L77++mskJiZi8uTJ8Pf3x6OPPoqWlhY0Nzfj73//OwwGA8rKygAA5eXliIyMtHo8mUyG0NBQlJeXd/mcq1evRlBQkPAVH++8o9X5c3ioQJYQQghxH7sDlJEjRyI3NxcHDx7Efffdh9tvvx3Hjx9HREQEvvjiC3z//fcICAhAUFAQ6uvrkZqaComkb5uFVq1ahYaGBuGruLi4T4/XHWGLcTAVyBJCCCHuIrP3Dj4+Phg2bBgAYMKECcjOzsbrr7+O9evXY86cOSgoKEB1dTVkMhmCg4MRHR2NIUOGAACio6NRWVlp9Xh6vR61tbWIjo7u8jkVCoXV0pEz8Us81OaeEEIIcZ8+90ExGo3QaDRWl4WHhyM4OBi7du1CZWUlrrnmGgBAWloa6uvrkZOTI9x2165dMBqNmDRpUl+H4hCl5h4oMRSgEEIIIW5jVwZl1apVmD9/PgYOHIjGxkZ88skn2LNnD3788UcAwPvvv4/Ro0cjIiICWVlZWL58OVauXImRI0cCAEaPHo158+Zh2bJlePvtt6HT6fDAAw/glltusXkHjzPpDEZUNPI1KLTEQwghhLiLXQFKZWUllixZgrKyMgQFBSElJQU//vgjrrrqKgDAqVOnsGrVKtTW1iIhIQH//Oc/sXLlSqvH2LRpEx544AHMmjULEokEixYtwtq1ax33E/VBhboNjAE+UgnC/V2zpEQIIYSQjvrcB8UdnNUH5VBhLW5an4VBYX7Y+8gMhz0uIYQQQlzUB8UblQqHBFL9CSGEEOJOFKBYULfpIJdyiKH6E0IIIcSt7N5m7M2WpCXgtkmD0KY3uHsohBBCSL9GGZRLSCQc/HwobiOEEELciQIUQgghhIgOBSiEEEIIER0KUAghhBAiOhSgEEIIIUR0KEAhhBBCiOhQgEIIIYQQ0aEAhRBCCCGiQwEKIYQQQkSHAhRCCCGEiA4FKIQQQggRHQpQCCGEECI6HnnoDGMMAKBWq908EkIIIYTYin/f5t/Hu+ORAUpjYyMAID4+3s0jIYQQQoi9GhsbERQU1O1tOGZLGCMyRqMRpaWlCAwMBMdxTnkOtVqN+Ph4FBcXQ6VSOeU5vAnNl21onuxD82Ufmq+e0RzZx9HzxRhDY2MjYmNjIZF0X2XikRkUiUSCAQMGuOS5VCoV/RLbgebLNjRP9qH5sg/NV89ojuzjyPnqKXPCoyJZQgghhIgOBSiEEEIIER0KULqgUCjw5JNPQqFQuHsoHoHmyzY0T/ah+bIPzVfPaI7s48758sgiWUIIIYR4N8qgEEIIIUR0KEAhhBBCiOhQgEIIIYQQ0aEAhRBCCCGiQwEKIQ7U1NTk7iEQL0X7GWxD8+Q9+mWAUlBQgKeeegpnz55191A8wvnz53Hffffhxx9/dPdQROvChQuYO3cuHn30UQCm4xhI18rLy/H777+jpKTE3UPxCHV1dVbBL70Jd666uhpVVVUwGAwAaJ56otfrAYj39apfBSiMMdx3330YPnw4ysrKXNYu35M9/vjjGD16NKqrq9HS0kJ/8JdgjOGee+7BsGHD8Ntvv2Hv3r0wGo09njHRn/3tb39DcnIy7rrrLiQnJ+Onn35y95BE7cEHH8Rll12Gq6++GosXL0ZZWZnTziDzZJmZmUhOTsacOXMwd+5cnD17luapG8uXL0d6ejoAiPb1SpyjcoJPP/0U4eHhOHToEA4dOoT169dDqVQCoCi7K7t27cLevXvxzTff4IsvvsCf//xn+oO38MorryA4OBi5ubk4fPgwXnjhBcjlclRUVLh7aKLU1taGW265BTk5Odi2bRs+++wzzJgxA4899pi7hyZKTU1NuPrqq/HHH39g48aNWLx4MQoLC5Geno5jx465e3ii8ve//x1ZWVnYvHkzHn74YWi1Wlx//fX45Zdf3D000Tlx4gTS09Px7bffYufOndi0aRMAkWZRWD8xd+5clpCQwEpLSxljjOXl5bEff/yRFRQUsObmZsYYY0aj0Z1DFJ3FixezxYsXM8YYy8rKYv/85z/Zxo0b2enTp908Mvc7ffo0mzZtGnv//feFy/bu3cs4jmPFxcWMMfp9utTRo0fZyJEj2datW4XLPv/8czZz5kym1WrdODJx+uWXX1hiYiLLzc0VLispKWFyuZwtW7aMXbx40Y2jEwej0ciam5vZZZddxp566inh8paWFjZ+/Hh26623srNnz7pxhOLz5ZdfsqVLl7Jdu3axFStWsOjoaNH+/fWbDMqLL74IiUSCt956CzfccAOuvvpqPPzww5g6dSqWLVsGAJQdMDMajWhpaUFpaSnmzJmDV199Fddeey2OHTuG5557DjNnzsSXX37p7mG61aBBg7Bnzx7ccccdAExZuODgYAwZMgS7d+8GQL9PlzIajTh9+rTQMrupqQkvv/wy4uPj8f7771OB8SWqqqpw4cIFjB071uqy0NBQ7Nq1C3v27HHf4ESC4zjU1dWhuLgYqampAACtVgtfX1+sWrUKeXl5+N///ufmUYoDnyGZPn06Hn74YcyYMQPLly+HRCLBv/71L6vbiIVXBiirV6/GypUrsX79emi1WgBASkoKFixYgBdffBE+Pj744osv8PHHH+PVV1/FN998g+eeew5A/1zuuXS+JBIJ/Pz8AAAbN27EkSNH8Omnn2LLli0oKChAamqqcHl/cekc+fj4gOM44Q+a4zhERERAo9FAo9EA6J+/S7zO/gbHjh2L+fPn46677kJ6ejpCQkIQGBiIkJAQ/Otf/0JGRgZ+//13N4/cPTqbr7i4OMTGxgpvHgDwzjvv4NZbb4VSqcQPP/wAoH/9nn311VdQq9XC94wxxMXFISEhAZs3bwbQXk9x4403Ch8Yqqqq3DJed7OcL35eQkNDMXr0aABAfHw8Vq1ahVdeeQVFRUWQSCTi+n1yZ/rG0U6ePMkSExNZcnIyu/nmm1lISAibPn06+/XXXxljjDU0NLDHH3+cnTt3zup+L730EgsODmY6nc4dw3abrubrwIEDjDHGPv30UyaXy1l8fLxVOjknJ4fFxMSwn376yV1Dd5mu5ui3336zup3BYGCMMTZ16lR2++23M8b65xJPV/O1f/9+xhhjra2t7OzZs2zGjBlWKfnTp0+zoUOHsg8++MBdQ3eLzuZr2rRp7I8//mAGg4G9/vrrjOM4NmXKFKZSqdiwYcOYWq1mH330EQsJCXH38F1m9+7dbOTIkYzjOLZ+/Xrhcv5v7L333mNyuVxYfm5tbWWMMbZjxw6mVCr73XJYV/PVmaqqKjZx4kR23XXXuWh0tvOqDMr//vc/BAUF4fDhw9i8eTOOHz+Ouro6rF27FqdPn4ZKpcKjjz6KwYMHW90vLi4OPj4+OHHihJtG7h5dzderr76KoqIizJw5E9OnT4dMJrPatjd+/HhoNBoUFRW5+Sdwvq7m6JVXXkFBQQEACLt2tFotRowYgaqqKjQ1NfXLJZ6u5uv111/H2bNnoVQq0dbWhpKSEtx5550ATPM3fPhwtLS0oLCw0M0/gWt1Nl8NDQ144YUXcOHCBfztb3/D7t27kZGRgU8++QRnzpxBYGAg1Go1hgwZgpqaGnf/CE534sQJvP3225g9ezaWLVuG559/HmVlZQDal1FnzJiBSZMm4f777wcAYQNEQkICFAoFTp065Z7Bu0F389WZ8PBwPPnkk/j222+xb98+AMCOHTtw+vRpVw25S14ToOj1euTn5yMyMhJSqRQAEB0djX/+858oKirCBx98AABQqVQd7puVlYXJkycjOTnZlUN2q57ma8OGDYiMjMTDDz+MiooKvPHGGyguLgbHcdi2bRuGDRuG2bNnu/mncK6e5ui9994DYEqdGo1G+Pj4IDw8HGVlZQgICBBXqtQFbJ0vlUqFwsJCnDt3DoBp/nbs2IHo6GjMmTPHbeN3tZ7m65133gEAXHnllbj//vuFLaEGgwH79+9HSkoKwsLC3DZ+VwkNDcVVV12FzMxMvPzyyzAYDPj3v/9tdZuEhAQ8/vjj+OWXX/DSSy8JSzp79uzB8OHDcdlll7lj6G5hy3xdatasWbj55ptx++23Y/LkybjuuutQX1/vmgF3x90pHEfKyMhgc+bMYXq9nun1euHyzMxMNnPmTHb48GHhsgsXLrDCwkKWmZnJ4uPj2ZYtWxhj/Sst3918TZ8+nR05coQxxti7777LYmNj2bBhw9iiRYtYQEAAe/zxx4VlDW9m6+8Uvzz4448/MolE0m93DnQ3XzNmzGBHjhxhOp2O/fWvf2U+Pj5s2bJl7K9//SsLDAxkjzzyiNV9+gN7XrNOnz7Nzp49y+655x42cOBAtmvXLsZY/3jNsnyt2bhxI1MoFFa7m3gbNmxgUVFRbPTo0eyGG25gCoWCPffcc8xoNPaLeeLZOl+8M2fOsKuuuopxHMfuuusuplarXTHMHnlFgML/Ye/evZtJJBL2xx9/MMba3zT27NnDhg0bxj7//HPGmOkP/eGHH2bR0dEsLS2NHT161C3jdhdb5mvo0KHss88+E+6TnZ3N1q9fzx599FEhcPFm9v5O8bZs2cKWLl3Kqqur+9ULoq2/U1988QVjjLG2tjb2+OOPs7/+9a/s1ltv7Re/U5Z68/v11ltvsREjRrBJkyb1u9csxqwDsUmTJrFrrrmm07rB/fv3s7Vr17IVK1Z0+6bs7Wydr5MnT7LLLruMjRkzhh07dsyVQ+yRxwQo58+fF/pLXPopi5/01tZWduWVV7LZs2czxqz/Bw0dOpQ9/fTTjDHTHvndu3ezn3/+2RVDdwtHzNczzzzjotG6hyPniL+/Nwcljvwb5HlzxsTRf4M1NTUsOzvb2cN2OVvmicfPz759+5hEImHfffedcL/KykoXjNb9HDVfVVVVjDHG6uvrRRvIeUSA8s033zCO4zpUGVv+z9Hr9ay8vJzt2bOHyeVy9p///EdIc9XW1rKUlBT25ptvunTc7kLz1TOaI/vQfNmH5ss2tsyTTqdj5eXlHe6bkZHBJkyYwH766Sc2d+5c9sQTT4i24ZijOHq+2tranD7mvvCIItlDhw5h0qRJKCoqEhqEGQwGobBs7dq18PPzw/bt23HllVfiySefxJNPPol77rkHv/zyC5599lk0NjZi1qxZ7vwxXIbmq2c0R/ah+bIPzZdtbJmngIAA/PDDDx2KzjMzM3H48GFcddVVAICHHnoIcrnctT+Aizl6vvimiaLl7gipO/yniczMTPbggw+ypUuXsiuuuEKIkuvr61lGRgaLjY1lH374oVV6dO3ateyKK65gycnJbOzYsezgwYNu+RlciearZzRH9qH5sg/Nl23smaf//ve/VvOk1+vZhx9+yORyOZs0aZJVIbG36q/zJeoAhTHTGtrcuXPZb7/9xrZu3coSExPZ66+/zhgz/U/Jzs62qji2rF42GAwdmrJ5O5qvntEc2Yfmyz40X7axd554zc3N7LXXXuuxAZm36Y/zJXN3Boe3ZcsWBAcHY8yYMYiJiQHQnrqSSqXQarWYPHkyrr/+erz33ns4ePAgkpOT8dBDD8HHx0d4HMtjoyUSSYembN6C5qtnNEf2ofmyD82XbRw1Tzw/Pz8sX77c1T+Gy9B8WXB3hPTf//6XRUZGsssvv5xFRESwP/3pT+zrr78Wrq+trWXR0dFMo9EwxhhbuXIlUyqVzNfXl/3+++9uGrX70Hz1jObIPjRf9qH5sg3Nk31ovjpyW4Ci0+nYa6+9xkaPHs3effddptFo2P79+9mSJUvY/PnzherikpISdvPNN7NPP/2UJScns/DwcLZw4UI2atQoYcudN29V5NF89YzmyD40X/ah+bINzZN9aL665rYApb6+nv3zn/9ka9assVqDXbNmDfvTn/7EGhsbGWOMFRUVMY7jmFwuZ5mZmayuro7l5+ezefPmsalTp7pr+C5H89UzmiP70HzZh+bLNjRP9qH56ppLa1DOnDmDYcOGgeM4BAUF4YYbbkBycrJwlolEIkF8fDyam5uFtbT4+Hh8+umnGDx4MC6//HIAQHBwMK677jo0NjYKW6m88WA2mq+e0RzZh+bLPjRftqF5sg/Nl41cEQV99tlnLCEhgY0cOZJdfvnl7N1337W63jJqvPXWW9kdd9zBGGOdNt3ht095WyrLEs1Xz2iO7EPzZR+aL9vQPNmH5ss+Tg9QduzYwRISEti6devY9u3b2UMPPcTkcjl75513WGtrK2OMCQc5tba2spSUFPbRRx91eBxv/p9giearZzRH9qH5sg/Nl21onuxD82U/pwUofHT39NNPswkTJlhFgPfffz+bOHEi++qrr6zuU1JSwhISEtjp06cZY6ZD/VauXOmsIYoKzVfPaI7sQ/NlH5ov29A82Yfmq/ec1uqeXwc7fvw4hg4dCrlcDp1OBwB47rnnoFQq8e2336K8vFy4z08//YT4+HjExMRg+fLlSExMxIULF6DT6Tq07fU2NF89ozmyD82XfWi+bEPzZB+arz5wVKSzY8cO9uCDD7JXX33VqkXzO++8wwIDA4W0FB89vvPOO2zEiBFs9+7djDFTlHnjjTeykJAQFhYWxsaMGeOVJ3fyaL56RnNkH5ov+9B82YbmyT40X47T5wCltLSULVy4kEVGRrKMjAyWnJzMgoKChP8xp06dYnFxcez//b//xxhjQpMZxhiLjo5mr776KmPM1I534cKFbMCAAWzz5s19HZZo0Xz1jObIPjRf9qH5sg3Nk31ovhyvTwFKc3Mzu/3229nNN99sdX7E5ZdfLlQfq9Vq9txzzzFfX19WVFTEGGtfk7vyyivZXXfdJdzPW7vh8Wi+ekZzZB+aL/vQfNmG5sk+NF/O0acaFD8/PygUCtxxxx0YPHgw9Ho9AGDBggU4ceIEGGMIDAzErbfeitTUVNx00024cOECOI5DUVERKisrcd111wmPN2HChD4tV4kdzVfPaI7sQ/NlH5ov29A82Yfmyzk4xvpWcaPT6SCXywFAaDCTkZEBf39/vPPOO8LtSkpKMH36dOj1ekycOBEHDhzAqFGj8MknnyAqKqpvP4UHofnqGc2RfWi+7EPzZRuaJ/vQfDlenwOUzkydOhXLli3D7bffDqPRCMB0SufZs2eRk5ODgwcPYuzYsbj99tsd/dQeiearZzRH9qH5sg/Nl21onuxD89VHjl4zKigoYFFRUVZraJbFQMQazVfPaI7sQ/NlH5ov29A82Yfmq+8c1geFmRMxv/76KwICAoQ1tKeffhrLly9HZWWlo57KK9B89YzmyD40X/ah+bINzZN9aL4cx2GHBfLNaA4dOoRFixZh586duPvuu9HS0oKPPvoIkZGRjnoqr0Dz1TOaI/vQfNmH5ss2NE/2oflyIEemY1pbW9mwYcMYx3FMoVCwNWvWOPLhvQ7NV89ojuxD82Ufmi/b0DzZh+bLMRxeJHvVVVdh+PDheOWVV6BUKh350F6J5qtnNEf2ofmyD82XbWie7EPz1XcOD1AMBgOkUqkjH9Kr0Xz1jObIPjRf9qH5sg3Nk31ovvrOKduMCSGEEEL6wmmnGRNCCCGE9BYFKIQQQggRHQpQCCGEECI6FKAQQgghRHQoQCGEEEKI6FCAQgghhBDRoQCFEEIIIaJDAQohhBBCRIcCFEKIU9xxxx3gOA4cx0EulyMqKgpXXXUVNm7cCKPRaPPjfPDBBwgODnbeQAkhokQBCiHEaebNm4eysjKcP38eP/zwA2bMmIHly5dj4cKF0Ov17h4eIUTEKEAhhDiNQqFAdHQ04uLikJqaiscffxzffvstfvjhB3zwwQcAgFdeeQXJycnw9/dHfHw87r//fjQ1NQEA9uzZgzvvvBMNDQ1CNuapp54CAGg0Gvz9739HXFwc/P39MWnSJOzZs8c9PyghxOEoQCGEuNTMmTMxduxYfPXVVwAAiUSCtWvXIj8/Hx9++CF27dqFf/zjHwCAKVOm4LXXXoNKpUJZWRnKysrw97//HQDwwAMPICsrC5s3b8bRo0dx4403Yt68eThz5ozbfjZCiOPQYYGEEKe44447UF9fj2+++abDdbfccguOHj2K48ePd7huy5YtuPfee1FdXQ3AVIOyYsUK1NfXC7cpKirCkCFDUFRUhNjYWOHy2bNn4/LLL8cLL7zg8J+HEOJaMncPgBDS/zDGwHEcAOCnn37C6tWrcfLkSajVauj1erS1taGlpQV+fn6d3j8vLw8GgwEjRoywulyj0SAsLMzp4yeEOB8FKIQQlztx4gQGDx6M8+fPY+HChbjvvvvw/PPPIzQ0FL/++iuWLl0KrVbbZYDS1NQEqVSKnJwcSKVSq+sCAgJc8SMQQpyMAhRCiEvt2rULeXl5WLlyJXJycmA0GvHvf/8bEompJO7zzz+3ur2Pjw8MBoPVZePHj4fBYEBlZSWuuOIKl42dEOI6FKAQQpxGo9GgvLwcBoMBFRUV2L59O1avXo2FCxdiyZIlOHbsGHQ6Hd544w1cffXV2L9/P95++22rx0hISEBTUxN+/vlnjB07Fn5+fhgxYgQyMjKwZMkS/Pvf/8b48eNRVVWFn3/+GSkpKUhPT3fTT0wIcRTaxUMIcZrt27cjJiYGCQkJmDdvHnbv3o21a9fi22+/hVQqxdixY/HKK6/g//7v/5CUlIRNmzZh9erVVo8xZcoU3Hvvvbj55psRERGBF198EQDw/vvvY8mSJXj44YcxcuRIXHfddcjOzsbAgQPd8aMSQhyMdvEQQgghRHQog0IIIYQQ0aEAhRBCCCGiQwEKIYQQQkSHAhRCCCGEiA4FKIQQQggRHQpQCCGEECI6FKAQQgghRHQoQCGEEEKI6FCAQgghhBDRoQCFEEIIIaJDAQohhBBCROf/AwFA5wX1LNBBAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist.Close.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = yf.Tickers('msft aapl goog')\n",
    "\n",
    "msft=tickers.tickers['MSFT'].history(period='1mo')\n",
    "apple=tickers.tickers['AAPL'].history(period=\"1mo\")\n",
    "goo=tickers.tickers['GOOG'].history(period=\"1mo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_msft</th>\n",
       "      <th>High_msft</th>\n",
       "      <th>Low_msft</th>\n",
       "      <th>Close_msft</th>\n",
       "      <th>Volume_msft</th>\n",
       "      <th>Dividends_msft</th>\n",
       "      <th>Stock Splits_msft</th>\n",
       "      <th>Open_apple</th>\n",
       "      <th>High_apple</th>\n",
       "      <th>Low_apple</th>\n",
       "      <th>...</th>\n",
       "      <th>Volume_apple</th>\n",
       "      <th>Dividends_apple</th>\n",
       "      <th>Stock Splits_apple</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-09-30 00:00:00-04:00</th>\n",
       "      <td>428.209991</td>\n",
       "      <td>430.420013</td>\n",
       "      <td>425.369995</td>\n",
       "      <td>430.299988</td>\n",
       "      <td>16807300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.039993</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>229.649994</td>\n",
       "      <td>...</td>\n",
       "      <td>54541900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.779999</td>\n",
       "      <td>167.360001</td>\n",
       "      <td>164.639999</td>\n",
       "      <td>167.190002</td>\n",
       "      <td>14070100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00-04:00</th>\n",
       "      <td>428.450012</td>\n",
       "      <td>428.480011</td>\n",
       "      <td>418.809998</td>\n",
       "      <td>420.690002</td>\n",
       "      <td>19092900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.520004</td>\n",
       "      <td>229.649994</td>\n",
       "      <td>223.740005</td>\n",
       "      <td>...</td>\n",
       "      <td>63285000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.860001</td>\n",
       "      <td>170.440002</td>\n",
       "      <td>165.899994</td>\n",
       "      <td>168.419998</td>\n",
       "      <td>18629500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-02 00:00:00-04:00</th>\n",
       "      <td>422.579987</td>\n",
       "      <td>422.820007</td>\n",
       "      <td>416.709991</td>\n",
       "      <td>417.130005</td>\n",
       "      <td>16582300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.889999</td>\n",
       "      <td>227.369995</td>\n",
       "      <td>223.020004</td>\n",
       "      <td>...</td>\n",
       "      <td>32880600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.759995</td>\n",
       "      <td>168.880005</td>\n",
       "      <td>166.250000</td>\n",
       "      <td>167.309998</td>\n",
       "      <td>12745000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-03 00:00:00-04:00</th>\n",
       "      <td>417.630005</td>\n",
       "      <td>419.549988</td>\n",
       "      <td>414.290009</td>\n",
       "      <td>416.540009</td>\n",
       "      <td>13686400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.139999</td>\n",
       "      <td>226.809998</td>\n",
       "      <td>223.320007</td>\n",
       "      <td>...</td>\n",
       "      <td>34044200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.820007</td>\n",
       "      <td>167.910004</td>\n",
       "      <td>165.369995</td>\n",
       "      <td>167.210007</td>\n",
       "      <td>11004300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-04 00:00:00-04:00</th>\n",
       "      <td>418.239990</td>\n",
       "      <td>419.750000</td>\n",
       "      <td>414.970001</td>\n",
       "      <td>416.059998</td>\n",
       "      <td>19169700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.899994</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>224.130005</td>\n",
       "      <td>...</td>\n",
       "      <td>37245100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.339996</td>\n",
       "      <td>169.550003</td>\n",
       "      <td>166.960007</td>\n",
       "      <td>168.559998</td>\n",
       "      <td>11422100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-07 00:00:00-04:00</th>\n",
       "      <td>416.000000</td>\n",
       "      <td>417.109985</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>409.540009</td>\n",
       "      <td>20919800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.500000</td>\n",
       "      <td>225.690002</td>\n",
       "      <td>221.330002</td>\n",
       "      <td>...</td>\n",
       "      <td>39505400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.139999</td>\n",
       "      <td>169.899994</td>\n",
       "      <td>164.130005</td>\n",
       "      <td>164.389999</td>\n",
       "      <td>14034700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08 00:00:00-04:00</th>\n",
       "      <td>410.899994</td>\n",
       "      <td>415.660004</td>\n",
       "      <td>408.170013</td>\n",
       "      <td>414.709991</td>\n",
       "      <td>19229300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.300003</td>\n",
       "      <td>225.979996</td>\n",
       "      <td>223.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>31855700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.429993</td>\n",
       "      <td>166.100006</td>\n",
       "      <td>164.309998</td>\n",
       "      <td>165.699997</td>\n",
       "      <td>11723900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-09 00:00:00-04:00</th>\n",
       "      <td>415.859985</td>\n",
       "      <td>420.380005</td>\n",
       "      <td>414.299988</td>\n",
       "      <td>417.459991</td>\n",
       "      <td>14974300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.229996</td>\n",
       "      <td>229.750000</td>\n",
       "      <td>224.830002</td>\n",
       "      <td>...</td>\n",
       "      <td>33591100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.854996</td>\n",
       "      <td>166.259995</td>\n",
       "      <td>161.119995</td>\n",
       "      <td>163.059998</td>\n",
       "      <td>19666400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-10 00:00:00-04:00</th>\n",
       "      <td>415.230011</td>\n",
       "      <td>417.350006</td>\n",
       "      <td>413.149994</td>\n",
       "      <td>415.839996</td>\n",
       "      <td>13848400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.779999</td>\n",
       "      <td>229.500000</td>\n",
       "      <td>227.169998</td>\n",
       "      <td>...</td>\n",
       "      <td>28183500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.110001</td>\n",
       "      <td>164.311005</td>\n",
       "      <td>161.639999</td>\n",
       "      <td>163.179993</td>\n",
       "      <td>12900500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-11 00:00:00-04:00</th>\n",
       "      <td>416.140015</td>\n",
       "      <td>417.130005</td>\n",
       "      <td>413.250000</td>\n",
       "      <td>416.320007</td>\n",
       "      <td>14144900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.300003</td>\n",
       "      <td>229.410004</td>\n",
       "      <td>227.339996</td>\n",
       "      <td>...</td>\n",
       "      <td>31759200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.330002</td>\n",
       "      <td>165.270004</td>\n",
       "      <td>162.500000</td>\n",
       "      <td>164.520004</td>\n",
       "      <td>10946000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-14 00:00:00-04:00</th>\n",
       "      <td>417.769989</td>\n",
       "      <td>424.040009</td>\n",
       "      <td>417.519989</td>\n",
       "      <td>419.140015</td>\n",
       "      <td>16653100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.699997</td>\n",
       "      <td>231.729996</td>\n",
       "      <td>228.600006</td>\n",
       "      <td>...</td>\n",
       "      <td>39882100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.910004</td>\n",
       "      <td>167.619995</td>\n",
       "      <td>164.779999</td>\n",
       "      <td>166.350006</td>\n",
       "      <td>9981800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-15 00:00:00-04:00</th>\n",
       "      <td>422.179993</td>\n",
       "      <td>422.480011</td>\n",
       "      <td>415.260010</td>\n",
       "      <td>418.739990</td>\n",
       "      <td>18900200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.610001</td>\n",
       "      <td>237.490005</td>\n",
       "      <td>232.369995</td>\n",
       "      <td>...</td>\n",
       "      <td>64751400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.139999</td>\n",
       "      <td>169.089996</td>\n",
       "      <td>166.050003</td>\n",
       "      <td>166.899994</td>\n",
       "      <td>14829300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-16 00:00:00-04:00</th>\n",
       "      <td>415.170013</td>\n",
       "      <td>416.359985</td>\n",
       "      <td>410.480011</td>\n",
       "      <td>416.119995</td>\n",
       "      <td>15508900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.600006</td>\n",
       "      <td>232.119995</td>\n",
       "      <td>229.839996</td>\n",
       "      <td>...</td>\n",
       "      <td>34082200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.029999</td>\n",
       "      <td>167.279999</td>\n",
       "      <td>165.216003</td>\n",
       "      <td>166.740005</td>\n",
       "      <td>9968500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-17 00:00:00-04:00</th>\n",
       "      <td>422.359985</td>\n",
       "      <td>422.500000</td>\n",
       "      <td>415.589996</td>\n",
       "      <td>416.720001</td>\n",
       "      <td>14820000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.429993</td>\n",
       "      <td>233.850006</td>\n",
       "      <td>230.520004</td>\n",
       "      <td>...</td>\n",
       "      <td>32993800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.380005</td>\n",
       "      <td>167.929993</td>\n",
       "      <td>164.369995</td>\n",
       "      <td>164.509995</td>\n",
       "      <td>15113400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-18 00:00:00-04:00</th>\n",
       "      <td>417.140015</td>\n",
       "      <td>419.649994</td>\n",
       "      <td>416.260010</td>\n",
       "      <td>418.160004</td>\n",
       "      <td>17145300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236.179993</td>\n",
       "      <td>236.179993</td>\n",
       "      <td>234.009995</td>\n",
       "      <td>...</td>\n",
       "      <td>46431500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.869995</td>\n",
       "      <td>166.369995</td>\n",
       "      <td>164.750000</td>\n",
       "      <td>165.050003</td>\n",
       "      <td>13091300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-21 00:00:00-04:00</th>\n",
       "      <td>416.119995</td>\n",
       "      <td>418.959991</td>\n",
       "      <td>413.750000</td>\n",
       "      <td>418.779999</td>\n",
       "      <td>14206100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234.449997</td>\n",
       "      <td>236.850006</td>\n",
       "      <td>234.449997</td>\n",
       "      <td>...</td>\n",
       "      <td>36254500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.580002</td>\n",
       "      <td>166.220001</td>\n",
       "      <td>164.304993</td>\n",
       "      <td>165.800003</td>\n",
       "      <td>11384000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-22 00:00:00-04:00</th>\n",
       "      <td>418.489990</td>\n",
       "      <td>430.579987</td>\n",
       "      <td>418.040009</td>\n",
       "      <td>427.510010</td>\n",
       "      <td>25482200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.889999</td>\n",
       "      <td>236.220001</td>\n",
       "      <td>232.600006</td>\n",
       "      <td>...</td>\n",
       "      <td>38846600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.699997</td>\n",
       "      <td>167.470001</td>\n",
       "      <td>164.669998</td>\n",
       "      <td>166.820007</td>\n",
       "      <td>11958600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-23 00:00:00-04:00</th>\n",
       "      <td>430.859985</td>\n",
       "      <td>431.079987</td>\n",
       "      <td>422.529999</td>\n",
       "      <td>424.600006</td>\n",
       "      <td>19654400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234.080002</td>\n",
       "      <td>235.139999</td>\n",
       "      <td>227.759995</td>\n",
       "      <td>...</td>\n",
       "      <td>52287000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.429993</td>\n",
       "      <td>167.600006</td>\n",
       "      <td>163.632996</td>\n",
       "      <td>164.479996</td>\n",
       "      <td>12754300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-24 00:00:00-04:00</th>\n",
       "      <td>425.329987</td>\n",
       "      <td>425.980011</td>\n",
       "      <td>422.399994</td>\n",
       "      <td>424.730011</td>\n",
       "      <td>13581600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.979996</td>\n",
       "      <td>230.820007</td>\n",
       "      <td>228.410004</td>\n",
       "      <td>...</td>\n",
       "      <td>31109500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.589996</td>\n",
       "      <td>165.050003</td>\n",
       "      <td>162.770004</td>\n",
       "      <td>164.529999</td>\n",
       "      <td>12764400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-25 00:00:00-04:00</th>\n",
       "      <td>426.760010</td>\n",
       "      <td>432.519989</td>\n",
       "      <td>426.570007</td>\n",
       "      <td>428.149994</td>\n",
       "      <td>16899100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.740005</td>\n",
       "      <td>233.220001</td>\n",
       "      <td>229.570007</td>\n",
       "      <td>...</td>\n",
       "      <td>38802300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.365005</td>\n",
       "      <td>167.399994</td>\n",
       "      <td>165.229996</td>\n",
       "      <td>166.990005</td>\n",
       "      <td>14566400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-28 00:00:00-04:00</th>\n",
       "      <td>431.660004</td>\n",
       "      <td>431.940002</td>\n",
       "      <td>426.299988</td>\n",
       "      <td>426.589996</td>\n",
       "      <td>14882400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.320007</td>\n",
       "      <td>234.729996</td>\n",
       "      <td>232.550003</td>\n",
       "      <td>...</td>\n",
       "      <td>36087100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.589996</td>\n",
       "      <td>170.606003</td>\n",
       "      <td>165.789993</td>\n",
       "      <td>168.339996</td>\n",
       "      <td>20858300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-29 00:00:00-04:00</th>\n",
       "      <td>428.000000</td>\n",
       "      <td>433.170013</td>\n",
       "      <td>425.799988</td>\n",
       "      <td>431.950012</td>\n",
       "      <td>17644100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.100006</td>\n",
       "      <td>234.330002</td>\n",
       "      <td>232.320007</td>\n",
       "      <td>...</td>\n",
       "      <td>35417200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.384995</td>\n",
       "      <td>171.860001</td>\n",
       "      <td>168.660004</td>\n",
       "      <td>171.139999</td>\n",
       "      <td>28916100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-30 00:00:00-04:00</th>\n",
       "      <td>437.440002</td>\n",
       "      <td>438.500000</td>\n",
       "      <td>432.100006</td>\n",
       "      <td>432.529999</td>\n",
       "      <td>29749100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232.610001</td>\n",
       "      <td>233.470001</td>\n",
       "      <td>229.550003</td>\n",
       "      <td>...</td>\n",
       "      <td>47070900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.410004</td>\n",
       "      <td>183.789993</td>\n",
       "      <td>175.744995</td>\n",
       "      <td>176.139999</td>\n",
       "      <td>49698300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-31 00:00:00-04:00</th>\n",
       "      <td>415.959991</td>\n",
       "      <td>416.065002</td>\n",
       "      <td>406.299988</td>\n",
       "      <td>407.075012</td>\n",
       "      <td>40516239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.229996</td>\n",
       "      <td>229.830002</td>\n",
       "      <td>226.179993</td>\n",
       "      <td>...</td>\n",
       "      <td>35461604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.654999</td>\n",
       "      <td>178.419998</td>\n",
       "      <td>172.690002</td>\n",
       "      <td>172.919998</td>\n",
       "      <td>25387584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Open_msft   High_msft    Low_msft  Close_msft  \\\n",
       "Date                                                                        \n",
       "2024-09-30 00:00:00-04:00  428.209991  430.420013  425.369995  430.299988   \n",
       "2024-10-01 00:00:00-04:00  428.450012  428.480011  418.809998  420.690002   \n",
       "2024-10-02 00:00:00-04:00  422.579987  422.820007  416.709991  417.130005   \n",
       "2024-10-03 00:00:00-04:00  417.630005  419.549988  414.290009  416.540009   \n",
       "2024-10-04 00:00:00-04:00  418.239990  419.750000  414.970001  416.059998   \n",
       "2024-10-07 00:00:00-04:00  416.000000  417.109985  409.000000  409.540009   \n",
       "2024-10-08 00:00:00-04:00  410.899994  415.660004  408.170013  414.709991   \n",
       "2024-10-09 00:00:00-04:00  415.859985  420.380005  414.299988  417.459991   \n",
       "2024-10-10 00:00:00-04:00  415.230011  417.350006  413.149994  415.839996   \n",
       "2024-10-11 00:00:00-04:00  416.140015  417.130005  413.250000  416.320007   \n",
       "2024-10-14 00:00:00-04:00  417.769989  424.040009  417.519989  419.140015   \n",
       "2024-10-15 00:00:00-04:00  422.179993  422.480011  415.260010  418.739990   \n",
       "2024-10-16 00:00:00-04:00  415.170013  416.359985  410.480011  416.119995   \n",
       "2024-10-17 00:00:00-04:00  422.359985  422.500000  415.589996  416.720001   \n",
       "2024-10-18 00:00:00-04:00  417.140015  419.649994  416.260010  418.160004   \n",
       "2024-10-21 00:00:00-04:00  416.119995  418.959991  413.750000  418.779999   \n",
       "2024-10-22 00:00:00-04:00  418.489990  430.579987  418.040009  427.510010   \n",
       "2024-10-23 00:00:00-04:00  430.859985  431.079987  422.529999  424.600006   \n",
       "2024-10-24 00:00:00-04:00  425.329987  425.980011  422.399994  424.730011   \n",
       "2024-10-25 00:00:00-04:00  426.760010  432.519989  426.570007  428.149994   \n",
       "2024-10-28 00:00:00-04:00  431.660004  431.940002  426.299988  426.589996   \n",
       "2024-10-29 00:00:00-04:00  428.000000  433.170013  425.799988  431.950012   \n",
       "2024-10-30 00:00:00-04:00  437.440002  438.500000  432.100006  432.529999   \n",
       "2024-10-31 00:00:00-04:00  415.959991  416.065002  406.299988  407.075012   \n",
       "\n",
       "                           Volume_msft  Dividends_msft  Stock Splits_msft  \\\n",
       "Date                                                                        \n",
       "2024-09-30 00:00:00-04:00     16807300             0.0                0.0   \n",
       "2024-10-01 00:00:00-04:00     19092900             0.0                0.0   \n",
       "2024-10-02 00:00:00-04:00     16582300             0.0                0.0   \n",
       "2024-10-03 00:00:00-04:00     13686400             0.0                0.0   \n",
       "2024-10-04 00:00:00-04:00     19169700             0.0                0.0   \n",
       "2024-10-07 00:00:00-04:00     20919800             0.0                0.0   \n",
       "2024-10-08 00:00:00-04:00     19229300             0.0                0.0   \n",
       "2024-10-09 00:00:00-04:00     14974300             0.0                0.0   \n",
       "2024-10-10 00:00:00-04:00     13848400             0.0                0.0   \n",
       "2024-10-11 00:00:00-04:00     14144900             0.0                0.0   \n",
       "2024-10-14 00:00:00-04:00     16653100             0.0                0.0   \n",
       "2024-10-15 00:00:00-04:00     18900200             0.0                0.0   \n",
       "2024-10-16 00:00:00-04:00     15508900             0.0                0.0   \n",
       "2024-10-17 00:00:00-04:00     14820000             0.0                0.0   \n",
       "2024-10-18 00:00:00-04:00     17145300             0.0                0.0   \n",
       "2024-10-21 00:00:00-04:00     14206100             0.0                0.0   \n",
       "2024-10-22 00:00:00-04:00     25482200             0.0                0.0   \n",
       "2024-10-23 00:00:00-04:00     19654400             0.0                0.0   \n",
       "2024-10-24 00:00:00-04:00     13581600             0.0                0.0   \n",
       "2024-10-25 00:00:00-04:00     16899100             0.0                0.0   \n",
       "2024-10-28 00:00:00-04:00     14882400             0.0                0.0   \n",
       "2024-10-29 00:00:00-04:00     17644100             0.0                0.0   \n",
       "2024-10-30 00:00:00-04:00     29749100             0.0                0.0   \n",
       "2024-10-31 00:00:00-04:00     40516239             0.0                0.0   \n",
       "\n",
       "                           Open_apple  High_apple   Low_apple  ...  \\\n",
       "Date                                                           ...   \n",
       "2024-09-30 00:00:00-04:00  230.039993  233.000000  229.649994  ...   \n",
       "2024-10-01 00:00:00-04:00  229.520004  229.649994  223.740005  ...   \n",
       "2024-10-02 00:00:00-04:00  225.889999  227.369995  223.020004  ...   \n",
       "2024-10-03 00:00:00-04:00  225.139999  226.809998  223.320007  ...   \n",
       "2024-10-04 00:00:00-04:00  227.899994  228.000000  224.130005  ...   \n",
       "2024-10-07 00:00:00-04:00  224.500000  225.690002  221.330002  ...   \n",
       "2024-10-08 00:00:00-04:00  224.300003  225.979996  223.250000  ...   \n",
       "2024-10-09 00:00:00-04:00  225.229996  229.750000  224.830002  ...   \n",
       "2024-10-10 00:00:00-04:00  227.779999  229.500000  227.169998  ...   \n",
       "2024-10-11 00:00:00-04:00  229.300003  229.410004  227.339996  ...   \n",
       "2024-10-14 00:00:00-04:00  228.699997  231.729996  228.600006  ...   \n",
       "2024-10-15 00:00:00-04:00  233.610001  237.490005  232.369995  ...   \n",
       "2024-10-16 00:00:00-04:00  231.600006  232.119995  229.839996  ...   \n",
       "2024-10-17 00:00:00-04:00  233.429993  233.850006  230.520004  ...   \n",
       "2024-10-18 00:00:00-04:00  236.179993  236.179993  234.009995  ...   \n",
       "2024-10-21 00:00:00-04:00  234.449997  236.850006  234.449997  ...   \n",
       "2024-10-22 00:00:00-04:00  233.889999  236.220001  232.600006  ...   \n",
       "2024-10-23 00:00:00-04:00  234.080002  235.139999  227.759995  ...   \n",
       "2024-10-24 00:00:00-04:00  229.979996  230.820007  228.410004  ...   \n",
       "2024-10-25 00:00:00-04:00  229.740005  233.220001  229.570007  ...   \n",
       "2024-10-28 00:00:00-04:00  233.320007  234.729996  232.550003  ...   \n",
       "2024-10-29 00:00:00-04:00  233.100006  234.330002  232.320007  ...   \n",
       "2024-10-30 00:00:00-04:00  232.610001  233.470001  229.550003  ...   \n",
       "2024-10-31 00:00:00-04:00  229.229996  229.830002  226.179993  ...   \n",
       "\n",
       "                           Volume_apple  Dividends_apple  Stock Splits_apple  \\\n",
       "Date                                                                           \n",
       "2024-09-30 00:00:00-04:00      54541900              0.0                 0.0   \n",
       "2024-10-01 00:00:00-04:00      63285000              0.0                 0.0   \n",
       "2024-10-02 00:00:00-04:00      32880600              0.0                 0.0   \n",
       "2024-10-03 00:00:00-04:00      34044200              0.0                 0.0   \n",
       "2024-10-04 00:00:00-04:00      37245100              0.0                 0.0   \n",
       "2024-10-07 00:00:00-04:00      39505400              0.0                 0.0   \n",
       "2024-10-08 00:00:00-04:00      31855700              0.0                 0.0   \n",
       "2024-10-09 00:00:00-04:00      33591100              0.0                 0.0   \n",
       "2024-10-10 00:00:00-04:00      28183500              0.0                 0.0   \n",
       "2024-10-11 00:00:00-04:00      31759200              0.0                 0.0   \n",
       "2024-10-14 00:00:00-04:00      39882100              0.0                 0.0   \n",
       "2024-10-15 00:00:00-04:00      64751400              0.0                 0.0   \n",
       "2024-10-16 00:00:00-04:00      34082200              0.0                 0.0   \n",
       "2024-10-17 00:00:00-04:00      32993800              0.0                 0.0   \n",
       "2024-10-18 00:00:00-04:00      46431500              0.0                 0.0   \n",
       "2024-10-21 00:00:00-04:00      36254500              0.0                 0.0   \n",
       "2024-10-22 00:00:00-04:00      38846600              0.0                 0.0   \n",
       "2024-10-23 00:00:00-04:00      52287000              0.0                 0.0   \n",
       "2024-10-24 00:00:00-04:00      31109500              0.0                 0.0   \n",
       "2024-10-25 00:00:00-04:00      38802300              0.0                 0.0   \n",
       "2024-10-28 00:00:00-04:00      36087100              0.0                 0.0   \n",
       "2024-10-29 00:00:00-04:00      35417200              0.0                 0.0   \n",
       "2024-10-30 00:00:00-04:00      47070900              0.0                 0.0   \n",
       "2024-10-31 00:00:00-04:00      35461604              0.0                 0.0   \n",
       "\n",
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2024-09-30 00:00:00-04:00  164.779999  167.360001  164.639999  167.190002   \n",
       "2024-10-01 00:00:00-04:00  168.860001  170.440002  165.899994  168.419998   \n",
       "2024-10-02 00:00:00-04:00  167.759995  168.880005  166.250000  167.309998   \n",
       "2024-10-03 00:00:00-04:00  165.820007  167.910004  165.369995  167.210007   \n",
       "2024-10-04 00:00:00-04:00  169.339996  169.550003  166.960007  168.559998   \n",
       "2024-10-07 00:00:00-04:00  169.139999  169.899994  164.130005  164.389999   \n",
       "2024-10-08 00:00:00-04:00  165.429993  166.100006  164.309998  165.699997   \n",
       "2024-10-09 00:00:00-04:00  164.854996  166.259995  161.119995  163.059998   \n",
       "2024-10-10 00:00:00-04:00  162.110001  164.311005  161.639999  163.179993   \n",
       "2024-10-11 00:00:00-04:00  163.330002  165.270004  162.500000  164.520004   \n",
       "2024-10-14 00:00:00-04:00  164.910004  167.619995  164.779999  166.350006   \n",
       "2024-10-15 00:00:00-04:00  167.139999  169.089996  166.050003  166.899994   \n",
       "2024-10-16 00:00:00-04:00  166.029999  167.279999  165.216003  166.740005   \n",
       "2024-10-17 00:00:00-04:00  167.380005  167.929993  164.369995  164.509995   \n",
       "2024-10-18 00:00:00-04:00  164.869995  166.369995  164.750000  165.050003   \n",
       "2024-10-21 00:00:00-04:00  164.580002  166.220001  164.304993  165.800003   \n",
       "2024-10-22 00:00:00-04:00  164.699997  167.470001  164.669998  166.820007   \n",
       "2024-10-23 00:00:00-04:00  166.429993  167.600006  163.632996  164.479996   \n",
       "2024-10-24 00:00:00-04:00  164.589996  165.050003  162.770004  164.529999   \n",
       "2024-10-25 00:00:00-04:00  165.365005  167.399994  165.229996  166.990005   \n",
       "2024-10-28 00:00:00-04:00  170.589996  170.606003  165.789993  168.339996   \n",
       "2024-10-29 00:00:00-04:00  169.384995  171.860001  168.660004  171.139999   \n",
       "2024-10-30 00:00:00-04:00  182.410004  183.789993  175.744995  176.139999   \n",
       "2024-10-31 00:00:00-04:00  174.654999  178.419998  172.690002  172.919998   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  \n",
       "Date                                                          \n",
       "2024-09-30 00:00:00-04:00  14070100        0.0           0.0  \n",
       "2024-10-01 00:00:00-04:00  18629500        0.0           0.0  \n",
       "2024-10-02 00:00:00-04:00  12745000        0.0           0.0  \n",
       "2024-10-03 00:00:00-04:00  11004300        0.0           0.0  \n",
       "2024-10-04 00:00:00-04:00  11422100        0.0           0.0  \n",
       "2024-10-07 00:00:00-04:00  14034700        0.0           0.0  \n",
       "2024-10-08 00:00:00-04:00  11723900        0.0           0.0  \n",
       "2024-10-09 00:00:00-04:00  19666400        0.0           0.0  \n",
       "2024-10-10 00:00:00-04:00  12900500        0.0           0.0  \n",
       "2024-10-11 00:00:00-04:00  10946000        0.0           0.0  \n",
       "2024-10-14 00:00:00-04:00   9981800        0.0           0.0  \n",
       "2024-10-15 00:00:00-04:00  14829300        0.0           0.0  \n",
       "2024-10-16 00:00:00-04:00   9968500        0.0           0.0  \n",
       "2024-10-17 00:00:00-04:00  15113400        0.0           0.0  \n",
       "2024-10-18 00:00:00-04:00  13091300        0.0           0.0  \n",
       "2024-10-21 00:00:00-04:00  11384000        0.0           0.0  \n",
       "2024-10-22 00:00:00-04:00  11958600        0.0           0.0  \n",
       "2024-10-23 00:00:00-04:00  12754300        0.0           0.0  \n",
       "2024-10-24 00:00:00-04:00  12764400        0.0           0.0  \n",
       "2024-10-25 00:00:00-04:00  14566400        0.0           0.0  \n",
       "2024-10-28 00:00:00-04:00  20858300        0.0           0.0  \n",
       "2024-10-29 00:00:00-04:00  28916100        0.0           0.0  \n",
       "2024-10-30 00:00:00-04:00  49698300        0.0           0.0  \n",
       "2024-10-31 00:00:00-04:00  25387584        0.0           0.0  \n",
       "\n",
       "[24 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined=msft.join(apple, how='left', on='Date', lsuffix='_msft', rsuffix='_apple')\n",
    "joined.join(goo, how='left', on='Date', rsuffix='_google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tickers:str, time_delta:str):\n",
    "    label_tickers=tickers.split(' ')\n",
    "\n",
    "    tickers = yf.Tickers(tickers)\n",
    "    \n",
    "    data=pd.DataFrame({})\n",
    "    for idx, tick in enumerate(label_tickers):\n",
    "        new_df=tickers.tickers[tick.upper()].history(period=time_delta)\n",
    "        new_df.columns=[f'{col.replace(' ', '_').lower()}_{tick}' for col in new_df.columns]\n",
    "\n",
    "        if idx==0:\n",
    "            data=new_df\n",
    "        elif idx==1:\n",
    "            data=data.join(new_df, how='left', on='Date')\n",
    "        else:\n",
    "            data=data.join(new_df, how='left', on='Date')\n",
    "            \n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "joinend_data=get_data('msft aapl goog', '5y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'open_msft'.find('open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_msft</th>\n",
       "      <th>open_aapl</th>\n",
       "      <th>open_goog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-31 00:00:00-04:00</th>\n",
       "      <td>138.401213</td>\n",
       "      <td>59.810074</td>\n",
       "      <td>62.909506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 00:00:00-04:00</th>\n",
       "      <td>137.789945</td>\n",
       "      <td>60.366473</td>\n",
       "      <td>63.095049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 00:00:00-05:00</th>\n",
       "      <td>138.334366</td>\n",
       "      <td>62.250956</td>\n",
       "      <td>63.666146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 00:00:00-05:00</th>\n",
       "      <td>138.468032</td>\n",
       "      <td>62.183215</td>\n",
       "      <td>64.486131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 00:00:00-05:00</th>\n",
       "      <td>137.894971</td>\n",
       "      <td>62.115485</td>\n",
       "      <td>64.315053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-25 00:00:00-04:00</th>\n",
       "      <td>426.760010</td>\n",
       "      <td>229.740005</td>\n",
       "      <td>165.365005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-28 00:00:00-04:00</th>\n",
       "      <td>431.660004</td>\n",
       "      <td>233.320007</td>\n",
       "      <td>170.589996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-29 00:00:00-04:00</th>\n",
       "      <td>428.000000</td>\n",
       "      <td>233.100006</td>\n",
       "      <td>169.384995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-30 00:00:00-04:00</th>\n",
       "      <td>437.440002</td>\n",
       "      <td>232.610001</td>\n",
       "      <td>182.410004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-31 00:00:00-04:00</th>\n",
       "      <td>415.959991</td>\n",
       "      <td>229.229996</td>\n",
       "      <td>174.654999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            open_msft   open_aapl   open_goog\n",
       "Date                                                         \n",
       "2019-10-31 00:00:00-04:00  138.401213   59.810074   62.909506\n",
       "2019-11-01 00:00:00-04:00  137.789945   60.366473   63.095049\n",
       "2019-11-04 00:00:00-05:00  138.334366   62.250956   63.666146\n",
       "2019-11-05 00:00:00-05:00  138.468032   62.183215   64.486131\n",
       "2019-11-06 00:00:00-05:00  137.894971   62.115485   64.315053\n",
       "...                               ...         ...         ...\n",
       "2024-10-25 00:00:00-04:00  426.760010  229.740005  165.365005\n",
       "2024-10-28 00:00:00-04:00  431.660004  233.320007  170.589996\n",
       "2024-10-29 00:00:00-04:00  428.000000  233.100006  169.384995\n",
       "2024-10-30 00:00:00-04:00  437.440002  232.610001  182.410004\n",
       "2024-10-31 00:00:00-04:00  415.959991  229.229996  174.654999\n",
       "\n",
       "[1259 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinend_data.loc[:, [col for col in joinend_data.columns if col.find('open')==0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSFT': yfinance.Ticker object <MSFT>,\n",
       " 'AAPL': yfinance.Ticker object <AAPL>,\n",
       " 'GOOG': yfinance.Ticker object <GOOG>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers.tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['2019-10-31', '2019-11-01', '2019-11-04', '2019-11-05', '2019-11-06',\n",
       "       '2019-11-07', '2019-11-08', '2019-11-11', '2019-11-12', '2019-11-13',\n",
       "       ...\n",
       "       '2024-10-18', '2024-10-21', '2024-10-22', '2024-10-23', '2024-10-24',\n",
       "       '2024-10-25', '2024-10-28', '2024-10-29', '2024-10-30', '2024-10-31'],\n",
       "      dtype='object', name='Date', length=1259)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinend_data.index.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-10-31'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils import check_database_day\n",
    "\n",
    "check_database_day()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/ernes/Documents/ML Projects/forecast_yahoo/data/data')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.config import RAW_DATA_DIR\n",
    "RAW_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open_msft', 'high_msft', 'low_msft', 'close_msft', 'volume_msft',\n",
       "       'dividends_msft', 'stock_splits_msft', 'open_aapl', 'high_aapl',\n",
       "       'low_aapl', 'close_aapl', 'volume_aapl', 'dividends_aapl',\n",
       "       'stock_splits_aapl', 'open_goog', 'high_goog', 'low_goog', 'close_goog',\n",
       "       'volume_goog', 'dividends_goog', 'stock_splits_goog'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinend_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinend_data.index=pd.to_datetime(joinend_data.index, format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_msft</th>\n",
       "      <th>high_msft</th>\n",
       "      <th>low_msft</th>\n",
       "      <th>close_msft</th>\n",
       "      <th>volume_msft</th>\n",
       "      <th>dividends_msft</th>\n",
       "      <th>stock_splits_msft</th>\n",
       "      <th>open_aapl</th>\n",
       "      <th>high_aapl</th>\n",
       "      <th>low_aapl</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_aapl</th>\n",
       "      <th>dividends_aapl</th>\n",
       "      <th>stock_splits_aapl</th>\n",
       "      <th>open_goog</th>\n",
       "      <th>high_goog</th>\n",
       "      <th>low_goog</th>\n",
       "      <th>close_goog</th>\n",
       "      <th>volume_goog</th>\n",
       "      <th>dividends_goog</th>\n",
       "      <th>stock_splits_goog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-25 00:00:00-04:00</th>\n",
       "      <td>426.760010</td>\n",
       "      <td>432.519989</td>\n",
       "      <td>426.570007</td>\n",
       "      <td>428.149994</td>\n",
       "      <td>16899100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.740005</td>\n",
       "      <td>233.220001</td>\n",
       "      <td>229.570007</td>\n",
       "      <td>...</td>\n",
       "      <td>38802300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.365005</td>\n",
       "      <td>167.399994</td>\n",
       "      <td>165.229996</td>\n",
       "      <td>166.990005</td>\n",
       "      <td>14566400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-28 00:00:00-04:00</th>\n",
       "      <td>431.660004</td>\n",
       "      <td>431.940002</td>\n",
       "      <td>426.299988</td>\n",
       "      <td>426.589996</td>\n",
       "      <td>14882400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.320007</td>\n",
       "      <td>234.729996</td>\n",
       "      <td>232.550003</td>\n",
       "      <td>...</td>\n",
       "      <td>36087100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.589996</td>\n",
       "      <td>170.606003</td>\n",
       "      <td>165.789993</td>\n",
       "      <td>168.339996</td>\n",
       "      <td>20858300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-29 00:00:00-04:00</th>\n",
       "      <td>428.000000</td>\n",
       "      <td>433.170013</td>\n",
       "      <td>425.799988</td>\n",
       "      <td>431.950012</td>\n",
       "      <td>17644100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.100006</td>\n",
       "      <td>234.330002</td>\n",
       "      <td>232.320007</td>\n",
       "      <td>...</td>\n",
       "      <td>35417200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.384995</td>\n",
       "      <td>171.860001</td>\n",
       "      <td>168.660004</td>\n",
       "      <td>171.139999</td>\n",
       "      <td>28916100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-30 00:00:00-04:00</th>\n",
       "      <td>437.440002</td>\n",
       "      <td>438.500000</td>\n",
       "      <td>432.100006</td>\n",
       "      <td>432.529999</td>\n",
       "      <td>29749100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232.610001</td>\n",
       "      <td>233.470001</td>\n",
       "      <td>229.550003</td>\n",
       "      <td>...</td>\n",
       "      <td>47070900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.410004</td>\n",
       "      <td>183.789993</td>\n",
       "      <td>175.744995</td>\n",
       "      <td>176.139999</td>\n",
       "      <td>49698300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-31 00:00:00-04:00</th>\n",
       "      <td>415.959991</td>\n",
       "      <td>416.065002</td>\n",
       "      <td>406.299988</td>\n",
       "      <td>407.075012</td>\n",
       "      <td>40516239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.229996</td>\n",
       "      <td>229.830002</td>\n",
       "      <td>226.179993</td>\n",
       "      <td>...</td>\n",
       "      <td>35470152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.654999</td>\n",
       "      <td>178.419998</td>\n",
       "      <td>172.690002</td>\n",
       "      <td>172.955002</td>\n",
       "      <td>25391441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            open_msft   high_msft    low_msft  close_msft  \\\n",
       "Date                                                                        \n",
       "2024-10-25 00:00:00-04:00  426.760010  432.519989  426.570007  428.149994   \n",
       "2024-10-28 00:00:00-04:00  431.660004  431.940002  426.299988  426.589996   \n",
       "2024-10-29 00:00:00-04:00  428.000000  433.170013  425.799988  431.950012   \n",
       "2024-10-30 00:00:00-04:00  437.440002  438.500000  432.100006  432.529999   \n",
       "2024-10-31 00:00:00-04:00  415.959991  416.065002  406.299988  407.075012   \n",
       "\n",
       "                           volume_msft  dividends_msft  stock_splits_msft  \\\n",
       "Date                                                                        \n",
       "2024-10-25 00:00:00-04:00     16899100             0.0                0.0   \n",
       "2024-10-28 00:00:00-04:00     14882400             0.0                0.0   \n",
       "2024-10-29 00:00:00-04:00     17644100             0.0                0.0   \n",
       "2024-10-30 00:00:00-04:00     29749100             0.0                0.0   \n",
       "2024-10-31 00:00:00-04:00     40516239             0.0                0.0   \n",
       "\n",
       "                            open_aapl   high_aapl    low_aapl  ...  \\\n",
       "Date                                                           ...   \n",
       "2024-10-25 00:00:00-04:00  229.740005  233.220001  229.570007  ...   \n",
       "2024-10-28 00:00:00-04:00  233.320007  234.729996  232.550003  ...   \n",
       "2024-10-29 00:00:00-04:00  233.100006  234.330002  232.320007  ...   \n",
       "2024-10-30 00:00:00-04:00  232.610001  233.470001  229.550003  ...   \n",
       "2024-10-31 00:00:00-04:00  229.229996  229.830002  226.179993  ...   \n",
       "\n",
       "                           volume_aapl  dividends_aapl  stock_splits_aapl  \\\n",
       "Date                                                                        \n",
       "2024-10-25 00:00:00-04:00     38802300             0.0                0.0   \n",
       "2024-10-28 00:00:00-04:00     36087100             0.0                0.0   \n",
       "2024-10-29 00:00:00-04:00     35417200             0.0                0.0   \n",
       "2024-10-30 00:00:00-04:00     47070900             0.0                0.0   \n",
       "2024-10-31 00:00:00-04:00     35470152             0.0                0.0   \n",
       "\n",
       "                            open_goog   high_goog    low_goog  close_goog  \\\n",
       "Date                                                                        \n",
       "2024-10-25 00:00:00-04:00  165.365005  167.399994  165.229996  166.990005   \n",
       "2024-10-28 00:00:00-04:00  170.589996  170.606003  165.789993  168.339996   \n",
       "2024-10-29 00:00:00-04:00  169.384995  171.860001  168.660004  171.139999   \n",
       "2024-10-30 00:00:00-04:00  182.410004  183.789993  175.744995  176.139999   \n",
       "2024-10-31 00:00:00-04:00  174.654999  178.419998  172.690002  172.955002   \n",
       "\n",
       "                           volume_goog  dividends_goog  stock_splits_goog  \n",
       "Date                                                                       \n",
       "2024-10-25 00:00:00-04:00     14566400             0.0                0.0  \n",
       "2024-10-28 00:00:00-04:00     20858300             0.0                0.0  \n",
       "2024-10-29 00:00:00-04:00     28916100             0.0                0.0  \n",
       "2024-10-30 00:00:00-04:00     49698300             0.0                0.0  \n",
       "2024-10-31 00:00:00-04:00     25391441             0.0                0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinend_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>SARIMAX Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>   <td>1259</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>            <td>ARIMA(1, 0, 0)</td>  <th>  Log Likelihood     </th> <td>-3750.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 31 Oct 2024</td> <th>  AIC                </th> <td>7506.148</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>13:56:51</td>     <th>  BIC                </th> <td>7521.562</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sample:</th>                  <td>0</td>        <th>  HQIC               </th> <td>7511.940</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                      <td> - 1259</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>        <td>opg</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td>  280.2068</td> <td>   80.271</td> <td>    3.491</td> <td> 0.000</td> <td>  122.879</td> <td>  437.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L1</th>  <td>    0.9991</td> <td>    0.001</td> <td>  682.518</td> <td> 0.000</td> <td>    0.996</td> <td>    1.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sigma2</th> <td>   22.5179</td> <td>    0.649</td> <td>   34.705</td> <td> 0.000</td> <td>   21.246</td> <td>   23.790</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Ljung-Box (L1) (Q):</th>     <td>10.75</td> <th>  Jarque-Bera (JB):  </th> <td>213.57</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Q):</th>                <td>0.00</td>  <th>  Prob(JB):          </th>  <td>0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Heteroskedasticity (H):</th> <td>2.13</td>  <th>  Skew:              </th>  <td>-0.24</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(H) (two-sided):</th>    <td>0.00</td>  <th>  Kurtosis:          </th>  <td>4.96</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Covariance matrix calculated using the outer product of gradients (complex-step)."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}          &        y         & \\textbf{  No. Observations:  } &    1259     \\\\\n",
       "\\textbf{Model:}                  &  ARIMA(1, 0, 0)  & \\textbf{  Log Likelihood     } & -3750.074   \\\\\n",
       "\\textbf{Date:}                   & Thu, 31 Oct 2024 & \\textbf{  AIC                } &  7506.148   \\\\\n",
       "\\textbf{Time:}                   &     13:56:51     & \\textbf{  BIC                } &  7521.562   \\\\\n",
       "\\textbf{Sample:}                 &        0         & \\textbf{  HQIC               } &  7511.940   \\\\\n",
       "\\textbf{}                        &      - 1259      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}        &       opg        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}  &     280.2068  &       80.271     &     3.491  &         0.000        &      122.879    &      437.534     \\\\\n",
       "\\textbf{ar.L1}  &       0.9991  &        0.001     &   682.518  &         0.000        &        0.996    &        1.002     \\\\\n",
       "\\textbf{sigma2} &      22.5179  &        0.649     &    34.705  &         0.000        &       21.246    &       23.790     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Ljung-Box (L1) (Q):}     & 10.75 & \\textbf{  Jarque-Bera (JB):  } & 213.57  \\\\\n",
       "\\textbf{Prob(Q):}                &  0.00 & \\textbf{  Prob(JB):          } &  0.00   \\\\\n",
       "\\textbf{Heteroskedasticity (H):} &  2.13 & \\textbf{  Skew:              } & -0.24   \\\\\n",
       "\\textbf{Prob(H) (two-sided):}    &  0.00 & \\textbf{  Kurtosis:          } &  4.96   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{SARIMAX Results}\n",
       "\\end{center}\n",
       "\n",
       "Warnings: \\newline\n",
       " [1] Covariance matrix calculated using the outer product of gradients (complex-step)."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                               SARIMAX Results                                \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                 1259\n",
       "Model:                 ARIMA(1, 0, 0)   Log Likelihood               -3750.074\n",
       "Date:                Thu, 31 Oct 2024   AIC                           7506.148\n",
       "Time:                        13:56:51   BIC                           7521.562\n",
       "Sample:                             0   HQIC                          7511.940\n",
       "                               - 1259                                         \n",
       "Covariance Type:                  opg                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        280.2068     80.271      3.491      0.000     122.879     437.534\n",
       "ar.L1          0.9991      0.001    682.518      0.000       0.996       1.002\n",
       "sigma2        22.5179      0.649     34.705      0.000      21.246      23.790\n",
       "===================================================================================\n",
       "Ljung-Box (L1) (Q):                  10.75   Jarque-Bera (JB):               213.57\n",
       "Prob(Q):                              0.00   Prob(JB):                         0.00\n",
       "Heteroskedasticity (H):               2.13   Skew:                            -0.24\n",
       "Prob(H) (two-sided):                  0.00   Kurtosis:                         4.96\n",
       "===================================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=ARIMA(joinend_data.loc[:, 'open_msft'].values, order=(1, 0,0))\n",
    "res=model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7506.147830832747)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path save c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\models2024_10_31.plk\n"
     ]
    }
   ],
   "source": [
    "from src.components.trainer import TrainerARIMA\n",
    "trainer=TrainerARIMA()\n",
    "model_path=trainer.init_trainer(joinend_data.loc[:, 'open_msft'].values, max_ar=2, max_i=1, max_ma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima=ARIMA(joinend_data.loc[:, 'open_msft'].values, order=(1,1,1))\n",
    "res=arima.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([417.79339975])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.forecast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<statsmodels.tsa.arima.model.ARIMA at 0x1d503e5eb70>,\n",
       " (0, 1, 4),\n",
       " <class 'statsmodels.iolib.summary.Summary'>\n",
       " \"\"\"\n",
       "                                SARIMAX Results                                \n",
       " ==============================================================================\n",
       " Dep. Variable:                      y   No. Observations:                 1259\n",
       " Model:                 ARIMA(0, 1, 4)   Log Likelihood               -3723.452\n",
       " Date:                Wed, 30 Oct 2024   AIC                           7456.903\n",
       " Time:                        14:05:20   BIC                           7482.590\n",
       " Sample:                             0   HQIC                          7466.557\n",
       "                                - 1259                                         \n",
       " Covariance Type:                  opg                                         \n",
       " ==============================================================================\n",
       "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
       " ------------------------------------------------------------------------------\n",
       " ma.L1         -0.0869      0.023     -3.702      0.000      -0.133      -0.041\n",
       " ma.L2         -0.0492      0.026     -1.884      0.060      -0.100       0.002\n",
       " ma.L3         -0.0175      0.026     -0.667      0.505      -0.069       0.034\n",
       " ma.L4          0.0776      0.027      2.902      0.004       0.025       0.130\n",
       " sigma2        21.7960      0.641     34.022      0.000      20.540      23.052\n",
       " ===================================================================================\n",
       " Ljung-Box (L1) (Q):                   0.03   Jarque-Bera (JB):               173.96\n",
       " Prob(Q):                              0.87   Prob(JB):                         0.00\n",
       " Heteroskedasticity (H):               2.02   Skew:                            -0.23\n",
       " Prob(H) (two-sided):                  0.00   Kurtosis:                         4.76\n",
       " ===================================================================================\n",
       " \n",
       " Warnings:\n",
       " [1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
       " \"\"\")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, best_order, report.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "898/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>SARIMAX Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>   <td>1259</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>            <td>ARIMA(0, 1, 4)</td>  <th>  Log Likelihood     </th> <td>-3723.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 30 Oct 2024</td> <th>  AIC                </th> <td>7456.903</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:05:28</td>     <th>  BIC                </th> <td>7482.590</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sample:</th>                  <td>0</td>        <th>  HQIC               </th> <td>7466.557</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                      <td> - 1259</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>        <td>opg</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ma.L1</th>  <td>   -0.0869</td> <td>    0.023</td> <td>   -3.702</td> <td> 0.000</td> <td>   -0.133</td> <td>   -0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ma.L2</th>  <td>   -0.0492</td> <td>    0.026</td> <td>   -1.884</td> <td> 0.060</td> <td>   -0.100</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ma.L3</th>  <td>   -0.0175</td> <td>    0.026</td> <td>   -0.667</td> <td> 0.505</td> <td>   -0.069</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ma.L4</th>  <td>    0.0776</td> <td>    0.027</td> <td>    2.902</td> <td> 0.004</td> <td>    0.025</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sigma2</th> <td>   21.7960</td> <td>    0.641</td> <td>   34.022</td> <td> 0.000</td> <td>   20.540</td> <td>   23.052</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Ljung-Box (L1) (Q):</th>     <td>0.03</td> <th>  Jarque-Bera (JB):  </th> <td>173.96</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Q):</th>                <td>0.87</td> <th>  Prob(JB):          </th>  <td>0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Heteroskedasticity (H):</th> <td>2.02</td> <th>  Skew:              </th>  <td>-0.23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(H) (two-sided):</th>    <td>0.00</td> <th>  Kurtosis:          </th>  <td>4.76</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Covariance matrix calculated using the outer product of gradients (complex-step)."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}          &        y         & \\textbf{  No. Observations:  } &    1259     \\\\\n",
       "\\textbf{Model:}                  &  ARIMA(0, 1, 4)  & \\textbf{  Log Likelihood     } & -3723.452   \\\\\n",
       "\\textbf{Date:}                   & Wed, 30 Oct 2024 & \\textbf{  AIC                } &  7456.903   \\\\\n",
       "\\textbf{Time:}                   &     14:05:28     & \\textbf{  BIC                } &  7482.590   \\\\\n",
       "\\textbf{Sample:}                 &        0         & \\textbf{  HQIC               } &  7466.557   \\\\\n",
       "\\textbf{}                        &      - 1259      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}        &       opg        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{ma.L1}  &      -0.0869  &        0.023     &    -3.702  &         0.000        &       -0.133    &       -0.041     \\\\\n",
       "\\textbf{ma.L2}  &      -0.0492  &        0.026     &    -1.884  &         0.060        &       -0.100    &        0.002     \\\\\n",
       "\\textbf{ma.L3}  &      -0.0175  &        0.026     &    -0.667  &         0.505        &       -0.069    &        0.034     \\\\\n",
       "\\textbf{ma.L4}  &       0.0776  &        0.027     &     2.902  &         0.004        &        0.025    &        0.130     \\\\\n",
       "\\textbf{sigma2} &      21.7960  &        0.641     &    34.022  &         0.000        &       20.540    &       23.052     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Ljung-Box (L1) (Q):}     & 0.03 & \\textbf{  Jarque-Bera (JB):  } & 173.96  \\\\\n",
       "\\textbf{Prob(Q):}                & 0.87 & \\textbf{  Prob(JB):          } &  0.00   \\\\\n",
       "\\textbf{Heteroskedasticity (H):} & 2.02 & \\textbf{  Skew:              } & -0.23   \\\\\n",
       "\\textbf{Prob(H) (two-sided):}    & 0.00 & \\textbf{  Kurtosis:          } &  4.76   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{SARIMAX Results}\n",
       "\\end{center}\n",
       "\n",
       "Warnings: \\newline\n",
       " [1] Covariance matrix calculated using the outer product of gradients (complex-step)."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                               SARIMAX Results                                \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                 1259\n",
       "Model:                 ARIMA(0, 1, 4)   Log Likelihood               -3723.452\n",
       "Date:                Wed, 30 Oct 2024   AIC                           7456.903\n",
       "Time:                        14:05:28   BIC                           7482.590\n",
       "Sample:                             0   HQIC                          7466.557\n",
       "                               - 1259                                         \n",
       "Covariance Type:                  opg                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "ma.L1         -0.0869      0.023     -3.702      0.000      -0.133      -0.041\n",
       "ma.L2         -0.0492      0.026     -1.884      0.060      -0.100       0.002\n",
       "ma.L3         -0.0175      0.026     -0.667      0.505      -0.069       0.034\n",
       "ma.L4          0.0776      0.027      2.902      0.004       0.025       0.130\n",
       "sigma2        21.7960      0.641     34.022      0.000      20.540      23.052\n",
       "===================================================================================\n",
       "Ljung-Box (L1) (Q):                   0.03   Jarque-Bera (JB):               173.96\n",
       "Prob(Q):                              0.87   Prob(JB):                         0.00\n",
       "Heteroskedasticity (H):               2.02   Skew:                            -0.23\n",
       "Prob(H) (two-sided):                  0.00   Kurtosis:                         4.76\n",
       "===================================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 30\n",
    "batch_size = 128\n",
    "shuffle_buffer_size = 1000\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(joinend_data['open_msft'])\n",
    "train_ds=train_ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "train_ds = train_ds.flat_map(lambda window: window.batch(window_size + 1))\n",
    "train_ds = train_ds.map(lambda window: (window[:-1], window[-1]))\n",
    "train_ds = train_ds.shuffle(shuffle_buffer_size)\n",
    "train_ds = train_ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,935</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m33,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │         \u001b[38;5;34m1,935\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m16\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,743</span> (139.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35,743\u001b[0m (139.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,743</span> (139.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,743\u001b[0m (139.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64), input_shape=[window_size, 1]),\n",
    "  tf.keras.layers.Dense(15, activation = 'relu'),\n",
    "  tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 17.3457 - learning_rate: 1.0000e-08\n",
      "Epoch 2/200\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 11.9038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.6569 - learning_rate: 1.1220e-08\n",
      "Epoch 3/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 17.4006 - learning_rate: 1.2589e-08\n",
      "Epoch 4/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 18.1672 - learning_rate: 1.4125e-08\n",
      "Epoch 5/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 17.4631 - learning_rate: 1.5849e-08\n",
      "Epoch 6/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 17.7155 - learning_rate: 1.7783e-08\n",
      "Epoch 7/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 17.6695 - learning_rate: 1.9953e-08\n",
      "Epoch 8/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 17.3969 - learning_rate: 2.2387e-08\n",
      "Epoch 9/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 17.7433 - learning_rate: 2.5119e-08\n",
      "Epoch 10/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 17.4096 - learning_rate: 2.8184e-08\n",
      "Epoch 11/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 17.5482 - learning_rate: 3.1623e-08\n",
      "Epoch 12/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 17.6037 - learning_rate: 3.5481e-08\n",
      "Epoch 13/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 18.0220 - learning_rate: 3.9811e-08\n",
      "Epoch 14/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17.5634 - learning_rate: 4.4668e-08\n",
      "Epoch 15/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17.5853 - learning_rate: 5.0119e-08\n",
      "Epoch 16/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.2126 - learning_rate: 5.6234e-08\n",
      "Epoch 17/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 17.4244 - learning_rate: 6.3096e-08\n",
      "Epoch 18/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.6579 - learning_rate: 7.0795e-08\n",
      "Epoch 19/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.3482 - learning_rate: 7.9433e-08\n",
      "Epoch 20/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.4276 - learning_rate: 8.9125e-08\n",
      "Epoch 21/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 17.8906 - learning_rate: 1.0000e-07\n",
      "Epoch 22/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 17.6465 - learning_rate: 1.1220e-07\n",
      "Epoch 23/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 16.9850 - learning_rate: 1.2589e-07\n",
      "Epoch 24/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.3814 - learning_rate: 1.4125e-07\n",
      "Epoch 25/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.2303 - learning_rate: 1.5849e-07\n",
      "Epoch 26/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 17.3271 - learning_rate: 1.7783e-07\n",
      "Epoch 27/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.3592 - learning_rate: 1.9953e-07\n",
      "Epoch 28/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 18.4091 - learning_rate: 2.2387e-07\n",
      "Epoch 29/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.2977 - learning_rate: 2.5119e-07\n",
      "Epoch 30/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 18.3489 - learning_rate: 2.8184e-07\n",
      "Epoch 31/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 18.1347 - learning_rate: 3.1623e-07\n",
      "Epoch 32/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.5336 - learning_rate: 3.5481e-07\n",
      "Epoch 33/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.9370 - learning_rate: 3.9811e-07\n",
      "Epoch 34/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16.8992 - learning_rate: 4.4668e-07\n",
      "Epoch 35/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.5402 - learning_rate: 5.0119e-07\n",
      "Epoch 36/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 17.6769 - learning_rate: 5.6234e-07\n",
      "Epoch 37/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.8265 - learning_rate: 6.3096e-07\n",
      "Epoch 38/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 17.2729 - learning_rate: 7.0795e-07\n",
      "Epoch 39/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.2564 - learning_rate: 7.9433e-07\n",
      "Epoch 40/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17.6923 - learning_rate: 8.9125e-07\n",
      "Epoch 41/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.9177 - learning_rate: 1.0000e-06\n",
      "Epoch 42/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17.8221 - learning_rate: 1.1220e-06\n",
      "Epoch 43/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.5750 - learning_rate: 1.2589e-06\n",
      "Epoch 44/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 17.5993 - learning_rate: 1.4125e-06\n",
      "Epoch 45/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 17.0790 - learning_rate: 1.5849e-06\n",
      "Epoch 46/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 18.2326 - learning_rate: 1.7783e-06\n",
      "Epoch 47/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17.0710 - learning_rate: 1.9953e-06\n",
      "Epoch 48/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.5717 - learning_rate: 2.2387e-06\n",
      "Epoch 49/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.7130 - learning_rate: 2.5119e-06\n",
      "Epoch 50/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 17.8950 - learning_rate: 2.8184e-06\n",
      "Epoch 51/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.7213 - learning_rate: 3.1623e-06\n",
      "Epoch 52/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.2091 - learning_rate: 3.5481e-06\n",
      "Epoch 53/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17.4622 - learning_rate: 3.9811e-06\n",
      "Epoch 54/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16.9347 - learning_rate: 4.4668e-06\n",
      "Epoch 55/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16.9786 - learning_rate: 5.0119e-06\n",
      "Epoch 56/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.1053 - learning_rate: 5.6234e-06\n",
      "Epoch 57/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.7148 - learning_rate: 6.3096e-06\n",
      "Epoch 58/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.1214 - learning_rate: 7.0795e-06\n",
      "Epoch 59/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 18.0866 - learning_rate: 7.9433e-06\n",
      "Epoch 60/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 17.3948 - learning_rate: 8.9125e-06\n",
      "Epoch 61/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.6303 - learning_rate: 1.0000e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.2661 - learning_rate: 1.1220e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.1011 - learning_rate: 1.2589e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 16.9790 - learning_rate: 1.4125e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16.8489 - learning_rate: 1.5849e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17.4693 - learning_rate: 1.7783e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 16.6996 - learning_rate: 1.9953e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.1670 - learning_rate: 2.2387e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.4294 - learning_rate: 2.5119e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.6925 - learning_rate: 2.8184e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.2546 - learning_rate: 3.1623e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.4708 - learning_rate: 3.5481e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17.1682 - learning_rate: 3.9811e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16.9925 - learning_rate: 4.4668e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 16.8993 - learning_rate: 5.0119e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 16.8097 - learning_rate: 5.6234e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16.5572 - learning_rate: 6.3096e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 16.9177 - learning_rate: 7.0795e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 17.3336 - learning_rate: 7.9433e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 16.9183 - learning_rate: 8.9125e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16.7329 - learning_rate: 1.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 15.7915 - learning_rate: 1.1220e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16.3637 - learning_rate: 1.2589e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 16.3633 - learning_rate: 1.4125e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 16.6972 - learning_rate: 1.5849e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 15.9281 - learning_rate: 1.7783e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 15.6159 - learning_rate: 1.9953e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 15.1614 - learning_rate: 2.2387e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 15.5872 - learning_rate: 2.5119e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 14.4442 - learning_rate: 2.8184e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 14.5210 - learning_rate: 3.1623e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 14.6445 - learning_rate: 3.5481e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 14.2782 - learning_rate: 3.9811e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 13.9985 - learning_rate: 4.4668e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 13.9822 - learning_rate: 5.0119e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.6173 - learning_rate: 5.6234e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 14.5613 - learning_rate: 6.3096e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 15.0393 - learning_rate: 7.0795e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 15.1139 - learning_rate: 7.9433e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 14.9201 - learning_rate: 8.9125e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17.7945 - learning_rate: 0.0010\n",
      "Epoch 102/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 15.5594 - learning_rate: 0.0011\n",
      "Epoch 103/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 15.5716 - learning_rate: 0.0013\n",
      "Epoch 104/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17.5597 - learning_rate: 0.0014\n",
      "Epoch 105/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 20.7611 - learning_rate: 0.0016\n",
      "Epoch 106/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 18.4967 - learning_rate: 0.0018\n",
      "Epoch 107/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 19.6922 - learning_rate: 0.0020\n",
      "Epoch 108/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 19.6711 - learning_rate: 0.0022\n",
      "Epoch 109/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 24.0931 - learning_rate: 0.0025\n",
      "Epoch 110/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 24.9447 - learning_rate: 0.0028\n",
      "Epoch 111/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 37.3162 - learning_rate: 0.0032\n",
      "Epoch 112/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 31.6076 - learning_rate: 0.0035\n",
      "Epoch 113/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 28.8841 - learning_rate: 0.0040\n",
      "Epoch 114/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 43.4413 - learning_rate: 0.0045\n",
      "Epoch 115/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 31.3798 - learning_rate: 0.0050\n",
      "Epoch 116/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 38.4200 - learning_rate: 0.0056\n",
      "Epoch 117/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 38.8189 - learning_rate: 0.0063\n",
      "Epoch 118/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 40.2501 - learning_rate: 0.0071\n",
      "Epoch 119/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 39.4683 - learning_rate: 0.0079\n",
      "Epoch 120/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 41.5663 - learning_rate: 0.0089\n",
      "Epoch 121/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 54.2216 - learning_rate: 0.0100\n",
      "Epoch 122/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 52.5577 - learning_rate: 0.0112\n",
      "Epoch 123/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 42.9234 - learning_rate: 0.0126\n",
      "Epoch 124/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 45.2769 - learning_rate: 0.0141\n",
      "Epoch 125/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 48.5198 - learning_rate: 0.0158\n",
      "Epoch 126/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 46.6671 - learning_rate: 0.0178\n",
      "Epoch 127/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 55.5800 - learning_rate: 0.0200\n",
      "Epoch 128/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 55.9873 - learning_rate: 0.0224\n",
      "Epoch 129/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 58.9332 - learning_rate: 0.0251\n",
      "Epoch 130/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 65.7196 - learning_rate: 0.0282\n",
      "Epoch 131/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 60.0304 - learning_rate: 0.0316\n",
      "Epoch 132/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 62.2783 - learning_rate: 0.0355\n",
      "Epoch 133/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 63.1093 - learning_rate: 0.0398\n",
      "Epoch 134/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 59.9402 - learning_rate: 0.0447\n",
      "Epoch 135/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 64.2426 - learning_rate: 0.0501\n",
      "Epoch 136/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 62.6097 - learning_rate: 0.0562\n",
      "Epoch 137/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 68.5974 - learning_rate: 0.0631\n",
      "Epoch 138/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 64.8615 - learning_rate: 0.0708\n",
      "Epoch 139/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 66.0601 - learning_rate: 0.0794\n",
      "Epoch 140/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 66.7681 - learning_rate: 0.0891\n",
      "Epoch 141/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 63.5974 - learning_rate: 0.1000\n",
      "Epoch 142/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 64.0207 - learning_rate: 0.1122\n",
      "Epoch 143/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 64.8577 - learning_rate: 0.1259\n",
      "Epoch 144/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 66.7741 - learning_rate: 0.1413\n",
      "Epoch 145/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 68.4925 - learning_rate: 0.1585\n",
      "Epoch 146/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 67.1016 - learning_rate: 0.1778\n",
      "Epoch 147/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 66.1902 - learning_rate: 0.1995\n",
      "Epoch 148/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 83.7968 - learning_rate: 0.2239\n",
      "Epoch 149/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 68.1717 - learning_rate: 0.2512\n",
      "Epoch 150/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 84.0238 - learning_rate: 0.2818\n",
      "Epoch 151/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 79.5084 - learning_rate: 0.3162\n",
      "Epoch 152/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 87.3914 - learning_rate: 0.3548\n",
      "Epoch 153/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 84.7890 - learning_rate: 0.3981\n",
      "Epoch 154/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 93.0701 - learning_rate: 0.4467\n",
      "Epoch 155/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 83.4462 - learning_rate: 0.5012\n",
      "Epoch 156/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 119.7054 - learning_rate: 0.5623\n",
      "Epoch 157/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 88.8232 - learning_rate: 0.6310\n",
      "Epoch 158/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 99.3372 - learning_rate: 0.7079\n",
      "Epoch 159/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 102.8021 - learning_rate: 0.7943\n",
      "Epoch 160/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 91.9707 - learning_rate: 0.8913\n",
      "Epoch 161/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 86.6617 - learning_rate: 1.0000\n",
      "Epoch 162/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 117.5830 - learning_rate: 1.1220\n",
      "Epoch 163/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 105.0921 - learning_rate: 1.2589\n",
      "Epoch 164/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 110.1967 - learning_rate: 1.4125\n",
      "Epoch 165/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 129.4174 - learning_rate: 1.5849\n",
      "Epoch 166/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 142.6426 - learning_rate: 1.7783\n",
      "Epoch 167/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 126.5099 - learning_rate: 1.9953\n",
      "Epoch 168/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 143.1530 - learning_rate: 2.2387\n",
      "Epoch 169/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 219.9869 - learning_rate: 2.5119\n",
      "Epoch 170/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 185.0484 - learning_rate: 2.8184\n",
      "Epoch 171/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 185.4622 - learning_rate: 3.1623\n",
      "Epoch 172/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 150.9653 - learning_rate: 3.5481\n",
      "Epoch 173/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 115.0118 - learning_rate: 3.9811\n",
      "Epoch 174/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 87.0030 - learning_rate: 4.4668\n",
      "Epoch 175/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 67.2924 - learning_rate: 5.0119\n",
      "Epoch 176/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 61.4540 - learning_rate: 5.6234\n",
      "Epoch 177/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 62.4194 - learning_rate: 6.3096\n",
      "Epoch 178/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 61.6070 - learning_rate: 7.0795\n",
      "Epoch 179/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 61.9130 - learning_rate: 7.9433\n",
      "Epoch 180/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 62.3644 - learning_rate: 8.9125\n",
      "Epoch 181/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 62.6157 - learning_rate: 10.0000\n",
      "Epoch 182/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 61.6286 - learning_rate: 11.2202\n",
      "Epoch 183/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 61.1859 - learning_rate: 12.5893\n",
      "Epoch 184/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 61.8894 - learning_rate: 14.1254\n",
      "Epoch 185/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 62.7244 - learning_rate: 15.8489\n",
      "Epoch 186/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 64.1956 - learning_rate: 17.7828\n",
      "Epoch 187/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 61.7775 - learning_rate: 19.9526\n",
      "Epoch 188/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 62.6270 - learning_rate: 22.3872\n",
      "Epoch 189/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 61.5635 - learning_rate: 25.1189\n",
      "Epoch 190/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 65.8663 - learning_rate: 28.1838\n",
      "Epoch 191/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 66.5984 - learning_rate: 31.6228\n",
      "Epoch 192/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 66.4974 - learning_rate: 35.4813\n",
      "Epoch 193/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 62.8994 - learning_rate: 39.8107\n",
      "Epoch 194/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 69.7834 - learning_rate: 44.6684\n",
      "Epoch 195/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 64.4735 - learning_rate: 50.1187\n",
      "Epoch 196/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 66.3928 - learning_rate: 56.2341\n",
      "Epoch 197/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 68.4704 - learning_rate: 63.0957\n",
      "Epoch 198/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 65.8300 - learning_rate: 70.7946\n",
      "Epoch 199/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 68.6736 - learning_rate: 79.4328\n",
      "Epoch 200/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 68.1552 - learning_rate: 89.1251\n"
     ]
    }
   ],
   "source": [
    "# Set the learning rate scheduler\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-3)\n",
    "\n",
    "# Set the training parameters\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_ds, epochs=200, callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select learning rate\n",
    "lrs=1e-8 * 10**(np.arange(200) / 20)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.semilogx(lrs[:120], history.history['loss'][:120])\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.components.data_ingestion import DataIngestion\n",
    "from src.components.transformer import DataTransformer\n",
    "from src.components.trainer import TrainerARIMA\n",
    "from src.components.trainer_rnn import TrainerNeuralNetwork\n",
    "\n",
    "from src.config import TICKERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check data True\n"
     ]
    }
   ],
   "source": [
    "data_ingesition=DataIngestion()\n",
    "raw_path,train_path,test_path=data_ingesition.init_data_ingestion(TICKERS, '5y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_data=DataTransformer()\n",
    "train_df, test_df=transformer_data.init_transformer(rnn_model=False,\n",
    "                                                    ticker='open_MSFT',\n",
    "                                                    train_path=train_path,\n",
    "                                                    test_path=test_path,\n",
    "                                                    shuffle_size=None)\n",
    "\n",
    "train_ds, test_ds=transformer_data.init_transformer(rnn_model=True,\n",
    "                                                    ticker='open_MSFT',\n",
    "                                                    train_path=train_path,\n",
    "                                                    test_path=test_path,\n",
    "                                                    shuffle_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path save c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\models2024-10-31.plk\n"
     ]
    }
   ],
   "source": [
    "trainer_arima=TrainerARIMA()\n",
    "arima_model_path=trainer_arima.init_trainer(train_dataset=train_df, max_ar=2, max_i=1, max_ma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[144.05709604 143.18495344 143.82709269 143.75998448 145.06339452\n",
      "  145.99309924 145.77266032 145.49471427 141.35445877 143.89415572\n",
      "  143.80795009 144.70881611 144.78548598 144.99633521]\n",
      " [146.46871209 158.86583657 167.02487796 161.92188658 159.5770118\n",
      "  156.27110428 145.11365022 151.99456898 151.00468991 139.6358699\n",
      "  141.75012487 134.54248478 134.54250494 132.62045825]\n",
      " [154.4461325  156.96678435 160.85786819 166.80953362 165.04608014\n",
      "  163.34011674 169.77095606 176.37436522 173.4416498  175.24342861\n",
      "  175.94306409 182.71894368 177.85988062 175.46389125]\n",
      " [138.82147633 139.71931569 140.15871235 140.42612997 142.25047137\n",
      "  143.33931857 144.11303301 144.05709604 143.18495344 143.82709269\n",
      "  143.75998448 145.06339452 145.99309924 145.77266032]\n",
      " [152.37602479 150.24834363 152.1747796  151.733915   150.54547532\n",
      "  152.69229472 152.31850457 155.10747638 156.04670803 155.03079187\n",
      "  156.59296993 155.8550067  157.51307403 160.45531624]\n",
      " [155.10747638 156.04670803 155.03079187 156.59296993 155.8550067\n",
      "  157.51307403 160.45531624 159.74608284 160.4361465  159.27651871\n",
      "  160.54156538 154.4461325  156.96678435 160.85786819]\n",
      " [180.72897797 179.66230073 176.02962168 161.22996165 167.40930959\n",
      "  163.09434747 156.95342393 146.46871209 158.86583657 167.02487796\n",
      "  161.92188658 159.5770118  156.27110428 145.11365022]\n",
      " [142.61502211 145.83445409 146.49753505 153.18621082 147.03574054\n",
      "  145.94015659 149.05385538 154.0703729  162.97899001 159.21179894\n",
      "  159.87491169 157.94329013 162.41203624 164.52623359]\n",
      " [145.83445409 146.49753505 153.18621082 147.03574054 145.94015659\n",
      "  149.05385538 154.0703729  162.97899001 159.21179894 159.87491169\n",
      "  157.94329013 162.41203624 164.52623359 167.50540101]\n",
      " [160.85786819 166.80953362 165.04608014 163.34011674 169.77095606\n",
      "  176.37436522 173.4416498  175.24342861 175.94306409 182.71894368\n",
      "  177.85988062 175.46389125 175.62680418 177.88861987]\n",
      " [163.34011674 169.77095606 176.37436522 173.4416498  175.24342861\n",
      "  175.94306409 182.71894368 177.85988062 175.46389125 175.62680418\n",
      "  177.88861987 180.72897797 179.66230073 176.02962168]\n",
      " [160.54156538 154.4461325  156.96678435 160.85786819 166.80953362\n",
      "  165.04608014 163.34011674 169.77095606 176.37436522 173.4416498\n",
      "  175.24342861 175.94306409 182.71894368 177.85988062]\n",
      " [145.06339452 145.99309924 145.77266032 145.49471427 141.35445877\n",
      "  143.89415572 143.80795009 144.70881611 144.78548598 144.99633521\n",
      "  145.23590423 145.34136712 146.63519645 148.65741032]\n",
      " [144.99633521 145.23590423 145.34136712 146.63519645 148.65741032\n",
      "  148.98327681 147.88114652 147.59361234 150.80425371 151.54221122\n",
      "  150.92883905 151.00551128 152.81688143 152.37602479]\n",
      " [151.54221122 150.92883905 151.00551128 152.81688143 152.37602479\n",
      "  150.24834363 152.1747796  151.733915   150.54547532 152.69229472\n",
      "  152.31850457 155.10747638 156.04670803 155.03079187]\n",
      " [177.88861987 180.72897797 179.66230073 176.02962168 161.22996165\n",
      "  167.40930959 163.09434747 156.95342393 146.46871209 158.86583657\n",
      "  167.02487796 161.92188658 159.5770118  156.27110428]\n",
      " [153.18621082 147.03574054 145.94015659 149.05385538 154.0703729\n",
      "  162.97899001 159.21179894 159.87491169 157.94329013 162.41203624\n",
      "  164.52623359 167.50540101 172.50268169 169.74453765]\n",
      " [167.02487796 161.92188658 159.5770118  156.27110428 145.11365022\n",
      "  151.99456898 151.00468991 139.6358699  141.75012487 134.54248478\n",
      "  134.54250494 132.62045825 137.20450931 140.30858592]\n",
      " [137.89500164 137.388771   137.52245875 138.82147633 139.71931569\n",
      "  140.15871235 140.42612997 142.25047137 143.33931857 144.11303301\n",
      "  144.05709604 143.18495344 143.82709269 143.75998448]\n",
      " [138.46804759 137.89500164 137.388771   137.52245875 138.82147633\n",
      "  139.71931569 140.15871235 140.42612997 142.25047137 143.33931857\n",
      "  144.11303301 144.05709604 143.18495344 143.82709269]\n",
      " [144.11303301 144.05709604 143.18495344 143.82709269 143.75998448\n",
      "  145.06339452 145.99309924 145.77266032 145.49471427 141.35445877\n",
      "  143.89415572 143.80795009 144.70881611 144.78548598]\n",
      " [152.69229472 152.31850457 155.10747638 156.04670803 155.03079187\n",
      "  156.59296993 155.8550067  157.51307403 160.45531624 159.74608284\n",
      "  160.4361465  159.27651871 160.54156538 154.4461325 ]\n",
      " [177.85988062 175.46389125 175.62680418 177.88861987 180.72897797\n",
      "  179.66230073 176.02962168 161.22996165 167.40930959 163.09434747\n",
      "  156.95342393 146.46871209 158.86583657 167.02487796]\n",
      " [156.59296993 155.8550067  157.51307403 160.45531624 159.74608284\n",
      "  160.4361465  159.27651871 160.54156538 154.4461325  156.96678435\n",
      "  160.85786819 166.80953362 165.04608014 163.34011674]\n",
      " [138.40119733 137.78991392 138.33436586 138.46804759 137.89500164\n",
      "  137.388771   137.52245875 138.82147633 139.71931569 140.15871235\n",
      "  140.42612997 142.25047137 143.33931857 144.11303301]\n",
      " [166.73660501 164.70882591 167.32281115 165.35272681 169.70613075\n",
      "  168.74512716 166.46752011 172.98318127 168.94694042 167.68800474\n",
      "  173.57905061 174.98211911 176.9906283  177.76905165]\n",
      " [139.71931569 140.15871235 140.42612997 142.25047137 143.33931857\n",
      "  144.11303301 144.05709604 143.18495344 143.82709269 143.75998448\n",
      "  145.06339452 145.99309924 145.77266032 145.49471427]\n",
      " [150.80425371 151.54221122 150.92883905 151.00551128 152.81688143\n",
      "  152.37602479 150.24834363 152.1747796  151.733915   150.54547532\n",
      "  152.69229472 152.31850457 155.10747638 156.04670803]\n",
      " [151.733915   150.54547532 152.69229472 152.31850457 155.10747638\n",
      "  156.04670803 155.03079187 156.59296993 155.8550067  157.51307403\n",
      "  160.45531624 159.74608284 160.4361465  159.27651871]\n",
      " [175.62680418 177.88861987 180.72897797 179.66230073 176.02962168\n",
      "  161.22996165 167.40930959 163.09434747 156.95342393 146.46871209\n",
      "  158.86583657 167.02487796 161.92188658 159.5770118 ]\n",
      " [164.70882591 167.32281115 165.35272681 169.70613075 168.74512716\n",
      "  166.46752011 172.98318127 168.94694042 167.68800474 173.57905061\n",
      "  174.98211911 176.9906283  177.76905165 176.01039952]\n",
      " [140.30858592 131.66901565 138.14631977 143.10516447 142.61502211\n",
      "  145.83445409 146.49753505 153.18621082 147.03574054 145.94015659\n",
      "  149.05385538 154.0703729  162.97899001 159.21179894]], shape=(32, 14), dtype=float64) tf.Tensor(\n",
      "[145.23590423 137.20450931 175.62680418 145.49471427 159.74608284\n",
      " 166.80953362 151.99456898 167.50540101 172.50268169 180.72897797\n",
      " 161.22996165 175.46389125 148.98327681 150.24834363 156.59296993\n",
      " 145.11365022 166.73660501 131.66901565 145.06339452 143.75998448\n",
      " 144.99633521 156.96678435 161.92188658 169.77095606 144.05709604\n",
      " 176.01039952 141.35445877 155.03079187 160.54156538 156.27110428\n",
      " 179.51809861 159.87491169], shape=(32,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_ds.take(1):\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     32/Unknown \u001b[1m3s\u001b[0m 6ms/step - loss: 213.4044 - mae: 213.9044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 218.9122 - mae: 219.4122 - val_loss: 293.8080 - val_mae: 294.3080\n",
      "Epoch 2/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 215.6915 - mae: 216.1915 - val_loss: 291.0893 - val_mae: 291.5893\n",
      "Epoch 3/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 212.8451 - mae: 213.3451 - val_loss: 288.3703 - val_mae: 288.8703\n",
      "Epoch 4/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 210.3633 - mae: 210.8633 - val_loss: 286.3062 - val_mae: 286.8062\n",
      "Epoch 5/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 208.4407 - mae: 208.9407 - val_loss: 284.2299 - val_mae: 284.7299\n",
      "Epoch 6/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 206.3913 - mae: 206.8913 - val_loss: 282.1983 - val_mae: 282.6983\n",
      "Epoch 7/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 203.9148 - mae: 204.4148 - val_loss: 280.0150 - val_mae: 280.5150\n",
      "Epoch 8/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 201.9280 - mae: 202.4280 - val_loss: 277.8961 - val_mae: 278.3961\n",
      "Epoch 9/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 200.0291 - mae: 200.5291 - val_loss: 275.2765 - val_mae: 275.7765\n",
      "Epoch 10/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 196.6180 - mae: 197.1180 - val_loss: 272.1393 - val_mae: 272.6393\n",
      "Epoch 11/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 194.0699 - mae: 194.5699 - val_loss: 269.2000 - val_mae: 269.7000\n",
      "Epoch 12/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 190.7321 - mae: 191.2321 - val_loss: 265.9921 - val_mae: 266.4921\n",
      "Epoch 13/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 188.2891 - mae: 188.7891 - val_loss: 262.8716 - val_mae: 263.3716\n",
      "Epoch 14/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 184.7452 - mae: 185.2452 - val_loss: 259.6282 - val_mae: 260.1282\n",
      "Epoch 15/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 181.3491 - mae: 181.8491 - val_loss: 256.2513 - val_mae: 256.7513\n",
      "Epoch 16/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 178.1222 - mae: 178.6222 - val_loss: 252.7364 - val_mae: 253.2364\n",
      "Epoch 17/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 174.5149 - mae: 175.0149 - val_loss: 249.0816 - val_mae: 249.5816\n",
      "Epoch 18/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 170.7733 - mae: 171.2733 - val_loss: 245.2861 - val_mae: 245.7861\n",
      "Epoch 19/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 167.0205 - mae: 167.5205 - val_loss: 241.3500 - val_mae: 241.8500\n",
      "Epoch 20/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 162.9419 - mae: 163.4419 - val_loss: 237.2339 - val_mae: 237.7339\n",
      "Epoch 21/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 158.3541 - mae: 158.8541 - val_loss: 232.4987 - val_mae: 232.9987\n",
      "Epoch 22/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 153.8048 - mae: 154.3048 - val_loss: 227.9686 - val_mae: 228.4686\n",
      "Epoch 23/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 149.4122 - mae: 149.9122 - val_loss: 223.3199 - val_mae: 223.8199\n",
      "Epoch 24/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 144.8753 - mae: 145.3753 - val_loss: 218.5418 - val_mae: 219.0418\n",
      "Epoch 25/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 139.5482 - mae: 140.0482 - val_loss: 213.6310 - val_mae: 214.1310\n",
      "Epoch 26/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 134.9140 - mae: 135.4140 - val_loss: 208.5862 - val_mae: 209.0862\n",
      "Epoch 27/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 129.5235 - mae: 130.0235 - val_loss: 203.4074 - val_mae: 203.9074\n",
      "Epoch 28/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 124.6162 - mae: 125.1162 - val_loss: 198.0949 - val_mae: 198.5949\n",
      "Epoch 29/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 119.2038 - mae: 119.7038 - val_loss: 192.6494 - val_mae: 193.1494\n",
      "Epoch 30/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 113.6577 - mae: 114.1577 - val_loss: 187.0716 - val_mae: 187.5716\n",
      "Epoch 31/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 108.1156 - mae: 108.6156 - val_loss: 181.3625 - val_mae: 181.8625\n",
      "Epoch 32/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 102.4044 - mae: 102.9044 - val_loss: 175.5230 - val_mae: 176.0230\n",
      "Epoch 33/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 96.6539 - mae: 97.1539 - val_loss: 169.5541 - val_mae: 170.0541\n",
      "Epoch 34/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 90.8121 - mae: 91.3121 - val_loss: 163.4568 - val_mae: 163.9568\n",
      "Epoch 35/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 84.1538 - mae: 84.6528 - val_loss: 157.2393 - val_mae: 157.7393\n",
      "Epoch 36/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 78.5395 - mae: 79.0391 - val_loss: 150.9538 - val_mae: 151.4538\n",
      "Epoch 37/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 72.7159 - mae: 73.2127 - val_loss: 144.6780 - val_mae: 145.1780\n",
      "Epoch 38/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 67.3079 - mae: 67.8021 - val_loss: 138.5349 - val_mae: 139.0349\n",
      "Epoch 39/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 62.8971 - mae: 63.3932 - val_loss: 132.5115 - val_mae: 133.0115\n",
      "Epoch 40/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 58.8010 - mae: 59.2983 - val_loss: 126.5684 - val_mae: 127.0684\n",
      "Epoch 41/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 55.6526 - mae: 56.1511 - val_loss: 120.7197 - val_mae: 121.2194\n",
      "Epoch 42/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 52.6876 - mae: 53.1860 - val_loss: 115.0047 - val_mae: 115.5046\n",
      "Epoch 43/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 50.6167 - mae: 51.1158 - val_loss: 109.6175 - val_mae: 110.1171\n",
      "Epoch 44/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 49.0811 - mae: 49.5797 - val_loss: 104.2987 - val_mae: 104.7982\n",
      "Epoch 45/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 47.1039 - mae: 47.6037 - val_loss: 99.1237 - val_mae: 99.6219\n",
      "Epoch 46/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 45.4404 - mae: 45.9362 - val_loss: 94.3248 - val_mae: 94.8226\n",
      "Epoch 47/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 44.6976 - mae: 45.1939 - val_loss: 90.1209 - val_mae: 90.6163\n",
      "Epoch 48/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 44.7946 - mae: 45.2865 - val_loss: 86.6607 - val_mae: 87.1594\n",
      "Epoch 49/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 44.9708 - mae: 45.4692 - val_loss: 83.6285 - val_mae: 84.1267\n",
      "Epoch 50/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 44.9188 - mae: 45.4173 - val_loss: 80.7114 - val_mae: 81.2102\n",
      "Epoch 51/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 45.9128 - mae: 46.4110 - val_loss: 78.0359 - val_mae: 78.5339\n",
      "Epoch 52/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 45.1629 - mae: 45.6613 - val_loss: 75.6150 - val_mae: 76.1137\n",
      "Epoch 53/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 47.4534 - mae: 47.9512 - val_loss: 73.4999 - val_mae: 73.9970\n",
      "Epoch 54/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 47.1192 - mae: 47.6175 - val_loss: 71.3010 - val_mae: 71.7995\n",
      "Epoch 55/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 44.4779 - mae: 44.9753 - val_loss: 69.7983 - val_mae: 70.2960\n",
      "Epoch 56/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 48.1866 - mae: 48.6850 - val_loss: 67.6766 - val_mae: 68.1738\n",
      "Epoch 57/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 44.7089 - mae: 45.2068 - val_loss: 70.4585 - val_mae: 70.9559\n",
      "Epoch 58/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 43.8321 - mae: 44.3300 - val_loss: 68.5835 - val_mae: 69.0803\n",
      "Epoch 59/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 43.7636 - mae: 44.2617 - val_loss: 66.9124 - val_mae: 67.4087\n",
      "Epoch 60/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 41.8685 - mae: 42.3673 - val_loss: 65.3862 - val_mae: 65.8836\n",
      "Epoch 61/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 40.6967 - mae: 41.1952 - val_loss: 63.8479 - val_mae: 64.3464\n",
      "Epoch 62/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 39.1600 - mae: 39.6583 - val_loss: 62.3156 - val_mae: 62.8133\n",
      "Epoch 63/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 37.0721 - mae: 37.5685 - val_loss: 59.3151 - val_mae: 59.8110\n",
      "Epoch 64/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29.5116 - mae: 30.0080 - val_loss: 53.8791 - val_mae: 54.3734\n",
      "Epoch 65/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 21.3718 - mae: 21.8648 - val_loss: 54.2640 - val_mae: 54.7618\n",
      "Epoch 66/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 20.4552 - mae: 20.9518 - val_loss: 51.2386 - val_mae: 51.7353\n",
      "Epoch 67/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 16.2667 - mae: 16.7565 - val_loss: 49.5927 - val_mae: 50.0866\n",
      "Epoch 68/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 14.5457 - mae: 15.0323 - val_loss: 46.1484 - val_mae: 46.6381\n",
      "Epoch 69/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 14.8872 - mae: 15.3722 - val_loss: 44.1620 - val_mae: 44.6469\n",
      "Epoch 70/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 11.4108 - mae: 11.8919 - val_loss: 42.7915 - val_mae: 43.2826\n",
      "Epoch 71/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.5500 - mae: 11.0341 - val_loss: 40.7929 - val_mae: 41.2794\n",
      "Epoch 72/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.0166 - mae: 9.4908 - val_loss: 40.4587 - val_mae: 40.9533\n",
      "Epoch 73/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.0589 - mae: 9.5413 - val_loss: 37.6323 - val_mae: 38.1165\n",
      "Epoch 74/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8056 - mae: 8.2839 - val_loss: 37.3619 - val_mae: 37.8556\n",
      "Epoch 75/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.2119 - mae: 7.6890 - val_loss: 33.4441 - val_mae: 33.9376\n",
      "Epoch 76/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.1785 - mae: 7.6544 - val_loss: 33.6299 - val_mae: 34.1268\n",
      "Epoch 77/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.5815 - mae: 7.0626 - val_loss: 30.4363 - val_mae: 30.9264\n",
      "Epoch 78/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.7255 - mae: 6.2030 - val_loss: 30.0511 - val_mae: 30.5440\n",
      "Epoch 79/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.9523 - mae: 7.4351 - val_loss: 28.4136 - val_mae: 28.8961\n",
      "Epoch 80/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.2301 - mae: 5.7062 - val_loss: 28.9699 - val_mae: 29.4655\n",
      "Epoch 81/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.1731 - mae: 5.6451 - val_loss: 27.3738 - val_mae: 27.8662\n",
      "Epoch 82/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.2648 - mae: 5.7389 - val_loss: 26.8582 - val_mae: 27.3512\n",
      "Epoch 83/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.0771 - mae: 5.5484 - val_loss: 27.3472 - val_mae: 27.8411\n",
      "Epoch 84/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.2831 - mae: 5.7618 - val_loss: 24.4604 - val_mae: 24.9452\n",
      "Epoch 85/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.7560 - mae: 5.2257 - val_loss: 23.9334 - val_mae: 24.4192\n",
      "Epoch 86/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.5503 - mae: 5.0260 - val_loss: 24.3479 - val_mae: 24.8391\n",
      "Epoch 87/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.7850 - mae: 5.2634 - val_loss: 22.8484 - val_mae: 23.3341\n",
      "Epoch 88/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.5893 - mae: 5.0653 - val_loss: 23.3415 - val_mae: 23.8301\n",
      "Epoch 89/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.7530 - mae: 5.2223 - val_loss: 22.2147 - val_mae: 22.6998\n",
      "Epoch 90/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7878 - mae: 5.2645 - val_loss: 20.5104 - val_mae: 20.9937\n",
      "Epoch 91/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.2456 - mae: 4.7147 - val_loss: 19.9889 - val_mae: 20.4713\n",
      "Epoch 92/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.6318 - mae: 5.1125 - val_loss: 19.8717 - val_mae: 20.3526\n",
      "Epoch 93/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.0978 - mae: 4.5672 - val_loss: 19.1790 - val_mae: 19.6569\n",
      "Epoch 94/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.8278 - mae: 4.2946 - val_loss: 19.0935 - val_mae: 19.5705\n",
      "Epoch 95/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7318 - mae: 4.2021 - val_loss: 18.5181 - val_mae: 18.9982\n",
      "Epoch 96/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.8502 - mae: 4.3184 - val_loss: 18.0498 - val_mae: 18.5318\n",
      "Epoch 97/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.5907 - mae: 4.0564 - val_loss: 20.7069 - val_mae: 21.2018\n",
      "Epoch 98/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.1325 - mae: 4.6051 - val_loss: 17.0744 - val_mae: 17.5496\n",
      "Epoch 99/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.6708 - mae: 4.1364 - val_loss: 17.4435 - val_mae: 17.9272\n",
      "Epoch 100/100\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.4983 - mae: 3.9648 - val_loss: 16.4578 - val_mae: 16.9310\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "this __dict__ descriptor does not support '_DictWrapper' objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m rnn_trainer\u001b[38;5;241m=\u001b[39mTrainerNeuralNetwork(recurrent_units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, dense_units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m rnn_model_path\u001b[38;5;241m=\u001b[39m\u001b[43mrnn_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\src\\components\\trainer_rnn.py:33\u001b[0m, in \u001b[0;36mTrainerNeuralNetwork.init_model\u001b[1;34m(self, train_dataset, val_dataset, epochs)\u001b[0m\n\u001b[0;32m     27\u001b[0m model\u001b[38;5;241m=\u001b[39mbuild_nn_models(dense_units\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense_units,\n\u001b[0;32m     28\u001b[0m                       recurrent_units\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurrent_units,\n\u001b[0;32m     29\u001b[0m                       window_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mwindow_size)\n\u001b[0;32m     32\u001b[0m hist\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(train_dataset, epochs\u001b[38;5;241m=\u001b[39mepochs, validation_data\u001b[38;5;241m=\u001b[39mval_dataset)\n\u001b[1;32m---> 33\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfi\u001b[38;5;241m.\u001b[39mmodel_save_path, hist\n",
      "File \u001b[1;32mc:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1432\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[1;32m-> 1432\u001b[0m \u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1434\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWrite(write_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1467\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[1;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[0;32m   1463\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m saved_model_pb2\u001b[38;5;241m.\u001b[39mSavedModel()\n\u001b[0;32m   1464\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39mmeta_graphs\u001b[38;5;241m.\u001b[39madd()\n\u001b[0;32m   1466\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1467\u001b[0m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1468\u001b[0m saved_model\u001b[38;5;241m.\u001b[39msaved_model_schema_version \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1469\u001b[0m     constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;66;03m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;66;03m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1682\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m \n\u001b[0;32m   1657\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;124;03m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[0;32m   1679\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save_context\u001b[38;5;241m.\u001b[39msave_context(options):\n\u001b[1;32m-> 1682\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1592\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   1590\u001b[0m augmented_graph_view \u001b[38;5;241m=\u001b[39m _AugmentedGraphView(obj)\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1592\u001b[0m   signatures \u001b[38;5;241m=\u001b[39m \u001b[43msignature_serialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_function_to_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1593\u001b[0m \u001b[43m      \u001b[49m\u001b[43maugmented_graph_view\u001b[49m\n\u001b[0;32m   1594\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1596\u001b[0m signatures, wrapped_functions, defaults \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1597\u001b[0m     signature_serialization\u001b[38;5;241m.\u001b[39mcanonicalize_signatures(signatures)\n\u001b[0;32m   1598\u001b[0m )\n\u001b[0;32m   1599\u001b[0m signature_serialization\u001b[38;5;241m.\u001b[39mvalidate_augmented_graph_view(augmented_graph_view)\n",
      "File \u001b[1;32mc:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\tensorflow\\python\\saved_model\\signature_serialization.py:109\u001b[0m, in \u001b[0;36mfind_function_to_export\u001b[1;34m(saveable_view)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# TODO(b/205014194): Discuss removing this behaviour. It can lead to WTFs when\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# a user decides to annotate more functions with tf.function and suddenly\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# serving that model way later in the process stops working.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m possible_signatures \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 109\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchildren\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdef_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConcreteFunction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mcontinue\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:190\u001b[0m, in \u001b[0;36m_AugmentedGraphView.list_children\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children_cache:\n\u001b[0;32m    188\u001b[0m   children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children_cache[obj] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 190\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_AugmentedGraphView\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_children\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m      \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSaveType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSAVEDMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialization_cache\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child, defun\u001b[38;5;241m.\u001b[39mConcreteFunction):\n\u001b[0;32m    195\u001b[0m       child \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_uncache_variable_captures(child)\n",
      "File \u001b[1;32mc:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\graph_view.py:75\u001b[0m, in \u001b[0;36mObjectGraphView.list_children\u001b[1;34m(self, obj, save_type, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns list of all child trackables attached to obj.\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m  List of all children attached to the object.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     74\u001b[0m children \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, ref \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mObjectGraphView\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     77\u001b[0m   children\u001b[38;5;241m.\u001b[39mappend(base\u001b[38;5;241m.\u001b[39mTrackableReference(name, ref))\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# GraphView objects may define children of the root object that are not\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# actually attached, e.g. a Checkpoint object's save_counter.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\trackable_view.py:85\u001b[0m, in \u001b[0;36mTrackableView.children\u001b[1;34m(cls, obj, save_type, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m children \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, ref \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_trackable_children(save_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 85\u001b[0m   ref \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_trackable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m   children[name] \u001b[38;5;241m=\u001b[39m ref\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m children\n",
      "File \u001b[1;32mc:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\tensorflow\\python\\trackable\\converter.py:31\u001b[0m, in \u001b[0;36mconvert_to_trackable\u001b[1;34m(obj, parent)\u001b[0m\n\u001b[0;32m     29\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m     30\u001b[0m obj \u001b[38;5;241m=\u001b[39m data_structures\u001b[38;5;241m.\u001b[39mwrap_or_unwrap(obj)\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mtensor_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_tf_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     obj\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (dtypes\u001b[38;5;241m.\u001b[39mvariant, dtypes\u001b[38;5;241m.\u001b[39mresource) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m resource_variable_ops\u001b[38;5;241m.\u001b[39mis_resource_variable(obj)):\n\u001b[0;32m     34\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_utils\u001b[38;5;241m.\u001b[39mTrackableConstant(obj, parent)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, base\u001b[38;5;241m.\u001b[39mTrackable):\n",
      "File \u001b[1;32mc:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:1163\u001b[0m, in \u001b[0;36mis_tf_type\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_tf_type\u001b[39m(x):  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Checks whether `x` is a TF-native type that can be passed to many TF ops.\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \n\u001b[0;32m   1139\u001b[0m \u001b[38;5;124;03m  Use `is_tensor` to differentiate types that can ingested by TensorFlow ops\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;124;03m    `True` if `x` is a TensorFlow-native type.\u001b[39;00m\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1163\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf_type_classes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\typing.py:1868\u001b[0m, in \u001b[0;36m_ProtocolMeta.__instancecheck__\u001b[1;34m(cls, instance)\u001b[0m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__protocol_attrs__:\n\u001b[0;32m   1867\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1868\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[43mgetattr_static\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1869\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   1870\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\inspect.py:1839\u001b[0m, in \u001b[0;36mgetattr_static\u001b[1;34m(obj, attr, default)\u001b[0m\n\u001b[0;32m   1836\u001b[0m     dict_attr \u001b[38;5;241m=\u001b[39m _shadowed_dict(klass)\n\u001b[0;32m   1837\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (dict_attr \u001b[38;5;129;01mis\u001b[39;00m _sentinel \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1838\u001b[0m         \u001b[38;5;28mtype\u001b[39m(dict_attr) \u001b[38;5;129;01mis\u001b[39;00m types\u001b[38;5;241m.\u001b[39mMemberDescriptorType):\n\u001b[1;32m-> 1839\u001b[0m         instance_result \u001b[38;5;241m=\u001b[39m \u001b[43m_check_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1840\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1841\u001b[0m     klass \u001b[38;5;241m=\u001b[39m obj\n",
      "File \u001b[1;32mc:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\inspect.py:1793\u001b[0m, in \u001b[0;36m_check_instance\u001b[1;34m(obj, attr)\u001b[0m\n\u001b[0;32m   1791\u001b[0m instance_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1792\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1793\u001b[0m     instance_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__dict__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: this __dict__ descriptor does not support '_DictWrapper' objects"
     ]
    }
   ],
   "source": [
    "rnn_trainer=TrainerNeuralNetwork(recurrent_units=64, dense_units=16)\n",
    "rnn_model_path=rnn_trainer.init_model(train_dataset=train_ds, val_dataset=test_ds, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from src.components.trainer_rnn import build_nn_models\n",
    "from src.config import DENSE_UNITS, RECURRENT_UNITS, WINDOW_SIZE\n",
    "\n",
    "mm=build_nn_models(dense_units=DENSE_UNITS, recurrent_units=RECURRENT_UNITS, window_size=WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "mm.load_weights(r'C:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\tmp\\model_checkpoints\\checkpoint.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-10-31.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "sorted(os.listdir(r'C:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\data\\data'))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['open', 'high', 'low', 'close', 'volume', 'dividends', 'stock_splits']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.config import METRICS\n",
    "from src.utils import percentage_calculator\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(r'C:\\Users\\ernes\\Documents\\ML Projects\\forecast_yahoo\\data\\data\\2024-10-31.csv')\n",
    "\n",
    "METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([428.        , 437.44000244])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=df.loc[:, 'open_MSFT'].values[-2:]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-2.21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_calculator(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([1, 2, 2]).iloc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
